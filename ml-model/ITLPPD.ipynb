{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITLPPD Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA \n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the architectures.\n",
    "\n",
    "The Autoencoder encodes the buffered data windows.\n",
    "\n",
    "The Information Theoretic Learning Point Process Detector is an architectural extension of the Autoencoder, that uses the expected value of the latent space to correct the learning process. Interpreting the latent space can additionally be used to generate a point process - when the batch is unexpected, it can be flagged (and generate a corresponding point process). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Autoencoder Model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, D, C, M_C):\n",
    "        '''\n",
    "        Hyperparameters:\n",
    "        ---------------\n",
    "        D: window_size\n",
    "        C: compression factor, 2**C\n",
    "        M_C: minimum compression\n",
    "\n",
    "        Attributes:\n",
    "        -----------\n",
    "        encoder: Encoder part of the autoencoder\n",
    "        decoder: Decoder part of the autoencoder\n",
    "        LD: Latent dimension\n",
    "        num_compressions: Number of compression layers\n",
    "        compressions: List of compression sizes\n",
    "        latent_code: Latent code of the input\n",
    "        -----------\n",
    "        '''\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        if D is None:\n",
    "            raise ValueError(\"window_size must be provided\")\n",
    "        self.D = D\n",
    "        if C is None:\n",
    "            raise ValueError(\"compression factor must be provided\")\n",
    "        self.C = C\n",
    "        if M_C is None:\n",
    "            raise ValueError(\"minimum compression must be provided\")\n",
    "        self.M_C = M_C\n",
    "\n",
    "        self.LD = None\n",
    "\n",
    "        # Calculate compression sizes\n",
    "        self.compressions = [D // (2**C)]\n",
    "        while self.compressions[-1] >= M_C:\n",
    "            s_c = self.compressions[-1] // (2**C)\n",
    "            if s_c < M_C:\n",
    "                break\n",
    "            else:\n",
    "                self.compressions.append(s_c)\n",
    "                self.LD = s_c\n",
    "\n",
    "        self.num_compressions = len(self.compressions)\n",
    "        self.latent_code = None\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential()\n",
    "        self.encoder.add_module(\"encoder_0\", nn.Linear(D, self.compressions[0]))\n",
    "        for i in range(self.num_compressions - 1):\n",
    "            self.encoder.add_module(f\"encoder_{i+1}\", nn.Linear(self.compressions[i], self.compressions[i + 1]))\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential()\n",
    "        for i in range(self.num_compressions - 1, 0, -1):\n",
    "            self.decoder.add_module(f\"decoder_{i}\", nn.Linear(self.compressions[i], self.compressions[i - 1]))\n",
    "        self.decoder.add_module(\"decoder_0\", nn.Linear(self.compressions[0], D))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        self.latent_code = x.detach()  # Store latent code\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# ITLPPD Model\n",
    "class ITLPPD:\n",
    "    def __init__(self, D=None, C=None, M_C=None, L=None, lr=None, sigma=None, lambda_reg=None, delta=None, device=None):\n",
    "        '''\n",
    "        Hyperparameters:\n",
    "        ---------------\n",
    "        D: window_size\n",
    "        C: compression factor, 2**C\n",
    "        M_C: minimum compression\n",
    "        L: number of windows/lags\n",
    "        lr: Learning rate for the optimizer\n",
    "        sigma: Standard deviation for the Gaussian function\n",
    "        lambda_reg: Weight for the regularization term\n",
    "        delta: Threshold value for the regularizer to trigger point process events\n",
    "        device: Device to run the model on (e.g., \"cuda\" or \"cpu\")\n",
    "\n",
    "        Attributes:\n",
    "        -----------\n",
    "        model: Instance of the Autoencoder class\n",
    "        Zs: Buffer of the previous L latent codes (as a tensor)\n",
    "        latent_history: List that stores latent codes at each training step\n",
    "        spike_train_history: List that stores spike (point process) events per sample\n",
    "        criterion: Loss function (MSE)\n",
    "        optimizer: Optimizer (Adam)\n",
    "        -----------\n",
    "        '''\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        if D is None:\n",
    "            raise ValueError(\"window_size must be provided\")\n",
    "        if C is None:\n",
    "            raise ValueError(\"compression factor must be provided\")\n",
    "        if M_C is None:\n",
    "            raise ValueError(\"minimum compression must be provided\")\n",
    "        if L is None:\n",
    "            raise ValueError(\"L must be provided\")\n",
    "        if sigma is None:\n",
    "            raise ValueError(\"Sigma must be provided\")\n",
    "        if lr is None:\n",
    "            raise ValueError(\"Learning rate must be provided\")\n",
    "        if delta is None:\n",
    "            raise ValueError(\"Delta threshold must be provided\")\n",
    "            \n",
    "        self.model = Autoencoder(D, C, M_C).to(self.device)\n",
    "        self.L = L\n",
    "        self.sigma = sigma\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.delta = delta  # Threshold for triggering a point process event\n",
    "\n",
    "        # Initialize Zs as a tensor of zeros on the device (shape: L x latent dimension)\n",
    "        if self.model.LD is None:\n",
    "            raise ValueError(\"Latent dimension is not defined in the model\")\n",
    "        self.Zs = torch.zeros((L, self.model.LD), device=self.device)\n",
    "        \n",
    "        self.criterion = nn.MSELoss() \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # To store latent codes from each training iteration (each element is a tensor of shape [batch_size, latent_dim])\n",
    "        self.latent_history = []\n",
    "        # To store spike (point process) events per sample\n",
    "        self.spike_train_history = []\n",
    "\n",
    "    def train(self, train_loader, num_epochs=10):\n",
    "        \"\"\"\n",
    "        Train the autoencoder with an additional latent-code regularization term.\n",
    "        For each sample in a batch, compute the regularization loss and generate a spike event\n",
    "        (1 if the loss exceeds delta, else 0). The spike events are generated per new sample.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        sigma = self.sigma  # Standard deviation for the Gaussian function\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                data = data.to(self.device)\n",
    "                \n",
    "                # Forward pass: autoencoder returns reconstructed data and stores the latent code.\n",
    "                outputs = self.model(data)\n",
    "                # Log latent codes from this batch (each element is of shape: [batch_size, latent_dim])\n",
    "                self.latent_history.append(self.model.latent_code.detach().cpu())\n",
    "                \n",
    "                recon_loss = self.criterion(outputs, data)\n",
    "                \n",
    "                # Instead of averaging over the batch, compute per-sample regularization.\n",
    "                latent_codes = self.model.latent_code  # shape: (batch_size, latent_dim)\n",
    "                reg_losses = []\n",
    "                \n",
    "                # Process each sample in the batch individually:\n",
    "                for i in range(latent_codes.size(0)):\n",
    "                    current_z = latent_codes[i]  # shape: (latent_dim,)\n",
    "                    diff = current_z.unsqueeze(0) - self.Zs  # shape: (L, latent_dim)\n",
    "                    squared_diff = diff.pow(2).sum(dim=1)      # shape: (L,)\n",
    "                    similarity = torch.exp(-squared_diff / (2 * sigma**2))\n",
    "                    avg_similarity = similarity.mean()\n",
    "                    reg_loss_i = 1 - avg_similarity  # Regularization loss for this sample\n",
    "                    reg_losses.append(reg_loss_i)\n",
    "                    \n",
    "                    # Generate a spike event per sample: compare reg_loss_i to threshold delta.\n",
    "                    spike_event = 1 if reg_loss_i.item() > self.delta else 0\n",
    "                    self.spike_train_history.append(spike_event)\n",
    "                    \n",
    "                    # Update the Zs buffer: remove the oldest latent code and append the current one.\n",
    "                    new_z = current_z.detach()\n",
    "                    self.Zs = torch.cat((self.Zs[1:], new_z.unsqueeze(0)), dim=0)\n",
    "                \n",
    "                # Average the regularization loss over all samples in the batch.\n",
    "                reg_loss = torch.stack(reg_losses).mean()\n",
    "                total_loss = recon_loss + self.lambda_reg * reg_loss\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += total_loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 1024 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.8f}\")\n",
    "        \n",
    "        print(\"Training Complete!\")\n",
    "    \n",
    "    def encode(self, data):\n",
    "        \"\"\"Return the latent code for the given input data.\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            data = data.to(self.device)\n",
    "            latent_code = self.model.encoder(data)\n",
    "        return latent_code.cpu()\n",
    "\n",
    "    def get_latent_codes(self, data_loader):\n",
    "        \"\"\"Iterate over the data loader and return latent codes for all samples.\"\"\"\n",
    "        self.model.eval()\n",
    "        latent_codes_list = []\n",
    "        with torch.no_grad():\n",
    "            for data in data_loader:\n",
    "                data = data.to(self.device)\n",
    "                latent_codes = self.model.encoder(data)\n",
    "                latent_codes_list.append(latent_codes.cpu())\n",
    "        return torch.cat(latent_codes_list, dim=0)\n",
    "    \n",
    "    def print_latent_history(self):\n",
    "        \"\"\"Print the stored latent history in a nicely formatted manner.\"\"\"\n",
    "        print(\"=== Latent History ===\")\n",
    "        for iter_idx, batch_latents in enumerate(self.latent_history):\n",
    "            print(f\"Iteration {iter_idx+1}:\")\n",
    "            for sample_idx in range(batch_latents.shape[0]):\n",
    "                code = batch_latents[sample_idx].tolist()\n",
    "                formatted_code = \", \".join([f\"{v:.4f}\" for v in code])\n",
    "                print(f\"  Sample {sample_idx+1}: [{formatted_code}]\")\n",
    "            print(\"-\" * 50)\n",
    "        print(\"=== End of Latent History ===\")\n",
    "    \n",
    "    def print_spike_train_history(self):\n",
    "        \"\"\"Print the recorded spike events corresponding to each sample.\"\"\"\n",
    "        print(\"=== Spike Train History ===\")\n",
    "        for idx, spike in enumerate(self.spike_train_history):\n",
    "            print(f\"Sample {idx+1}: Spike event = {spike}\")\n",
    "        print(\"=== End of Spike Train History ===\")\n",
    "    \n",
    "    def plot_spike_train_history(self, save_path=None):\n",
    "        \"\"\"Plot the spike train events over time using a scatter plot with different colors for 0s and 1s.\"\"\"\n",
    "        spike_indices = [i for i, val in enumerate(self.spike_train_history) if val == 1]\n",
    "        non_spike_indices = [i for i, val in enumerate(self.spike_train_history) if val == 0]\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.scatter(non_spike_indices, [0] * len(non_spike_indices), color='r', marker='o', label=\"No Spike (0)\")\n",
    "        plt.scatter(spike_indices, [1] * len(spike_indices), color='b', marker='o', label=\"Spike (1)\")\n",
    "\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Spike Event (1=Spike, 0=No Spike)\")\n",
    "        plt.title(\"Spike Train History Over Samples\")\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_latent_space_history(self, save_path=None, title=None):\n",
    "        \"\"\"\n",
    "        Plot the evolution of the latent space over training iterations.\n",
    "        \n",
    "        This function extracts the latent code of the first sample from each batch (stored in latent_history)\n",
    "        and plots their evolution. If the latent code dimension is 2, a direct scatter plot is generated;\n",
    "        otherwise, PCA is used to project the latent codes into 2D.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        save_path : str, optional\n",
    "            If provided, the figure is saved to this path.\n",
    "        title : str, optional\n",
    "            Custom title for the plot.\n",
    "        \"\"\"\n",
    "        # Extract the first sample's latent code from each batch in the latent history.\n",
    "        first_sample_latents = []\n",
    "        for batch_latents in self.latent_history:\n",
    "            # Each batch_latents is assumed to be a tensor of shape [batch_size, latent_dim]\n",
    "            first_sample_latents.append(batch_latents[0])\n",
    "        first_sample_latents = torch.stack(first_sample_latents)  # Shape: [num_batches, latent_dim]\n",
    "        first_sample_latents = first_sample_latents.detach().cpu().numpy()\n",
    "        \n",
    "        iterations = np.arange(first_sample_latents.shape[0])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        if first_sample_latents.shape[1] == 2:\n",
    "            # If the latent dimension is 2, plot directly.\n",
    "            plt.scatter(first_sample_latents[:, 0], first_sample_latents[:, 1],\n",
    "                        c=iterations, cmap='viridis', s=50)\n",
    "            plt.xlabel(\"Latent Dimension 1\")\n",
    "            plt.ylabel(\"Latent Dimension 2\")\n",
    "            if title is None:\n",
    "                plt.title(\"Latent Codes Evolution (first sample in each batch)\")\n",
    "            else:\n",
    "                plt.title(title)\n",
    "        else:\n",
    "            # Otherwise, project the latent codes to 2D using PCA.\n",
    "            pca = PCA(n_components=2)\n",
    "            latents_2d = pca.fit_transform(first_sample_latents)\n",
    "            plt.scatter(latents_2d[:, 0], latents_2d[:, 1],\n",
    "                        c=iterations, cmap='viridis', s=50)\n",
    "            plt.xlabel(\"Principal Component 1\")\n",
    "            plt.ylabel(\"Principal Component 2\")\n",
    "            if title is None:\n",
    "                plt.title(\"Latent Codes Evolution (first sample in each batch) - PCA Projection\")\n",
    "            else:\n",
    "                plt.title(title)\n",
    "        \n",
    "        plt.colorbar(label=\"Training Iteration\")\n",
    "        \n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, signal, window_size, step=None):\n",
    "        \"\"\"\n",
    "        signal: 1D numpy array (e.g., one EEG channel)\n",
    "        window_size: number of samples per window (D)\n",
    "        step: step size between windows (default: non-overlapping windows)\n",
    "        \"\"\"\n",
    "        self.signal = signal\n",
    "        self.window_size = window_size\n",
    "        self.step = step if step is not None else window_size\n",
    "        self.windows = []\n",
    "        # Create sliding windows\n",
    "        for start in range(0, len(signal) - window_size + 1, self.step):\n",
    "            self.windows.append(signal[start:start+window_size])\n",
    "        self.windows = np.array(self.windows)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.windows[idx]\n",
    "        # Convert to tensor (shape: [window_size])\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 250                      # Sampling frequency (Hz)\n",
    "batch_size = 32\n",
    "num_epochs = 4096\n",
    "\n",
    "D_candidates = [32, 64, 128, 256]    # Window size (e.g., 1 sec of data)\n",
    "C_candidates = [1, 2, 3]             # Compression factor\n",
    "M_C_candidates = [2, 4, 8]           # Minimum compression size\n",
    "L_candidates = [16, 32, 64]          # Number of latent codes to store\n",
    "lr_candidates = [2**-i for i in [6, 10, 13]]\n",
    "lambda_reg_candidates = [0, 1/4, 1, 128]\n",
    "sigma_candidates = [2**-i for i in [0, 3, 6]]\n",
    "delta_candidates = [0.25, 0.5, 0.75]\n",
    "\n",
    "# Approximately 4k combinations\n",
    "combinations = list(product(D_candidates, C_candidates, M_C_candidates, L_candidates, lr_candidates, lambda_reg_candidates, sigma_candidates, delta_candidates))\n",
    "\n",
    "# Channels specification\n",
    "essential_channels = ['EXG Channel 6', 'EXG Channel 7']\n",
    "keep_channels = [\n",
    "    'EXG Channel 0', 'EXG Channel 1', 'EXG Channel 2', 'EXG Channel 3',\n",
    "    'EXG Channel 4', 'EXG Channel 5', 'EXG Channel 6', 'EXG Channel 7'\n",
    "]\n",
    "drop_channels = [\n",
    "    'Accel Channel 0', 'Accel Channel 1', 'Accel Channel 2', 'Not Used',\n",
    "    'Digital Channel 0 (D11)', 'Digital Channel 1 (D12)', 'Digital Channel 2 (D13)',\n",
    "    'Digital Channel 3 (D17)', 'Not Used', 'Digital Channel 4 (D18)', \n",
    "    'Analog Channel 0', 'Analog Channel 1', 'Analog Channel 2',\n",
    "    'Timestamp', 'Marker Channel', 'Timestamp (Formatted)'\n",
    "]\n",
    "\n",
    "# Loop over experiments (for example, experiments 1, 2, and 3)\n",
    "for i in [1, 2, 3]:\n",
    "    # Loop over all hyperparameter combinations\n",
    "    for hyperparameters in combinations:\n",
    "        D, C, M_C, L, lr, lambda_reg, sigma, delta = hyperparameters\n",
    "        print(f\"\\nProcessing experiment {i} ...\")\n",
    "        print(f\"Hyperparameters: D={D}, C={C}, M_C={M_C}, L={L}, lr={lr}, lambda_reg={lambda_reg}, sigma={sigma}, delta={delta}\")\n",
    "        hyp_str = f\"D={D}_C={C}_M_C={M_C}_L={L}_lr={lr}_lambda_reg={lambda_reg}_sigma={sigma}_delta={delta}\"\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(f\"wink{i}_received_data.txt\", skiprows=4, delimiter=', ', engine='python')\n",
    "        \n",
    "        # Drop unwanted channels and remove rows with NaNs\n",
    "        df = df.drop(columns=drop_channels, errors='ignore').dropna().reset_index(drop=True)\n",
    "\n",
    "        # Normalize data by magnitude for channels to keep\n",
    "        for channel in keep_channels:\n",
    "            df[channel] = df[channel] / np.linalg.norm(df[channel])\n",
    "              \n",
    "        # Select one channel for training (e.g., \"EXG Channel 6\")\n",
    "        signal = df['EXG Channel 6'].values\n",
    "        \n",
    "        # Create dataset from sliding windows (non-overlapping windows)\n",
    "        dataset = EEGDataset(signal, window_size=D, step=D)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Instantiate the model and train it\n",
    "        try:\n",
    "            model = ITLPPD(D=D, C=C, M_C=M_C, L=L, lr=lr, sigma=sigma, lambda_reg=lambda_reg, delta=delta, device=\"cuda\")\n",
    "            print(f\"Training model on experiment {i} data...\")\n",
    "            model.train(dataloader, num_epochs=num_epochs)\n",
    "            \n",
    "            # Plot latent space evolution using the new method\n",
    "            save_path = f\"plots/latent_codes/experiment_{i}_{hyp_str}.png\"\n",
    "            model.plot_latent_space_history(save_path=save_path, title=\"Latent Codes Evolution (first sample in each batch)\")\n",
    "            \n",
    "            # (Optional) Plot spike train history\n",
    "            save_path = f\"plots/spike_trains/experiment_{i}_{hyp_str}.png\"\n",
    "            model.plot_spike_train_history(save_path=save_path)\n",
    "            \n",
    "            # (Optional) Test prediction on a sample window and visualize reconstruction.\n",
    "            sample_window = next(iter(dataloader))\n",
    "            reconstructed = model.model(sample_window.to(model.device))\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(sample_window[0].cpu().numpy(), label='Original')\n",
    "            plt.plot(reconstructed[0].cpu().detach().numpy(), label='Reconstructed')\n",
    "            plt.legend()\n",
    "            plt.title(f'Reconstruction Example for Experiment {i}')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"#####################################################\")\n",
    "        except ValueError as e:\n",
    "            if \"Latent dimension is not defined in the model\" in str(e):\n",
    "                print(\"Skipping due to undefined latent dimension.\")\n",
    "            else:\n",
    "                raise e\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "        finally:\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
