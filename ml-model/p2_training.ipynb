{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 Unsupervised & Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import os\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterable Data and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_search_param_grid(archtype=\"ANN\", searchkey=\"learning_rate\"):\n",
    "    # Possible activations\n",
    "    activations = [\"linear\", \"relu\", \"sigmoid\", \"tanh\", \"lrelu\"]\n",
    "    lin_activations = [\"linear\", \"relu\", \"lrelu\"]\n",
    "    nonlin_activations = [\"sigmoid\", \"tanh\"]\n",
    "    # Generate all combinations\n",
    "    encoder_combinations = [\n",
    "        [first, second, first]\n",
    "        for first, second in product(lin_activations, nonlin_activations)\n",
    "    ]\n",
    "    decoder_combinations = [\n",
    "        [first, second, third]\n",
    "        for first, second, third in product(lin_activations, nonlin_activations, activations)\n",
    "    ]\n",
    "    # Grid Search Parameters\n",
    "    p_griddy_ANN = {\n",
    "        \"unit-test\": {\n",
    "            \"learning_rate\": [0.01],\n",
    "            \"batch_size\": [32],\n",
    "            \"epochs\": [1],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"layer_PE_nodes\": [[2**13, 64, 10]],\n",
    "            \"layer_PE_activations\": [[\"linear\", \"linear\", \"softmax\"]],\n",
    "            \"loss\": [\"CE\"]\n",
    "        },\n",
    "        # In Order...\n",
    "        \"learning_rate\": {\n",
    "            \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [256],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"layer_PE_nodes\": [[2**11, 128, 64, 10]],\n",
    "            \"layer_PE_activations\": [[\"lrelu\", \"lrelu\", \"lrelu\", \"softmax\"]],\n",
    "            \"loss\": [\"CE\"]\n",
    "        },\n",
    "        # \"dropout_rate\": {\n",
    "        #     \"learning_rate\": [0.01],\n",
    "        #     \"batch_size\": [32],\n",
    "        #     \"epochs\": [256],\n",
    "        #     \"dropout_rate\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        #     \"input_size\": [784],\n",
    "        #     \"layer_PE_nodes\": [[2**11, 128, 64, 10]],\n",
    "        #     \"layer_PE_activations\": [[\"lrelu\", \"lrelu\", \"lrelu\", \"softmax\"]],\n",
    "        #     \"loss\": [\"CE\"]\n",
    "        # },\n",
    "        # \"layer_PE_activations\": {\n",
    "        #     \"learning_rate\": [0.01],\n",
    "        #     \"batch_size\": [32],\n",
    "        #     \"epochs\": [256],\n",
    "        #     \"dropout_rate\": [0.0],\n",
    "        #     \"input_size\": [784],\n",
    "        #     \"layer_PE_nodes\": [[2**11, 128, 64, 10]],\n",
    "        #     \"layer_PE_activations\": [[\"linear\", \"relu\", \"softmax\"], [\"linear\", \"sigmoid\", \"softmax\"], [\"linear\", \"tanh\", \"softmax\"], [\"linear\", \"lrelu\", \"softmax\"]],\n",
    "        #     \"loss\": [\"CE\"]\n",
    "        # },\n",
    "    }\n",
    "    p_griddy_SAE = {\n",
    "        \"unit-test\": {\n",
    "            \"learning_rate\": [0.01],\n",
    "            \"batch_size\": [32],\n",
    "            \"epochs\": [1],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            'loss': ['MSE'],\n",
    "            '_lambda': [0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        # In Order...\n",
    "        \"learning_rate\": {\n",
    "            \"learning_rate\": [2**-30, 2**-28, 2**-26, 2**-24, 2**-22, 2**-20, 2**-18, 2**-16, 2**-14, 2**-12, 2**-10, 2**-8, 2**-6, 2**-4],\n",
    "            \"batch_size\": [256],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            'loss': ['MSE'],\n",
    "            '_lambda': [0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"dropout_rate\": {\n",
    "            \"learning_rate\": [0.01],\n",
    "            \"batch_size\": [256],\n",
    "            \"epochs\": [256],\n",
    "            \"dropout_rate\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            'loss': ['MSE'],\n",
    "            '_lambda': [0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"layer_PE_activations\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [256],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": encoder_combinations,\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": decoder_combinations,\n",
    "            'loss': ['MSE'],\n",
    "            '_lambda': [0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"code_length\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10+4*k] for k in range(30)],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\" , \"sigmoid\"]],\n",
    "            'loss': ['MSE'],\n",
    "            '_lambda': [2**-6],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"_lambda\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [256],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-20, 2**-19, 2**-18, 2**-17, 2**-16, 2**-15, 2**-14, 2**-13, 2**-12, 2**-11, 2**-10, 2**-9, 2**-8, 2**-7, 2**-6, 2**-5, 2**-4, 2**-3, 2**-2, 2**-1, 2**0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"norm_type\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [256],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-12],\n",
    "            'norm_type': [0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4],\n",
    "        },\n",
    "        \"3d_grid\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [32, 64, 128, 256, 512],\n",
    "            \"epochs\": [2048],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-10, 2**-9, 2**-8, 2**-7, 2**-6, 2**-5, 2**-4, 2**-3, 2**-2, 2**-1, 2**0],\n",
    "            'norm_type': [1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5],\n",
    "        }\n",
    "    }\n",
    "    p_griddy_SAEANN = {\n",
    "        \"unit-test\": {\n",
    "            \"learning_rate\": [0.01],\n",
    "            \"batch_size\": [32],\n",
    "            \"epochs\": [1],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**6, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [1],\n",
    "        },\n",
    "        # In Order...\n",
    "        \"learning_rate\": {\n",
    "            \"learning_rate\": [2**-20, 2**-18, 2**-16, 2**-14, 2**-12, 2**-10, 2**-8, 2**-6, 2**-4],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**6, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [1],\n",
    "        },\n",
    "        \"dropout_rate\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.0, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**6, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [1],\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [32, 64, 128, 256, 512],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**6, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [1],\n",
    "        },\n",
    "        \"_lambda\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**6, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [2**-12, 2**-10, 2**-8, 2**-6, 2**-4, 2**-2, 2**0, 2**2, 2**4],\n",
    "        },\n",
    "        \"code_length\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10+4*k] for k in range(30)],\n",
    "            \"encoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**6, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [1],\n",
    "        },\n",
    "        \"3d_grid\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [32, 64, 128, 256, 512],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10+4*k] for k in range(20)],\n",
    "            \"encoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"lrelu\", \"lrelu\", \"sigmoid\"]],\n",
    "            'loss': ['CE'],\n",
    "            \"sae_model_path\": [None],  # Update with actual path\n",
    "            \"freeze_encoder\": [False],  # Option to freeze or fine-tune the encoder\n",
    "            \"layer_PE_nodes\": [[2**7, 10]],\n",
    "            \"layer_PE_activations\": [[\"relu\", \"softmax\"]],\n",
    "            \"_lambda\": [2**-12, 2**-10, 2**-8, 2**-6, 2**-4, 2**-2, 2**0, 2**2, 2**4],\n",
    "        },\n",
    "        # ... Add other hyperparameters if needed\n",
    "    }\n",
    "    p_griddy_VAE = {\n",
    "        \"unit-test\": {\n",
    "            \"learning_rate\": [0.01],\n",
    "            \"batch_size\": [32],\n",
    "            \"epochs\": [5],\n",
    "            \"dropout_rate\": [0.0],\n",
    "            \"input_size\": [784],\n",
    "            \"latent_dim\": [10],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"linear\", \"linear\", \"linear\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"linear\", \"linear\", \"sigmoid\"]],\n",
    "            'loss': ['MSE'],\n",
    "            '_lambda': [0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        # In Order...\n",
    "        \"learning_rate\": {\n",
    "            \"learning_rate\": [2**-30, 2**-28, 2**-26, 2**-24, 2**-22, 2**-20, 2**-18, 2**-16, 2**-14, 2**-12, 2**-10, 2**-8, 2**-6, 2**-4],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"latent_dim\": [10],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-12],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"dropout_rate\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5],\n",
    "            \"input_size\": [784],\n",
    "            \"latent_dim\": [10],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-12],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"layer_PE_activations\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"latent_dim\": [10],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": encoder_combinations,\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": decoder_combinations,\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-12],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"_lambda\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"latent_dim\": [10],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-20, 2**-19, 2**-18, 2**-17, 2**-16, 2**-15, 2**-14, 2**-13, 2**-12, 2**-11, 2**-10, 2**-9, 2**-8, 2**-7, 2**-6, 2**-5, 2**-4, 2**-3, 2**-2, 2**-1, 2**0],\n",
    "            'norm_type': [2]\n",
    "        },\n",
    "        \"norm_type\": {\n",
    "            \"learning_rate\": [2**-10],\n",
    "            \"batch_size\": [128],\n",
    "            \"epochs\": [1024],\n",
    "            \"dropout_rate\": [0.1],\n",
    "            \"input_size\": [784],\n",
    "            \"latent_dim\": [10],\n",
    "            \"encoder_PE_nodes\": [[800, 200, 10]],\n",
    "            \"encoder_PE_activations\": [[\"relu\", \"sigmoid\", \"relu\"]],\n",
    "            \"decoder_PE_nodes\": [[200, 800, 784]],\n",
    "            \"decoder_PE_activations\": [[\"relu\", \"sigmoid\", \"sigmoid\"]],\n",
    "            'loss': ['custom'],\n",
    "            '_lambda': [2**-12],\n",
    "            'norm_type': [0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4],\n",
    "        },\n",
    "    }\n",
    "    # If just keys are needed\n",
    "    if archtype == \"ANN\" and searchkey == None:\n",
    "        return p_griddy_ANN.keys()\n",
    "    elif archtype == \"SAE\" and searchkey == None:\n",
    "        return p_griddy_SAE.keys()\n",
    "    elif archtype == \"SAEANN\" and searchkey == None:\n",
    "        return p_griddy_SAEANN.keys()\n",
    "    elif archtype == \"VAE\" and searchkey == None:\n",
    "        return p_griddy_VAE.keys()\n",
    "    # If the search grids are needed\n",
    "    elif archtype == \"ANN\" and searchkey in p_griddy_ANN:\n",
    "        return p_griddy_ANN[searchkey]\n",
    "    elif archtype == \"SAE\" and searchkey in p_griddy_SAE:\n",
    "        return p_griddy_SAE[searchkey]\n",
    "    elif archtype == \"SAEANN\" and searchkey in p_griddy_SAEANN:\n",
    "        return p_griddy_SAEANN[searchkey]\n",
    "    elif archtype == \"VAE\" and searchkey in p_griddy_VAE:\n",
    "        return p_griddy_VAE[searchkey]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported archtype '{archtype}' or hyperparameter '{searchkey}'.\")\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    tr_X = np.load('kmnist-train-imgs.npz')['arr_0']\n",
    "    tr_Y = np.load('kmnist-train-labels.npz')['arr_0']\n",
    "    ts_X = np.load('kmnist-test-imgs.npz')['arr_0']\n",
    "    ts_Y = np.load('kmnist-test-labels.npz')['arr_0']\n",
    "    \n",
    "    # Normalize Data\n",
    "    tr_X = tr_X / 255.0\n",
    "    ts_X = ts_X / 255.0\n",
    "    \n",
    "    # Do not one-hot encode labels\n",
    "    return tr_X, tr_Y, ts_X, ts_Y\n",
    "\n",
    "def train_val_split(X, Y, val_size=0.2):\n",
    "    '''\n",
    "    Split data into training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - X: input data (n_samples, n_features)\n",
    "    - Y: true output (n_samples, n_output)\n",
    "    - val_size: fraction of the dataset to be used as validation (default: 0.2)\n",
    "\n",
    "    Returns:\n",
    "    - X_train, Y_train: training data\n",
    "    - X_val, Y_val: validation data\n",
    "    '''\n",
    "    n_samples = X.shape[0]\n",
    "    split_idx = int(n_samples * (1 - val_size))\n",
    "    \n",
    "    # Shuffle the data\n",
    "    perm = np.random.permutation(n_samples)\n",
    "    X_shuffled, Y_shuffled = X[perm], Y[perm]\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    X_train, Y_train = X_shuffled[:split_idx], Y_shuffled[:split_idx]\n",
    "    X_val, Y_val = X_shuffled[split_idx:], Y_shuffled[split_idx:]\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def split_by_class(X, Y):\n",
    "    '''\n",
    "    Split data by class label.\n",
    "\n",
    "    Parameters:\n",
    "    - X: input data (n_samples, n_features)\n",
    "    - Y: true output (n_samples, n_output)\n",
    "\n",
    "    Returns:\n",
    "    - class_data: dictionary where keys are class labels and values are tuples (X_class, Y_class)\n",
    "    '''\n",
    "    class_data = {}\n",
    "    for i in range(10):\n",
    "        class_data[i] = (X[Y == i], Y[Y == i])\n",
    "    return class_data\n",
    "\n",
    "def split_data(X, Y, k, seed=0):\n",
    "    '''\n",
    "    Split data into k folds for cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - X: input data (n_samples, n_features)\n",
    "    - Y: true output (n_samples, n_output)\n",
    "    - k: number of folds\n",
    "    \n",
    "    Returns:\n",
    "    - folds: list of tuples, where each tuple contains (X_train, Y_train, X_val, Y_val)\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    n_samples = X.shape[0]\n",
    "    fold_size = n_samples // k\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        val_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "        \n",
    "        X_train, Y_train = X[train_indices], Y[train_indices]\n",
    "        X_val, Y_val = X[val_indices], Y[val_indices]\n",
    "        folds.append((X_train, Y_train, X_val, Y_val))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurableANN(nn.Module):\n",
    "    \"\"\"\n",
    "    Configurable Artificial Neural Network (ANN) implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(ConfigurableANN, self).__init__()\n",
    "        layers = []\n",
    "        input_size = config['input_size']\n",
    "        \n",
    "        # Extract layer configurations from the config dictionary\n",
    "        layer_PE_nodes = config['layer_PE_nodes']  # Assuming the first (or only) list of nodes\n",
    "        layer_PE_activations = config['layer_PE_activations']  # Assuming the first (or only) list of activations\n",
    "\n",
    "        # Add fully connected layers\n",
    "        for i, units in enumerate(layer_PE_nodes):\n",
    "            layers.append(nn.Linear(input_size, units))\n",
    "            layers.append(nn.BatchNorm1d(units))\n",
    "            layers.append(self._get_activation(layer_PE_activations[i]))\n",
    "            if 'dropout_rate' in config and config['dropout_rate'] > 0:\n",
    "                layers.append(nn.Dropout(config['dropout_rate']))\n",
    "            input_size = units\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def _get_activation(self, activation_name):\n",
    "        \"\"\"\n",
    "        Helper method to return the activation function based on the name.\n",
    "        \"\"\"\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"linear\": nn.Identity(),\n",
    "            \"softmax\": nn.Softmax(dim=1),\n",
    "            \"lrelu\": nn.LeakyReLU()\n",
    "        }\n",
    "        return activations.get(activation_name.lower(), nn.Identity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, config, device='cuda'):\n",
    "        \"\"\"\n",
    "        Train the ANN model using the given configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=config['learning_rate'])\n",
    "        patience = 16\n",
    "        best_val_loss = np.inf\n",
    "        \n",
    "        # Training loop\n",
    "        train_losses, val_losses = [], []\n",
    "        for epoch in range(config['epochs']):\n",
    "            super().train()\n",
    "            train_loss = 0.0\n",
    "            for i, (inputs, targets) in enumerate(train_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "            # Validation loss\n",
    "            super().eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    inputs = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "                    outputs = self(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_loss += loss.item()\n",
    "                val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "            # Early stopping\n",
    "            if epoch > 0 and val_losses[-1] > best_val_loss:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print(f\"Early stopping at epoch {epoch+1} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "                    break\n",
    "            else:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                patience = 16\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 16 == 15:\n",
    "                print(f\"Epoch {epoch+1}/{config['epochs']} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def predict(self, X, device='cuda'):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        X_tensor = X_tensor.view(X_tensor.size(0), -1)  # Flatten the input\n",
    "        with torch.no_grad():\n",
    "            outputs = self(X_tensor)\n",
    "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the given data.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        X, Y = val_loader.dataset.tensors\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        X = X.view(X.size(0), -1)  # Flatten the input\n",
    "        with torch.no_grad():\n",
    "            outputs = self(X)\n",
    "            loss = criterion(outputs, Y).item()\n",
    "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            Y = Y.cpu().numpy()\n",
    "            accuracy = (predictions == Y).mean()\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Save the model to the given path.\n",
    "        \"\"\"\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        Load the model from the given path.\n",
    "        \"\"\"\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "class ConfigurableSAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Configurable Stacked Autoencoder implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(ConfigurableSAE, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self._lambda = config.get('_lambda', 0.0)\n",
    "        self.norm_type = config.get('norm_type', 2)  # Default to L2 norm\n",
    "        dropout_rate = config.get('dropout_rate', 0.0)\n",
    "\n",
    "        # Extract encoder configuration\n",
    "        encoder_PE_nodes = config['encoder_PE_nodes']\n",
    "        encoder_PE_activations = config['encoder_PE_activations']\n",
    "\n",
    "        # Build encoder layers\n",
    "        input_size = config['input_size']\n",
    "        for i, units in enumerate(encoder_PE_nodes):\n",
    "            self.encoder.append(nn.Linear(input_size, units))\n",
    "            self.encoder.append(nn.BatchNorm1d(units))\n",
    "            self.encoder.append(self._get_activation(encoder_PE_activations[i]))\n",
    "            if dropout_rate > 0:\n",
    "                self.encoder.append(nn.Dropout(dropout_rate))\n",
    "            input_size = units  # Update for the next layer\n",
    "\n",
    "        # Latent representation\n",
    "        self.code_size = encoder_PE_nodes[-1]\n",
    "\n",
    "        # Extract decoder configuration\n",
    "        decoder_PE_nodes = config['decoder_PE_nodes']\n",
    "        decoder_PE_activations = config['decoder_PE_activations']\n",
    "\n",
    "        # Build decoder layers\n",
    "        for i, units in enumerate(decoder_PE_nodes):\n",
    "            self.decoder.append(nn.Linear(input_size, units))\n",
    "            self.decoder.append(nn.BatchNorm1d(units))\n",
    "            self.decoder.append(self._get_activation(decoder_PE_activations[i]))\n",
    "            if dropout_rate > 0:\n",
    "                self.decoder.append(nn.Dropout(dropout_rate))\n",
    "            input_size = units  # Update for the next layer\n",
    "\n",
    "    def _get_activation(self, activation_name):\n",
    "        \"\"\"\n",
    "        Helper method to return the activation function based on the name.\n",
    "        \"\"\"\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"linear\": nn.Identity(),\n",
    "            \"softmax\": nn.Softmax(dim=1),\n",
    "            \"lrelu\": nn.LeakyReLU()\n",
    "        }\n",
    "        return activations.get(activation_name.lower(), nn.Identity())\n",
    "\n",
    "    def encode(self, x, device='cuda'):\n",
    "        \"\"\"\n",
    "        Encode the input data.\n",
    "        \"\"\"\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, device='cuda'):\n",
    "        \"\"\"\n",
    "        Decode the latent representation.\n",
    "        \"\"\"\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the SAE model.\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.encode(x) # Encode the input\n",
    "        self.codes = x     # Save the latent representation\n",
    "        x = self.decode(x) # Decode the latent representation\n",
    "\n",
    "        return x\n",
    "\n",
    "    def fit(self, train_loader, val_loader, config, device='cuda'):\n",
    "        \"\"\"\n",
    "        Train the SAE model using the given configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        if config['loss'] == 'MSE':\n",
    "            criterion = nn.MSELoss()\n",
    "        elif config['loss'] == 'custom':\n",
    "            criterion = scsae_loss\n",
    "        elif config['loss'] == 'CE':\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported loss function '{config['loss']}'\")\n",
    "        optimizer = optim.Adam(self.parameters(), lr=config['learning_rate'])\n",
    "        patience = 16\n",
    "        best_val_loss = np.inf\n",
    "        \n",
    "        # Training loop\n",
    "        train_losses, val_losses = [], []\n",
    "        for epoch in range(config['epochs']):\n",
    "            super().train()\n",
    "            train_loss = 0.0\n",
    "            for i, (inputs, targets) in enumerate(train_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                if config['loss'] == 'custom':\n",
    "                    loss = criterion(inputs, outputs, self.codes, targets, config['norm_type'], config['_lambda'])\n",
    "                else:\n",
    "                    loss = criterion(outputs, inputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "            # Validation loss\n",
    "            super().eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    inputs = inputs.view(inputs.size(0), -1)\n",
    "                    outputs = self(inputs)\n",
    "                    if config['loss'] == 'custom':\n",
    "                        loss = criterion(inputs, outputs, self.codes, targets, config['norm_type'], config['_lambda'])\n",
    "                    else:\n",
    "                        loss = criterion(outputs, inputs)\n",
    "                    val_loss += loss.item()\n",
    "                val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "            # Early stopping\n",
    "            if epoch > 0 and val_losses[-1] > best_val_loss:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print(f\"Early stopping at epoch {epoch+1} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "                    break\n",
    "            else:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                patience = 16\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 16 == 15:\n",
    "                print(f\"Epoch {epoch+1}/{config['epochs']} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def predict(self, X, device='cuda'):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        X_tensor = X_tensor.view(X_tensor.size(0), -1)\n",
    "        with torch.no_grad():\n",
    "            outputs = self(X_tensor)\n",
    "            predictions = outputs.cpu().numpy()\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_reconstruction(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the given data.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        criterion = nn.MSELoss()\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                total_samples += inputs.size(0)\n",
    "        avg_loss = total_loss / total_samples\n",
    "        return avg_loss\n",
    "    \n",
    "    def evaluate_code(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the given data.\n",
    "        Returns:\n",
    "            avg_loss: Average MSE loss between codes and one-hot encoded labels.\n",
    "            avg_accuracy: Classification accuracy based on codes.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        criterion = nn.MSELoss()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                codes = self.encode(inputs)\n",
    "                labels_onehot = F.one_hot(labels, num_classes=self.code_size).float()\n",
    "                loss = criterion(codes, labels_onehot)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                total_samples += inputs.size(0)\n",
    "                predictions = torch.argmax(codes, dim=1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_accuracy = correct / total_samples\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "    def evaluate(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using evaluate_reconstruction and evaluate_code.\n",
    "        \"\"\"\n",
    "        avg_reconstruction_loss = self.evaluate_reconstruction(val_loader, device)\n",
    "        avg_code_loss, avg_accuracy = self.evaluate_code(val_loader, device)\n",
    "        return avg_reconstruction_loss + avg_code_loss, avg_accuracy\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Save the model to the given path.\n",
    "        \"\"\"\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        Load the model from the given path.\n",
    "        \"\"\"\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "class ConfigurableSAEANN(nn.Module):\n",
    "    \"\"\"\n",
    "    Configurable Stacked Autoencoder - Artificial Neural Network (SAE-ANN) implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, sae_model_path, config, ann_model_path=None, freeze_encoder=False, device='cuda'):\n",
    "        super(ConfigurableSAEANN, self).__init__()\n",
    "        \n",
    "        if sae_model_path is not(None):\n",
    "            # Load the SAE checkpoint\n",
    "            checkpoint = torch.load(sae_model_path, map_location=device)\n",
    "            sae_state_dict = checkpoint['model_state_dict']\n",
    "            sae_config = checkpoint['config']  # Load the saved configuration\n",
    "            \n",
    "            # Initialize the SAE model with the loaded configuration\n",
    "            self.sae_model = ConfigurableSAE(sae_config).to(device)\n",
    "            self.sae_model.load_state_dict(sae_state_dict)\n",
    "        else:\n",
    "            self.sae_model = self._build_sae(config)\n",
    "        \n",
    "        # Optionally freeze the encoder\n",
    "        if freeze_encoder:\n",
    "            for param in self.sae_model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Initialize the ANN classifier\n",
    "        self.classifier = self._build_classifier(config)\n",
    "        \n",
    "        # Optionally load ANN classifier weights\n",
    "        if ann_model_path is not None:\n",
    "            self.classifier.load_state_dict(torch.load(ann_model_path, map_location=device))\n",
    "\n",
    "    def _build_sae(self, config):\n",
    "        \"\"\"\n",
    "        Builds the SAE part of the SAE-ANN based on the configuration.\n",
    "        \"\"\"\n",
    "        return ConfigurableSAE(config)\n",
    "\n",
    "    def _build_classifier(self, config):\n",
    "        \"\"\"\n",
    "        Builds the classifier part of the ANN based on the configuration.\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        input_size = config['encoder_PE_nodes'][-1]  # Should match the encoder's output size\n",
    "        layer_PE_nodes = config['layer_PE_nodes']\n",
    "        layer_PE_activations = config['layer_PE_activations']\n",
    "        \n",
    "        for i, units in enumerate(layer_PE_nodes):\n",
    "            layers.append(nn.Linear(input_size, units))\n",
    "            layers.append(nn.BatchNorm1d(units))\n",
    "            layers.append(self._get_activation(layer_PE_activations[i]))\n",
    "            if 'dropout_rate' in config and config['dropout_rate'] > 0:\n",
    "                layers.append(nn.Dropout(config['dropout_rate']))\n",
    "            input_size = units\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _get_activation(self, activation_name):\n",
    "        \"\"\"\n",
    "        Helper method to return the activation function based on the name.\n",
    "        \"\"\"\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"linear\": nn.Identity(),\n",
    "            \"softmax\": nn.Softmax(dim=1),\n",
    "            \"lrelu\": nn.LeakyReLU()\n",
    "        }\n",
    "        return activations.get(activation_name.lower(), nn.Identity())\n",
    "\n",
    "    def forward(self, x, device='cuda'):\n",
    "        # Encoder pass\n",
    "        codes = self.sae_model.encode(x)\n",
    "        classification = self.classifier(codes)\n",
    "        reconstruction = self.sae_model.decode(codes)\n",
    "        return classification, reconstruction\n",
    "\n",
    "    def freeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def fit(self, train_loader, val_loader, config, device='cuda'):\n",
    "        \"\"\"\n",
    "        Train the SAE-ANN model in two stages per epoch: classification and reconstruction.\n",
    "        \"\"\"\n",
    "        self.to(device)\n",
    "        criterion_classification = nn.CrossEntropyLoss()\n",
    "        optimizer_classifier = optim.Adam(\n",
    "            list(self.classifier.parameters()) + list(self.sae_model.encoder.parameters()), \n",
    "            lr=config['learning_rate']\n",
    "        )\n",
    "        \n",
    "        criterion_reconstruction = nn.MSELoss()\n",
    "        optimizer_reconstruction = optim.Adam(\n",
    "            list(self.sae_model.decoder.parameters()) + list(self.sae_model.encoder.parameters()), \n",
    "            lr=config['learning_rate']\n",
    "        )\n",
    "        patience = 16\n",
    "        best_val_loss = np.inf\n",
    "        _lambda = config.get('_lambda', 1.0)\n",
    "        \n",
    "        train_losses, val_losses = [], []\n",
    "        for epoch in range(config['epochs']):\n",
    "            super().train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            # Classification phase\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                optimizer_classifier.zero_grad()\n",
    "                classification, _ = self(inputs)\n",
    "                loss_classification = _lambda*criterion_classification(classification, targets)\n",
    "                loss_classification.backward()\n",
    "                optimizer_classifier.step()\n",
    "                train_loss += loss_classification.item()\n",
    "\n",
    "            # Reconstruction phase\n",
    "            for inputs, _ in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                optimizer_reconstruction.zero_grad()\n",
    "                _, reconstruction = self(inputs)\n",
    "                loss_reconstruction = criterion_reconstruction(reconstruction, inputs)\n",
    "                loss_reconstruction.backward()\n",
    "                optimizer_reconstruction.step()\n",
    "                train_loss += loss_reconstruction.item()\n",
    "\n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "            # Validation phase\n",
    "            super().eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    inputs = inputs.view(inputs.size(0), -1)\n",
    "                    classification, reconstruction = self(inputs)\n",
    "                    loss_classification = criterion_classification(classification, targets)\n",
    "                    loss_reconstruction = criterion_reconstruction(reconstruction, inputs)\n",
    "                    val_loss += loss_classification.item() + loss_reconstruction.item()\n",
    "                val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "            # Early stopping\n",
    "            if epoch > 0 and val_losses[-1] > best_val_loss:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print(f\"Early stopping at epoch {epoch+1} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "                    break\n",
    "            else:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                patience = 16\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 16 == 15:\n",
    "                print(f\"Epoch {epoch+1}/{config['epochs']} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def predict(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                codes = self.sae_model.encode(inputs)  # Pass inputs through encoder\n",
    "                outputs = self.classifier(codes)  # Classify using the ANN\n",
    "                batch_predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                predictions.extend(batch_predictions)\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the given data.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        criterion_classification = nn.CrossEntropyLoss()\n",
    "        criterion_reconstruction = nn.MSELoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                codes = self.sae_model.encode(inputs)  # Pass inputs through encoder\n",
    "                classification = self.classifier(codes)  # Classify using the ANN\n",
    "                reconstruction = self.sae_model.decode(codes)  # Reconstruct the input\n",
    "                loss = criterion_classification(classification, targets) + criterion_reconstruction(reconstruction, inputs)\n",
    "                total_loss += loss.item()\n",
    "                predictions = torch.argmax(classification, dim=1)\n",
    "                correct += (predictions == targets).sum().item()\n",
    "                total_samples += targets.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        accuracy = correct / total_samples\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Save the model to the given path.\n",
    "        \"\"\"\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        Load the model from the given path.\n",
    "        \"\"\"\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "class ConfigurableVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Configurable Variational Autoencoder (VAE) implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(ConfigurableVAE, self).__init__()\n",
    "        \n",
    "        # Encoder configurations\n",
    "        input_size = config[\"input_size\"]\n",
    "        encoder_PE_nodes = config[\"encoder_PE_nodes\"]\n",
    "        encoder_PE_activations = config[\"encoder_PE_activations\"]\n",
    "        self.latent_dim = config[\"latent_dim\"]\n",
    "        \n",
    "        # Decoder configurations\n",
    "        decoder_PE_nodes = config[\"decoder_PE_nodes\"]\n",
    "        decoder_PE_activations = config[\"decoder_PE_activations\"]\n",
    "\n",
    "\n",
    "        # Build encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for i, units in enumerate(encoder_PE_nodes):\n",
    "            self.encoder.append(nn.Linear(input_size, units))\n",
    "            self.encoder.append(self._get_activation(encoder_PE_activations[i]))\n",
    "            input_size = units\n",
    "        \n",
    "        # Latent space\n",
    "        self.mu_layer = nn.Linear(input_size, self.latent_dim)\n",
    "        self.logvar_layer = nn.Linear(input_size, self.latent_dim)\n",
    "        \n",
    "        # Build decoder\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i, units in enumerate(decoder_PE_nodes):\n",
    "            self.decoder.append(nn.Linear(self.latent_dim, units))\n",
    "            self.decoder.append(self._get_activation(decoder_PE_activations[i]))\n",
    "            self.latent_dim = units\n",
    "    \n",
    "    def _get_activation(self, activation_name):\n",
    "        \"\"\"\n",
    "        Helper method to return the activation function based on the name.\n",
    "        \"\"\"\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"linear\": nn.Identity(),\n",
    "            \"softmax\": nn.Softmax(dim=1),\n",
    "            \"lrelu\": nn.LeakyReLU()\n",
    "        }\n",
    "        return activations.get(activation_name.lower(), nn.Identity())\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encoder pass: compute latent mean and log-variance.\n",
    "        \"\"\"\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        mu = self.mu_layer(x)\n",
    "        logvar = self.logvar_layer(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) using N(0, 1).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decoder pass: reconstruct input from latent space.\n",
    "        \"\"\"\n",
    "        for layer in self.decoder:\n",
    "            z = layer(z)\n",
    "\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Full VAE forward pass.\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "    def fit(self, train_loader, val_loader, config, device='cuda'):\n",
    "        \"\"\"\n",
    "        Train the VAE model using the given configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        optimizer = optim.Adam(self.parameters(), lr=config['learning_rate'])\n",
    "        best_val_loss = np.inf\n",
    "        \n",
    "        # Training loop\n",
    "        train_losses, val_losses = [], []\n",
    "        for epoch in range(config['epochs']):\n",
    "            super().train()\n",
    "            train_loss = 0.0\n",
    "            for i, (inputs, _) in enumerate(train_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "                optimizer.zero_grad()\n",
    "                recon_x, mu, logvar = self(inputs)\n",
    "                loss = vae_loss(recon_x, inputs, mu, logvar)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "            # Validation loss\n",
    "            super().eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, _ in val_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    inputs = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "                    recon_x, mu, logvar = self(inputs)\n",
    "                    loss = vae_loss(recon_x, inputs, mu, logvar)\n",
    "                    val_loss += loss.item()\n",
    "                val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "            # Early stopping\n",
    "            if epoch > 0 and val_losses[-1] > best_val_loss:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print(f\"Early stopping at epoch {epoch+1} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "                    break\n",
    "            else:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                patience = 16\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 16 == 15:\n",
    "                print(f\"Epoch {epoch+1}/{config['epochs']} - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "        return train_losses, val_losses\n",
    "    \n",
    "    def predict(self, X, device='cuda'):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs, _, _ = self(X_tensor)\n",
    "            predictions = outputs.cpu().numpy()\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_reconstruction(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the given data.\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                recon_x, mu, logvar = self(inputs)\n",
    "                loss = nn.MSELoss()(recon_x, inputs).item()\n",
    "                total_loss += loss\n",
    "                total_samples += inputs.size(0)\n",
    "        avg_loss = total_loss / total_samples\n",
    "        return avg_loss\n",
    "    \n",
    "    def evaluate_code(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the given data.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)  # Ensure labels are on the correct device\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                _, mu, logvar = self(inputs)\n",
    "                z = self.reparameterize(mu, logvar)\n",
    "                outputs = self.decode(z)\n",
    "                loss = nn.MSELoss()(outputs, inputs)\n",
    "                total_loss += loss.item() * inputs.size(0)  # Multiply by batch size if needed\n",
    "                total_samples += inputs.size(0)\n",
    "                predictions = torch.argmax(z, dim=1)\n",
    "                correct += (predictions == labels).float().sum().item()  # Convert to float before summing\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_accuracy = correct / total_samples\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "    def evaluate(self, val_loader, device='cuda'):\n",
    "        \"\"\"\n",
    "        Evaluate the model using evaluate_reconstruction and evaluate_code.\n",
    "        \"\"\"\n",
    "        avg_reconstruction_loss = self.evaluate_reconstruction(val_loader, device)\n",
    "        avg_code_loss, accuracy = self.evaluate_code(val_loader, device)\n",
    "        return avg_reconstruction_loss + avg_code_loss, accuracy\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Save the model to the given path.\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'config': {\n",
    "                'input_size': self.input_size,\n",
    "                'encoder_PE_nodes': self.encoder_PE_nodes,\n",
    "                'encoder_PE_activations': self.encoder_PE_activations,\n",
    "                'latent_dim': self.latent_dim,\n",
    "                'decoder_PE_nodes': self.decoder_PE_nodes,\n",
    "                'decoder_PE_activations': self.decoder_PE_activations,\n",
    "                'output_size': self.output_size,\n",
    "                'output_activation': self.output_activation\n",
    "            }\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        Load the model from the given path.\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(path)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.input_size = checkpoint['config']['input_size']\n",
    "        self.encoder_PE_nodes = checkpoint['config']['encoder_PE_nodes']\n",
    "        self.encoder_PE_activations = checkpoint['config']['encoder_PE_activations']\n",
    "        self.latent_dim = checkpoint['config']['latent_dim']\n",
    "        self.decoder_PE_nodes = checkpoint['config']['decoder_PE_nodes']\n",
    "        self.decoder_PE_activations = checkpoint['config']['decoder_PE_activations']\n",
    "        self.output_size = checkpoint['config']['output_size']\n",
    "        self.output_activation = checkpoint['config']['output_activation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    VAE Loss: Reconstruction + KL Divergence.\n",
    "    \"\"\"\n",
    "    recon_loss = nn.MSELoss()(recon_x, x)\n",
    "    kl_divergence = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_divergence\n",
    "\n",
    "def scsae_loss(inputs, outputs, codes, targets, norm_type=2, _lambda=0.0):\n",
    "    \"\"\"\n",
    "    Custom loss function for Stacked Autoencoders with adjustable sparsity norm and lambda.\n",
    "    \"\"\"\n",
    "    # Reconstruction loss\n",
    "    recon_loss = nn.MSELoss()(outputs, inputs)\n",
    "    \n",
    "    # Convert targets to one-hot encoding\n",
    "    labels_onehot = F.one_hot(targets, num_classes=codes.shape[1]).float()\n",
    "    \n",
    "    # Ensure labels_onehot is on the same device as codes\n",
    "    labels_onehot = labels_onehot.to(codes.device)\n",
    "    \n",
    "    # Sparsity penalty\n",
    "    sparsity_loss = torch.mean(torch.norm(codes - labels_onehot, p=norm_type, dim=1))\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = recon_loss + _lambda * sparsity_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Information Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(train_data, val_data, param_grid, model_class, search_key, reps=5, metric=\"loss\", device='cuda', save_path=\"./\"):\n",
    "    \"\"\"\n",
    "    Perform grid search to find the best hyperparameters for a given model class.\n",
    "    \"\"\"\n",
    "    param_keys = list(param_grid.keys())\n",
    "    param_values = [param_grid[key] for key in param_keys]\n",
    "    param_combinations = [dict(zip(param_keys, v)) for v in product(*param_values)]\n",
    "    results = []\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    # Create Save Path\n",
    "    folder_path = os.path.join(save_path, search_key)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    # Initialize best score and comparison function\n",
    "    if metric == \"loss\":\n",
    "        best_score = float('inf')\n",
    "        score_compare = lambda new, best: new < best\n",
    "    elif metric == \"accuracy\":\n",
    "        best_score = float('-inf')\n",
    "        score_compare = lambda new, best: new > best\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported metric '{metric}'\")\n",
    "    # Define a lambda function to get the hyperparameter value\n",
    "    get_hyperparam_value = lambda params: params['encoder_PE_nodes'][-1] if search_key == 'code_length' else params.get(search_key)\n",
    "    # Check model class\n",
    "    if model_class == ConfigurableANN:\n",
    "        for params in param_combinations:\n",
    "            print(f\"Testing parameters: {params}\")\n",
    "            # Prepare DataLoaders\n",
    "            train_loader = DataLoader(train_data, batch_size=params.get('batch_size', 32), shuffle=True)\n",
    "            val_loader = DataLoader(val_data, batch_size=params.get('batch_size', 32), shuffle=False)\n",
    "            # Initialize lists to store losses and accuracies per repetition\n",
    "            reps_val_losses = []\n",
    "            # Initialize lists to store final losses and accuracies\n",
    "            fin_losses = []\n",
    "            fin_accuracies = []\n",
    "            for i in range(reps):\n",
    "                # Instantiate the model\n",
    "                model = model_class(params).to(device)\n",
    "                # Train and evaluate model\n",
    "                train_losses, val_losses = model.fit(train_loader, val_loader, params, device)\n",
    "                val_loss, val_accuracy = model.evaluate(val_loader, device)\n",
    "                reps_val_losses.append(val_losses)\n",
    "                fin_losses.append(val_loss)\n",
    "                fin_accuracies.append(val_accuracy)\n",
    "                # Generate unique model filename\n",
    "                param_hash = hashlib.md5(str(params).encode()).hexdigest()[:8]\n",
    "                model_filename = os.path.join(folder_path, f\"ConfigurableANN_{search_key}_{i}_{val_losses[-1]:.4f}_{param_hash}.pth\")\n",
    "                # Save model weights\n",
    "                try:\n",
    "                    torch.save({'model_state_dict': model.state_dict(),'config': params}, model_filename)\n",
    "                    print(f\"Model saved to {model_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving model: {e}\")\n",
    "                # Record results\n",
    "                results.append({\n",
    "                    **params,\n",
    "                    search_key: get_hyperparam_value(params),\n",
    "                    'repetition': i,\n",
    "                    'val_loss': fin_losses[-1],\n",
    "                    'val_accuracy': fin_accuracies[-1],\n",
    "                    'model_filename': model_filename\n",
    "                })\n",
    "            max_length = max(len(vl) for vl in reps_val_losses)\n",
    "            reps_val_losses_padded = [np.pad(vl, (0, max_length - len(vl)), 'constant', constant_values=np.nan) for vl in reps_val_losses]\n",
    "            reps_val_losses_array = np.array(reps_val_losses_padded)\n",
    "            avg_val_losses = np.nanmean(reps_val_losses_array, axis=0)\n",
    "            std_val_losses = np.nanstd(reps_val_losses_array, axis=0)\n",
    "            # Save losses and accuracies\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableANN_avg_val_losses_{search_key}_{param_hash}.npy\"), avg_val_losses)\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableANN_std_val_losses_{search_key}_{param_hash}.npy\"), std_val_losses)\n",
    "            # Select score based on model type\n",
    "            score = np.mean(fin_losses) if metric == \"loss\" else np.mean(fin_accuracies)\n",
    "            # Update the best model\n",
    "            if score_compare(score, best_score):\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "        # Save results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(folder_path, f\"ConfigurableANN_results_{search_key}.csv\"), index=False)\n",
    "        return results_df, best_model, best_params\n",
    "    elif model_class == ConfigurableSAE:\n",
    "        for params in param_combinations:\n",
    "            print(f\"Testing parameters: {params}\")\n",
    "            # Prepare DataLoaders\n",
    "            train_loader = DataLoader(train_data, batch_size=params.get('batch_size', 32), shuffle=True)\n",
    "            val_loader = DataLoader(val_data, batch_size=params.get('batch_size', 32), shuffle=False)\n",
    "            # Initialize lists to store losses and accuracies per repetition\n",
    "            reps_val_losses = []\n",
    "            reps_val_accuracies = []\n",
    "            # Initialize lists to store final losses and accuracies\n",
    "            fin_losses = []\n",
    "            fin_accuracies = []\n",
    "            for i in range(reps):\n",
    "                # Instantiate the model\n",
    "                model = model_class(params).to(device)\n",
    "                # Train and evaluate model\n",
    "                train_losses, val_losses = model.fit(train_loader, val_loader, params, device)\n",
    "                reconstr_loss = model.evaluate_reconstruction(val_loader, device)\n",
    "                code_loss, code_accuracy = model.evaluate_code(val_loader, device)\n",
    "                reps_val_losses.append(val_losses)\n",
    "                fin_losses.append(code_loss + reconstr_loss)\n",
    "                fin_accuracies.append(code_accuracy)\n",
    "                # Generate unique model filename\n",
    "                param_hash = hashlib.md5(str(params).encode()).hexdigest()[:8]\n",
    "                model_filename = os.path.join(folder_path, f\"ConfigurableSAE_{search_key}_{i}_{val_losses[-1]:.4f}_{param_hash}.pth\")\n",
    "                # Save model weights\n",
    "                try:\n",
    "                    torch.save({'model_state_dict': model.state_dict(),'config': params}, model_filename)\n",
    "                    print(f\"Model saved to {model_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving model: {e}\")\n",
    "                # Get the hyperparameter value using the lambda function\n",
    "                hyperparam_value = get_hyperparam_value(params)\n",
    "                # Record results\n",
    "                results.append({\n",
    "                    **params,\n",
    "                    search_key: hyperparam_value,\n",
    "                    'repetition': i,\n",
    "                    'val_loss': val_losses[-1],\n",
    "                    'val_accuracy': fin_accuracies[-1],\n",
    "                    'model_filename': model_filename\n",
    "                })\n",
    "            max_length = max(len(vl) for vl in reps_val_losses)\n",
    "            reps_val_losses_padded = [np.pad(vl, (0, max_length - len(vl)), 'constant', constant_values=np.nan) for vl in reps_val_losses]\n",
    "            reps_val_losses_array = np.array(reps_val_losses_padded)\n",
    "            avg_val_losses = np.nanmean(reps_val_losses_array, axis=0)\n",
    "            std_val_losses = np.nanstd(reps_val_losses_array, axis=0)\n",
    "            # Save losses and accuracies\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableSAE_avg_val_losses_{search_key}_{param_hash}.npy\"), avg_val_losses)\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableSAE_std_val_losses_{search_key}_{param_hash}.npy\"), std_val_losses)\n",
    "            # Select score based on model type\n",
    "            score = np.mean(fin_losses)\n",
    "            # Update the best model\n",
    "            if score_compare(score, best_score):\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "        # Save results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(folder_path, f\"ConfigurableSAE_results_{search_key}.csv\"), index=False)\n",
    "        return results_df, best_model, best_params\n",
    "    \n",
    "    elif model_class == ConfigurableSAEANN:\n",
    "        for params in param_combinations:\n",
    "            print(f\"Testing parameters: {params}\")\n",
    "            # Prepare DataLoaders\n",
    "            train_loader = DataLoader(train_data, batch_size=params.get('batch_size', 32), shuffle=True)\n",
    "            val_loader = DataLoader(val_data, batch_size=params.get('batch_size', 32), shuffle=False)\n",
    "            # Initialize lists to store losses and accuracies per repetition\n",
    "            reps_val_losses = []\n",
    "            reps_val_accuracies = []\n",
    "            # Initialize lists to store final losses and accuracies\n",
    "            fin_losses = []\n",
    "            fin_accuracies = []\n",
    "            for i in range(reps):\n",
    "                # Instantiate the model\n",
    "                model = model_class(\n",
    "                    sae_model_path=params['sae_model_path'],\n",
    "                    config=params,\n",
    "                    ann_model_path=params.get('ann_model_path', None),\n",
    "                    freeze_encoder=params.get('freeze_encoder', True),\n",
    "                    device=device\n",
    "                ).to(device)\n",
    "                # Train and evaluate model\n",
    "                train_losses, val_losses = model.fit(train_loader, val_loader, params, device)\n",
    "                val_loss, val_accuracy = model.evaluate(val_loader, device)\n",
    "                reps_val_losses.append(val_losses)\n",
    "                fin_losses.append(val_loss)\n",
    "                fin_accuracies.append(val_accuracy)\n",
    "                # Generate unique model filename\n",
    "                param_hash = hashlib.md5(str(params).encode()).hexdigest()[:8]\n",
    "                model_filename = os.path.join(folder_path, f\"ConfigurableSAEANN_{search_key}_{i}_{val_loss:.4f}_{param_hash}.pth\")\n",
    "                # Save model weights\n",
    "                try:\n",
    "                    torch.save({'model_state_dict': model.state_dict(),'config': params}, model_filename)\n",
    "                    print(f\"Model saved to {model_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving model: {e}\")\n",
    "                # Get the hyperparameter value using the lambda function\n",
    "                hyperparam_value = get_hyperparam_value(params)\n",
    "                # Record results\n",
    "                results.append({\n",
    "                    **params,\n",
    "                    search_key: hyperparam_value,\n",
    "                    'repetition': i,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'model_filename': model_filename\n",
    "                })\n",
    "            max_length = max(len(vl) for vl in reps_val_losses)\n",
    "            reps_val_losses_padded = [np.pad(vl, (0, max_length - len(vl)), 'constant', constant_values=np.nan) for vl in reps_val_losses]\n",
    "            reps_val_losses_array = np.array(reps_val_losses_padded)\n",
    "            avg_val_losses = np.nanmean(reps_val_losses_array, axis=0)\n",
    "            std_val_losses = np.nanstd(reps_val_losses_array, axis=0)\n",
    "            # Save losses and accuracies\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableSAEANN_avg_val_losses_{search_key}_{param_hash}.npy\"), avg_val_losses)\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableSAEANN_std_val_losses_{search_key}_{param_hash}.npy\"), std_val_losses)\n",
    "            # Select score based on model type\n",
    "            score = np.mean(fin_losses)\n",
    "            # Update the best model\n",
    "            if score_compare(score, best_score):\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "        # Save results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(folder_path, f\"ConfigurableSAEANN_results_{search_key}.csv\"), index=False)\n",
    "        return results_df, best_model, best_params   \n",
    "     \n",
    "    elif model_class == ConfigurableVAE:\n",
    "        for param in param_combinations:\n",
    "            print(f\"Testing parameters: {param}\")\n",
    "            # Prepare DataLoaders\n",
    "            train_loader = DataLoader(train_data, batch_size=param.get('batch_size', 32), shuffle=True)\n",
    "            val_loader = DataLoader(val_data, batch_size=param.get('batch_size', 32), shuffle=False)\n",
    "            # Initialize lists to store losses and accuracies per repetition\n",
    "            reps_val_losses = []\n",
    "            reps_val_accuracies = []\n",
    "            # Initialize lists to store final losses and accuracies\n",
    "            fin_losses = []\n",
    "            fin_accuracies = []\n",
    "            for i in range(reps):\n",
    "                # Instantiate the model\n",
    "                model = model_class(param).to(device)\n",
    "                # Train and evaluate model\n",
    "                train_losses, val_losses = model.fit(train_loader, val_loader, param, device)\n",
    "                val_loss, val_accuracy = model.evaluate(val_loader, device)\n",
    "                reps_val_losses.append(val_losses)\n",
    "                fin_losses.append(val_loss)\n",
    "                fin_accuracies.append(val_accuracy)\n",
    "                # Generate unique model filename\n",
    "                param_hash = hashlib.md5(str(param).encode()).hexdigest()[:8]\n",
    "                model_filename = os.path.join(folder_path, f\"ConfigurableVAE_{search_key}_{i}_{val_losses[-1]:.4f}_{param_hash}.pth\")\n",
    "                # Save model weights\n",
    "                try:\n",
    "                    torch.save({'model_state_dict': model.state_dict(),'config': param}, model_filename)\n",
    "                    print(f\"Model saved to {model_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving model: {e}\")\n",
    "                # Get the hyperparameter value using the lambda function\n",
    "                hyperparam_value = get_hyperparam_value(param)\n",
    "                # Record results\n",
    "                results.append({\n",
    "                    **param,\n",
    "                    search_key: hyperparam_value,\n",
    "                    'repetition': i,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'model_filename': model_filename\n",
    "                })\n",
    "            max_length = max(len(vl) for vl in reps_val_losses)\n",
    "            reps_val_losses_padded = [np.pad(vl, (0, max_length - len(vl)), 'constant', constant_values=np.nan) for vl in reps_val_losses]\n",
    "            reps_val_losses_array = np.array(reps_val_losses_padded)\n",
    "            avg_val_losses = np.nanmean(reps_val_losses_array, axis=0)\n",
    "            std_val_losses = np.nanstd(reps_val_losses_array, axis=0)\n",
    "            # Save losses and accuracies\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableVAE_avg_val_losses_{search_key}_{param_hash}.npy\"), avg_val_losses)\n",
    "            np.save(os.path.join(folder_path, f\"ConfigurableVAE_std_val_losses_{search_key}_{param_hash}.npy\"), std_val_losses)\n",
    "            # Select score based on model type\n",
    "            score = np.mean(fin_losses)\n",
    "            # Update the best model\n",
    "            if score_compare(score, best_score):\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = param\n",
    "        # Save results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(folder_path, f\"ConfigurableVAE_results_{search_key}.csv\"), index=False)\n",
    "        return results_df, best_model, best_params\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class '{model_class}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Information Query & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_best_hyperparameters(results_df, model_class, target_metric=None):\n",
    "    \"\"\"\n",
    "    Query the dataframe for the best performing hyperparameters.\n",
    "    \"\"\"\n",
    "    # Set default target metric based on model class\n",
    "    if target_metric is None:\n",
    "        target_metric = 'val_loss' if model_class == ConfigurableSAE else 'val_accuracy'\n",
    "\n",
    "    # Ensure the column is numeric and contains valid data\n",
    "    if target_metric not in results_df or results_df[target_metric].isnull().all():\n",
    "        raise ValueError(f\"Target metric '{target_metric}' is not available or contains no valid data.\")\n",
    "\n",
    "    # Filter out rows with NaN or None in the target metric\n",
    "    valid_results = results_df.dropna(subset=[target_metric])\n",
    "\n",
    "    if valid_results.empty:\n",
    "        raise ValueError(f\"No valid results available for metric '{target_metric}'.\")\n",
    "\n",
    "    # Find the row with the best value for the target metric\n",
    "    if model_class == ConfigurableSAE:\n",
    "        best_row = valid_results.loc[valid_results[target_metric].idxmin()]\n",
    "    else:\n",
    "        best_row = valid_results.loc[valid_results[target_metric].idxmax()]\n",
    "    return best_row.to_dict()\n",
    "\n",
    "def filter_hyperparameters(results_df, **criteria):\n",
    "    \"\"\"\n",
    "    Return all entries that match the specified hyperparameters.\n",
    "    \"\"\"\n",
    "    filtered_df = results_df\n",
    "    for key, value in criteria.items():\n",
    "        filtered_df = filtered_df[filtered_df[key] == value]\n",
    "    return filtered_df\n",
    "\n",
    "def plot_hyperparameters(results_df, hyperparameter, metric='val_loss', save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the evaluation metric vs hyperparameters using Matplotlib,\n",
    "    including error bars representing the standard deviation.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Ensure hyperparameter values are hashable (e.g., convert lists to strings)\n",
    "    if results_df[hyperparameter].apply(lambda x: isinstance(x, list)).any():\n",
    "        results_df[hyperparameter] = results_df[hyperparameter].apply(lambda x: str(x))\n",
    "\n",
    "    # Group the results by the hyperparameter\n",
    "    grouped = results_df.groupby(hyperparameter)[metric]\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    mean_metrics = grouped.mean()\n",
    "    std_metrics = grouped.std()\n",
    "\n",
    "    # Get the hyperparameter values and corresponding metrics\n",
    "    X = mean_metrics.index\n",
    "    Y = mean_metrics.values\n",
    "    Yerr = std_metrics.values\n",
    "\n",
    "    # If hyperparameter values are strings (non-numeric), convert to numerical indices\n",
    "    if not np.issubdtype(np.array(X).dtype, np.number):\n",
    "        X_labels = X\n",
    "        X = np.arange(len(X))\n",
    "        plt.xticks(X, X_labels, rotation='vertical')\n",
    "\n",
    "    # Plot the mean metric with error bars for the standard deviation\n",
    "    plt.errorbar(X, Y, yerr=Yerr, fmt='o-', capsize=5, elinewidth=2, markeredgewidth=2)\n",
    "\n",
    "    plt.xlabel(hyperparameter)\n",
    "    plt.ylabel(metric)\n",
    "    if hyperparameter in ['learning_rate', '_lambda']:\n",
    "        plt.xscale('log')\n",
    "    plt.title(f\"{metric.capitalize()} vs {hyperparameter}\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def load_model(model_class, filename, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load a model from a file.\n",
    "    \"\"\"\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(filename, map_location=device))\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Information Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_from_code(model, code, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate an image from a given code using the SAE model.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    code_tensor = torch.tensor(code, dtype=torch.float32).to(device)\n",
    "    code_tensor = code_tensor.view(1, -1)  # Reshape to (1, code_size)\n",
    "    image = model.code_forward(code_tensor)\n",
    "    return image.cpu().detach().numpy().reshape(28, 28)\n",
    "\n",
    "def generate_eigenimages(model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate eigenimages from the decoder weights of the SAE model.\n",
    "    \"\"\"\n",
    "    eigenimages = []\n",
    "    model.to(device)\n",
    "    code_size = model.code_size\n",
    "    for i in range(code_size):\n",
    "        code = torch.zeros(1, code_size).to(device)\n",
    "        code[0, i] = 1.0\n",
    "        image = model.code_forward(code)\n",
    "        eigenimage = image.cpu().detach().numpy().reshape(28, 28)\n",
    "        eigenimages.append(eigenimage)\n",
    "    return eigenimages\n",
    "\n",
    "def plot_eigenimages(eigenimages, n_cols=8, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the eigenimages using Matplotlib.\n",
    "    \"\"\"\n",
    "    n_rows = len(eigenimages) // n_cols + 1\n",
    "    plt.figure(figsize=(16, 2 * n_rows))\n",
    "    for i, eigenimage in enumerate(eigenimages):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(eigenimage, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def generate_class_codes(model, data_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate class codes from the SAE model. Get 1 sample from each class, encode it, and store the code.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    class_codes = {}\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in data_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            X_batch = X_batch.view(X_batch.size(0), -1)  # Flatten for input to the model\n",
    "            outputs = model.encoder(X_batch)\n",
    "            for i, code in enumerate(outputs):\n",
    "                label = Y_batch[i].item()\n",
    "                if label not in class_codes:\n",
    "                    class_codes[label] = code.cpu().detach().numpy()\n",
    "                    if len(class_codes) == 10:\n",
    "                        break\n",
    "    return \n",
    "\n",
    "def generate_class_images(model, class_codes, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate class images from the SAE model using the class codes. Add a 0 mean, varying variance gaussian noise to the code. Decode the noisy code to get the class image.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    variances = [2**-4.5, 2**-4, 2**-3.5, 2**-3, 2**-2.5, 2**-2, 2**-1.5, 2**-1, 2**-0.5, 2**0]\n",
    "    class_images = {}\n",
    "    for label, code in class_codes.items():\n",
    "        for variance in variances:\n",
    "            for i in range(10):\n",
    "                noisy_code = code + torch.randn_like(code) * variance\n",
    "                image = model.code_forward(noisy_code)\n",
    "                image = image.cpu().detach().numpy().reshape(28, 28)\n",
    "                class_images[(label, variance)] = image\n",
    "    return class_images\n",
    "\n",
    "def plot_class_images(class_images, n_cols=10, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the class images using Matplotlib.\n",
    "    \"\"\"\n",
    "    n_rows = len(class_images) // n_cols + 1\n",
    "    plt.figure(figsize=(16, 2 * n_rows))\n",
    "    for i, (key, image) in enumerate(class_images.items()):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"Class {key[0]}, Variance {key[1]:.4f}\")\n",
    "        plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test():\n",
    "    for model_archtype in [\"ANN\", \"SAE\", \"SAEANN\", \"VAE\"]:\n",
    "        # Load and preprocess KMNIST data\n",
    "        tr_X, tr_Y, ts_X, ts_Y = load_and_preprocess_data()\n",
    "\n",
    "        # Split training data into training and validation sets\n",
    "        X_train, Y_train, X_val, Y_val = train_val_split(tr_X, tr_Y, val_size=0.35)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        train_data = TensorDataset(torch.tensor(X_train).float(), torch.tensor(Y_train).long())\n",
    "        val_data = TensorDataset(torch.tensor(X_val).float(), torch.tensor(Y_val).long())\n",
    "        test_data = TensorDataset(torch.tensor(ts_X).float(), torch.tensor(ts_Y).long())\n",
    "\n",
    "        # Choose architecture and hyperparameter grid\n",
    "        archtype = model_archtype  # Set to \"SAEANN\" for testing the combined model\n",
    "        searchkey = \"unit-test\"  # Primary hyperparameter to test\n",
    "\n",
    "        # Determine the model class based on architecture\n",
    "        if archtype == \"SAE\":\n",
    "            model_class = ConfigurableSAE\n",
    "        elif archtype == \"ANN\":\n",
    "            model_class = ConfigurableANN\n",
    "        elif archtype == \"SAEANN\":\n",
    "            model_class = ConfigurableSAEANN\n",
    "        elif archtype == \"VAE\":\n",
    "            model_class = ConfigurableVAE\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported archtype '{archtype}'.\")\n",
    "\n",
    "        # Get the parameter grid for the selected architecture\n",
    "        param_grid = ret_search_param_grid(archtype=archtype, searchkey=searchkey)\n",
    "\n",
    "        # Perform grid search\n",
    "        results_df, best_model, best_params = grid_search_cv(train_data, val_data, param_grid, model_class, searchkey, device='cuda')\n",
    "\n",
    "        # Plot the results (optional)\n",
    "        if archtype == \"SAE\" and searchkey != \"3d_grid\":\n",
    "            plot_hyperparameters(results_df, searchkey, metric='val_loss', save_path=f\"{searchkey}/val_loss.png\")\n",
    "        elif archtype == \"ANN\":\n",
    "            plot_hyperparameters(results_df, searchkey, metric='val_accuracy', save_path=f\"{searchkey}/val_accuracy.png\")\n",
    "\n",
    "        # Display results\n",
    "        print(\"Grid Search Results:\")\n",
    "        print(results_df)\n",
    "\n",
    "        # Identify the best hyperparameters\n",
    "        best_hyperparams = query_best_hyperparameters(results_df, model_class)\n",
    "        print(\"Best Hyperparameters:\", best_hyperparams)\n",
    "\n",
    "        # Evaluate the best model on the test set\n",
    "        print(\"Evaluating best model on the test set...\")\n",
    "        if best_model is None:\n",
    "            raise RuntimeError(\"No valid model found. Check grid search results.\")\n",
    "\n",
    "        best_model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        test_loader = DataLoader(test_data, batch_size=best_params.get('batch_size', 32), shuffle=False)\n",
    "\n",
    "        if model_archtype == \"ANN\":\n",
    "            # For ANN, proceed as before\n",
    "            with torch.no_grad():\n",
    "                for X_batch, Y_batch in test_loader:\n",
    "                    X_batch, Y_batch = X_batch.to('cuda'), Y_batch.to('cuda')\n",
    "                    X_batch = X_batch.view(X_batch.size(0), -1)\n",
    "                    outputs = best_model(X_batch)\n",
    "                    loss = criterion(outputs, Y_batch)\n",
    "                    test_loss += loss.item() * X_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct += (predicted == Y_batch).sum().item()\n",
    "                    total += Y_batch.size(0)\n",
    "            test_loss /= total\n",
    "            test_accuracy = correct / total\n",
    "        elif model_archtype == \"SAE\":\n",
    "            # For SAE, use the evaluate methods\n",
    "            test_loss_rc = best_model.evaluate_reconstruction(test_loader)\n",
    "            test_loss_cd, test_accuracy = best_model.evaluate_code(test_loader)\n",
    "            test_loss = test_loss_rc + test_loss_cd\n",
    "            print(f\"Test Reconstruction Loss: {test_loss_rc:.4f}\")\n",
    "            print(f\"Test Code Loss: {test_loss_cd:.4f}\")\n",
    "        elif model_archtype == \"SAEANN\":\n",
    "            # For SAEANN, adjust outputs accordingly\n",
    "            with torch.no_grad():\n",
    "                for X_batch, Y_batch in test_loader:\n",
    "                    X_batch, Y_batch = X_batch.to('cuda'), Y_batch.to('cuda')\n",
    "                    X_batch = X_batch.view(X_batch.size(0), -1)\n",
    "                    outputs, _ = best_model(X_batch)\n",
    "                    loss = criterion(outputs, Y_batch)\n",
    "                    test_loss += loss.item() * X_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct += (predicted == Y_batch).sum().item()\n",
    "                    total += Y_batch.size(0)\n",
    "            test_loss /= total\n",
    "            test_accuracy = correct / total\n",
    "        elif model_archtype == \"VAE\":\n",
    "            # For VAE, use appropriate evaluation methods\n",
    "            test_loss = best_model.evaluate_reconstruction(test_loader)\n",
    "            test_accuracy = None  # VAE may not have accuracy metric\n",
    "\n",
    "        print(f\"Test Loss: {test_loss:.4f}\")\n",
    "        if test_accuracy is not None:\n",
    "            print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        # Clean up\n",
    "        del param_grid, results_df, best_model, best_params, test_loss, test_accuracy, best_hyperparams, model_class, correct, total, criterion, test_loader, tr_X, tr_Y, ts_X, ts_Y, X_train, Y_train, X_val, Y_val, train_data, val_data, test_data, archtype, searchkey, model_archtype\n",
    "        # Garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "def testing():\n",
    "    model_archtypes = [\"SAE\"]\n",
    "    #model_archtypes = [\"ANN\", \"SAE\", \"SAEANN\", \"VAE\"]\n",
    "    for model_archtype in model_archtypes:\n",
    "        #keys = ret_search_param_grid(archtype=model_archtype, searchkey=None)\n",
    "        keys = [\"3d_grid\"]\n",
    "        for key in keys:\n",
    "            if key == \"unit-test\":\n",
    "                continue\n",
    "            # Load and preprocess KMNIST data\n",
    "            tr_X, tr_Y, ts_X, ts_Y = load_and_preprocess_data()\n",
    "\n",
    "            # Split training data into training and validation sets\n",
    "            X_train, Y_train, X_val, Y_val = train_val_split(tr_X, tr_Y, val_size=0.35)\n",
    "\n",
    "            # Convert to PyTorch tensors\n",
    "            train_data = TensorDataset(torch.tensor(X_train).float(), torch.tensor(Y_train).long())\n",
    "            val_data = TensorDataset(torch.tensor(X_val).float(), torch.tensor(Y_val).long())\n",
    "            test_data = TensorDataset(torch.tensor(ts_X).float(), torch.tensor(ts_Y).long())\n",
    "\n",
    "            # Choose architecture and hyperparameter grid\n",
    "            archtype = model_archtype  # Set to \"SAEANN\" for testing the combined model\n",
    "            searchkey = key  # Primary hyperparameter to test\n",
    "\n",
    "            # Determine the model class based on architecture\n",
    "            if archtype == \"SAE\":\n",
    "                model_class = ConfigurableSAE\n",
    "            elif archtype == \"ANN\":\n",
    "                model_class = ConfigurableANN\n",
    "            elif archtype == \"SAEANN\":\n",
    "                model_class = ConfigurableSAEANN\n",
    "            elif archtype == \"VAE\":\n",
    "                model_class = ConfigurableVAE\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported archtype '{archtype}'.\")\n",
    "\n",
    "            # Get the parameter grid for the selected architecture\n",
    "            param_grid = ret_search_param_grid(archtype=archtype, searchkey=searchkey)\n",
    "\n",
    "            # Perform grid search\n",
    "            results_df, best_model, best_params = grid_search_cv(train_data, val_data, param_grid, model_class, searchkey, device='cuda')\n",
    "\n",
    "            # Plot the results (optional)\n",
    "            if searchkey in [\"learning_rate\", \"batch_size\", \"_lambda\", \"dropout_rate\", \"code_length\"]:\n",
    "                plot_hyperparameters(results_df, searchkey, metric='val_loss', save_path=f\"{searchkey}/{archtype}_val_loss.png\")\n",
    "\n",
    "            # Display results\n",
    "            print(\"Grid Search Results:\")\n",
    "            print(results_df)\n",
    "\n",
    "            # Identify the best hyperparameters\n",
    "            best_hyperparams = query_best_hyperparameters(results_df, model_class)\n",
    "            print(\"Best Hyperparameters:\", best_hyperparams)\n",
    "\n",
    "            # Evaluate the best model on the test set\n",
    "            print(\"Evaluating best model on the test set...\")\n",
    "            if best_model is None:\n",
    "                raise RuntimeError(\"No valid model found. Check grid search results.\")\n",
    "\n",
    "            best_model.eval()\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            test_loader = DataLoader(test_data, batch_size=best_params.get('batch_size', 32), shuffle=False)\n",
    "\n",
    "            if model_archtype == \"ANN\":\n",
    "                # For ANN, proceed as before\n",
    "                with torch.no_grad():\n",
    "                    for X_batch, Y_batch in test_loader:\n",
    "                        X_batch, Y_batch = X_batch.to('cuda'), Y_batch.to('cuda')\n",
    "                        X_batch = X_batch.view(X_batch.size(0), -1)\n",
    "                        outputs = best_model(X_batch)\n",
    "                        loss = criterion(outputs, Y_batch)\n",
    "                        test_loss += loss.item() * X_batch.size(0)\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        correct += (predicted == Y_batch).sum().item()\n",
    "                        total += Y_batch.size(0)\n",
    "                test_loss /= total\n",
    "                test_accuracy = correct / total\n",
    "            elif model_archtype == \"SAE\":\n",
    "                # For SAE, use the evaluate methods\n",
    "                test_loss_rc = best_model.evaluate_reconstruction(test_loader)\n",
    "                test_loss_cd, test_accuracy = best_model.evaluate_code(test_loader)\n",
    "                test_loss = test_loss_rc + test_loss_cd\n",
    "                print(f\"Test Reconstruction Loss: {test_loss_rc:.4f}\")\n",
    "                print(f\"Test Code Loss: {test_loss_cd:.4f}\")\n",
    "            elif model_archtype == \"SAEANN\":\n",
    "                # For SAEANN, adjust outputs accordingly\n",
    "                with torch.no_grad():\n",
    "                    for X_batch, Y_batch in test_loader:\n",
    "                        X_batch, Y_batch = X_batch.to('cuda'), Y_batch.to('cuda')\n",
    "                        X_batch = X_batch.view(X_batch.size(0), -1)\n",
    "                        outputs, _ = best_model(X_batch)\n",
    "                        loss = criterion(outputs, Y_batch)\n",
    "                        test_loss += loss.item() * X_batch.size(0)\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        correct += (predicted == Y_batch).sum().item()\n",
    "                        total += Y_batch.size(0)\n",
    "                test_loss /= total\n",
    "                test_accuracy = correct / total\n",
    "            elif model_archtype == \"VAE\":\n",
    "                # For VAE, use appropriate evaluation methods\n",
    "                test_loss = best_model.evaluate_reconstruction(test_loader)\n",
    "                test_accuracy = None  # VAE may not have accuracy metric\n",
    "\n",
    "            print(f\"Test Loss: {test_loss:.4f}\")\n",
    "            if test_accuracy is not None:\n",
    "                print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 1}\n",
      "Epoch 16/2048 - Train Loss: 0.0501, Val Loss: 0.0461\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0455, Val Loss: 0.0430\n",
      "Epoch 64/2048 - Train Loss: 0.0446, Val Loss: 0.0422\n",
      "Epoch 80/2048 - Train Loss: 0.0439, Val Loss: 0.0426\n",
      "Epoch 96/2048 - Train Loss: 0.0434, Val Loss: 0.0426\n",
      "Early stopping at epoch 97 - Train Loss: 0.0434, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0421_deb9ba71.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0500, Val Loss: 0.0464\n",
      "Epoch 32/2048 - Train Loss: 0.0469, Val Loss: 0.0438\n",
      "Epoch 48/2048 - Train Loss: 0.0455, Val Loss: 0.0438\n",
      "Epoch 64/2048 - Train Loss: 0.0446, Val Loss: 0.0419\n",
      "Epoch 80/2048 - Train Loss: 0.0439, Val Loss: 0.0420\n",
      "Early stopping at epoch 83 - Train Loss: 0.0438, Val Loss: 0.0418\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0418_deb9ba71.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0462\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0439\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0429\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0435\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0420\n",
      "Epoch 96/2048 - Train Loss: 0.0435, Val Loss: 0.0422\n",
      "Epoch 112/2048 - Train Loss: 0.0432, Val Loss: 0.0416\n",
      "Early stopping at epoch 123 - Train Loss: 0.0430, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0421_deb9ba71.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0501, Val Loss: 0.0454\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0442\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0434\n",
      "Epoch 64/2048 - Train Loss: 0.0447, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0440, Val Loss: 0.0422\n",
      "Epoch 96/2048 - Train Loss: 0.0434, Val Loss: 0.0430\n",
      "Early stopping at epoch 99 - Train Loss: 0.0434, Val Loss: 0.0417\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0417_deb9ba71.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0461\n",
      "Epoch 32/2048 - Train Loss: 0.0472, Val Loss: 0.0437\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0430\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0428\n",
      "Early stopping at epoch 75 - Train Loss: 0.0442, Val Loss: 0.0437\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0437_deb9ba71.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 1.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0499, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0468, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0453, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0415\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0416\n",
      "Early stopping at epoch 81 - Train Loss: 0.0435, Val Loss: 0.0414\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0414_c2aeb0c4.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0498, Val Loss: 0.0451\n",
      "Epoch 32/2048 - Train Loss: 0.0467, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0443, Val Loss: 0.0415\n",
      "Epoch 80/2048 - Train Loss: 0.0437, Val Loss: 0.0411\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0426\n",
      "Early stopping at epoch 110 - Train Loss: 0.0428, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0413_c2aeb0c4.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0498, Val Loss: 0.0453\n",
      "Epoch 32/2048 - Train Loss: 0.0470, Val Loss: 0.0430\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0445, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0438, Val Loss: 0.0418\n",
      "Epoch 96/2048 - Train Loss: 0.0434, Val Loss: 0.0417\n",
      "Epoch 112/2048 - Train Loss: 0.0430, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0426, Val Loss: 0.0412\n",
      "Epoch 144/2048 - Train Loss: 0.0424, Val Loss: 0.0407\n",
      "Early stopping at epoch 156 - Train Loss: 0.0422, Val Loss: 0.0412\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0412_c2aeb0c4.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0499, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0468, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0419\n",
      "Epoch 64/2048 - Train Loss: 0.0443, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0437, Val Loss: 0.0411\n",
      "Epoch 96/2048 - Train Loss: 0.0433, Val Loss: 0.0412\n",
      "Early stopping at epoch 109 - Train Loss: 0.0429, Val Loss: 0.0409\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0409_c2aeb0c4.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0499, Val Loss: 0.0454\n",
      "Epoch 32/2048 - Train Loss: 0.0468, Val Loss: 0.0430\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0418\n",
      "Epoch 64/2048 - Train Loss: 0.0443, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0412\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0410\n",
      "Epoch 112/2048 - Train Loss: 0.0428, Val Loss: 0.0412\n",
      "Epoch 128/2048 - Train Loss: 0.0424, Val Loss: 0.0407\n",
      "Early stopping at epoch 143 - Train Loss: 0.0421, Val Loss: 0.0417\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0417_c2aeb0c4.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 1.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0499, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0466, Val Loss: 0.0427\n",
      "Epoch 48/2048 - Train Loss: 0.0451, Val Loss: 0.0416\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0415\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0430, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0426, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0423, Val Loss: 0.0405\n",
      "Epoch 144/2048 - Train Loss: 0.0420, Val Loss: 0.0405\n",
      "Epoch 160/2048 - Train Loss: 0.0418, Val Loss: 0.0408\n",
      "Early stopping at epoch 162 - Train Loss: 0.0418, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0404_0ecf2b24.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0449\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0416\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0408\n",
      "Early stopping at epoch 101 - Train Loss: 0.0428, Val Loss: 0.0408\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0408_0ecf2b24.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0500, Val Loss: 0.0452\n",
      "Epoch 32/2048 - Train Loss: 0.0469, Val Loss: 0.0427\n",
      "Epoch 48/2048 - Train Loss: 0.0454, Val Loss: 0.0419\n",
      "Epoch 64/2048 - Train Loss: 0.0443, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0437, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0433, Val Loss: 0.0408\n",
      "Early stopping at epoch 105 - Train Loss: 0.0430, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0413_0ecf2b24.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0500, Val Loss: 0.0453\n",
      "Epoch 32/2048 - Train Loss: 0.0469, Val Loss: 0.0429\n",
      "Epoch 48/2048 - Train Loss: 0.0453, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0411\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0410\n",
      "Epoch 112/2048 - Train Loss: 0.0427, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0424, Val Loss: 0.0410\n",
      "Epoch 144/2048 - Train Loss: 0.0420, Val Loss: 0.0413\n",
      "Early stopping at epoch 145 - Train Loss: 0.0421, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0406_0ecf2b24.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0454\n",
      "Epoch 32/2048 - Train Loss: 0.0468, Val Loss: 0.0426\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0417\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0420\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0412\n",
      "Epoch 96/2048 - Train Loss: 0.0432, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0408\n",
      "Early stopping at epoch 113 - Train Loss: 0.0427, Val Loss: 0.0407\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0407_0ecf2b24.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 1.75}\n",
      "Epoch 16/2048 - Train Loss: 0.0497, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0467, Val Loss: 0.0427\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0418\n",
      "Epoch 64/2048 - Train Loss: 0.0443, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0409\n",
      "Epoch 96/2048 - Train Loss: 0.0432, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0427, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0424, Val Loss: 0.0406\n",
      "Early stopping at epoch 136 - Train Loss: 0.0422, Val Loss: 0.0405\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0405_d58a612d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0497, Val Loss: 0.0452\n",
      "Epoch 32/2048 - Train Loss: 0.0467, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0453, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0444, Val Loss: 0.0414\n",
      "Epoch 80/2048 - Train Loss: 0.0437, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0432, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0427, Val Loss: 0.0407\n",
      "Epoch 128/2048 - Train Loss: 0.0424, Val Loss: 0.0405\n",
      "Epoch 144/2048 - Train Loss: 0.0422, Val Loss: 0.0407\n",
      "Early stopping at epoch 157 - Train Loss: 0.0419, Val Loss: 0.0408\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0408_d58a612d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0496, Val Loss: 0.0449\n",
      "Epoch 32/2048 - Train Loss: 0.0466, Val Loss: 0.0426\n",
      "Epoch 48/2048 - Train Loss: 0.0451, Val Loss: 0.0419\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0406\n",
      "Epoch 128/2048 - Train Loss: 0.0423, Val Loss: 0.0409\n",
      "Epoch 144/2048 - Train Loss: 0.0420, Val Loss: 0.0404\n",
      "Epoch 160/2048 - Train Loss: 0.0417, Val Loss: 0.0401\n",
      "Early stopping at epoch 176 - Train Loss: 0.0415, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0404_d58a612d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0451\n",
      "Epoch 32/2048 - Train Loss: 0.0466, Val Loss: 0.0424\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0409\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0406\n",
      "Epoch 112/2048 - Train Loss: 0.0426, Val Loss: 0.0403\n",
      "Epoch 128/2048 - Train Loss: 0.0421, Val Loss: 0.0404\n",
      "Epoch 144/2048 - Train Loss: 0.0419, Val Loss: 0.0407\n",
      "Early stopping at epoch 152 - Train Loss: 0.0416, Val Loss: 0.0403\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0403_d58a612d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0496, Val Loss: 0.0452\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0426\n",
      "Epoch 48/2048 - Train Loss: 0.0451, Val Loss: 0.0417\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0430, Val Loss: 0.0406\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0405\n",
      "Epoch 128/2048 - Train Loss: 0.0423, Val Loss: 0.0404\n",
      "Epoch 144/2048 - Train Loss: 0.0420, Val Loss: 0.0407\n",
      "Epoch 160/2048 - Train Loss: 0.0417, Val Loss: 0.0405\n",
      "Early stopping at epoch 168 - Train Loss: 0.0417, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0406_d58a612d.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 2}\n",
      "Epoch 16/2048 - Train Loss: 0.0498, Val Loss: 0.0451\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0426\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0416\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0426, Val Loss: 0.0409\n",
      "Epoch 128/2048 - Train Loss: 0.0422, Val Loss: 0.0406\n",
      "Early stopping at epoch 142 - Train Loss: 0.0420, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0404_701453df.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0445\n",
      "Epoch 32/2048 - Train Loss: 0.0466, Val Loss: 0.0425\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0417\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0411\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0410\n",
      "Epoch 96/2048 - Train Loss: 0.0430, Val Loss: 0.0409\n",
      "Epoch 112/2048 - Train Loss: 0.0427, Val Loss: 0.0405\n",
      "Epoch 128/2048 - Train Loss: 0.0424, Val Loss: 0.0405\n",
      "Early stopping at epoch 134 - Train Loss: 0.0422, Val Loss: 0.0408\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0408_701453df.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0496, Val Loss: 0.0448\n",
      "Epoch 32/2048 - Train Loss: 0.0466, Val Loss: 0.0427\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0418\n",
      "Epoch 64/2048 - Train Loss: 0.0442, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0436, Val Loss: 0.0413\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0409\n",
      "Early stopping at epoch 98 - Train Loss: 0.0431, Val Loss: 0.0409\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0409_701453df.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0444\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0412\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0406\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0402\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0401\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0402\n",
      "Early stopping at epoch 141 - Train Loss: 0.0418, Val Loss: 0.0401\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0401_701453df.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0449\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0415\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0411\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0406\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0404\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0402\n",
      "Early stopping at epoch 152 - Train Loss: 0.0417, Val Loss: 0.0400\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0400_701453df.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 2.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0496, Val Loss: 0.0452\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0425\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0417\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0409\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0407\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0422, Val Loss: 0.0405\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0404\n",
      "Early stopping at epoch 151 - Train Loss: 0.0419, Val Loss: 0.0405\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0405_34de1d3c.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0424\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0411\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0408\n",
      "Epoch 112/2048 - Train Loss: 0.0426, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0422, Val Loss: 0.0401\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0404\n",
      "Early stopping at epoch 146 - Train Loss: 0.0418, Val Loss: 0.0405\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0405_34de1d3c.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0416\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0406\n",
      "Epoch 112/2048 - Train Loss: 0.0426, Val Loss: 0.0405\n",
      "Epoch 128/2048 - Train Loss: 0.0423, Val Loss: 0.0405\n",
      "Epoch 144/2048 - Train Loss: 0.0421, Val Loss: 0.0403\n",
      "Early stopping at epoch 153 - Train Loss: 0.0417, Val Loss: 0.0403\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0403_34de1d3c.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0449\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0451, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0426, Val Loss: 0.0405\n",
      "Early stopping at epoch 119 - Train Loss: 0.0424, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0406_34de1d3c.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0449\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0425\n",
      "Epoch 48/2048 - Train Loss: 0.0452, Val Loss: 0.0418\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0410\n",
      "Epoch 96/2048 - Train Loss: 0.0430, Val Loss: 0.0406\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0405\n",
      "Epoch 128/2048 - Train Loss: 0.0422, Val Loss: 0.0402\n",
      "Epoch 144/2048 - Train Loss: 0.0419, Val Loss: 0.0404\n",
      "Early stopping at epoch 148 - Train Loss: 0.0418, Val Loss: 0.0405\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0405_34de1d3c.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 2.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0412\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0412\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0405\n",
      "Early stopping at epoch 111 - Train Loss: 0.0425, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0404_486be96d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0446\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0426\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0418\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0410\n",
      "Epoch 96/2048 - Train Loss: 0.0430, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0406\n",
      "Early stopping at epoch 127 - Train Loss: 0.0423, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0406_486be96d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0447, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0433, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0409\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0402\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0405\n",
      "Epoch 144/2048 - Train Loss: 0.0419, Val Loss: 0.0400\n",
      "Early stopping at epoch 145 - Train Loss: 0.0417, Val Loss: 0.0401\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0401_486be96d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0412\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0407\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0407\n",
      "Early stopping at epoch 126 - Train Loss: 0.0422, Val Loss: 0.0403\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0403_486be96d.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0491, Val Loss: 0.0443\n",
      "Epoch 32/2048 - Train Loss: 0.0460, Val Loss: 0.0422\n",
      "Epoch 48/2048 - Train Loss: 0.0446, Val Loss: 0.0411\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0406\n",
      "Epoch 80/2048 - Train Loss: 0.0431, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0425, Val Loss: 0.0407\n",
      "Epoch 112/2048 - Train Loss: 0.0421, Val Loss: 0.0402\n",
      "Epoch 128/2048 - Train Loss: 0.0418, Val Loss: 0.0402\n",
      "Early stopping at epoch 131 - Train Loss: 0.0417, Val Loss: 0.0403\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0403_486be96d.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 2.75}\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0445\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0422\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0404\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0403\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0401\n",
      "Epoch 144/2048 - Train Loss: 0.0419, Val Loss: 0.0401\n",
      "Early stopping at epoch 157 - Train Loss: 0.0416, Val Loss: 0.0401\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0401_513a3f7b.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0492, Val Loss: 0.0443\n",
      "Epoch 32/2048 - Train Loss: 0.0462, Val Loss: 0.0420\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0410\n",
      "Epoch 64/2048 - Train Loss: 0.0437, Val Loss: 0.0406\n",
      "Epoch 80/2048 - Train Loss: 0.0431, Val Loss: 0.0403\n",
      "Epoch 96/2048 - Train Loss: 0.0426, Val Loss: 0.0398\n",
      "Epoch 112/2048 - Train Loss: 0.0421, Val Loss: 0.0401\n",
      "Epoch 128/2048 - Train Loss: 0.0419, Val Loss: 0.0398\n",
      "Epoch 144/2048 - Train Loss: 0.0415, Val Loss: 0.0399\n",
      "Epoch 160/2048 - Train Loss: 0.0412, Val Loss: 0.0398\n",
      "Epoch 176/2048 - Train Loss: 0.0410, Val Loss: 0.0399\n",
      "Early stopping at epoch 188 - Train Loss: 0.0409, Val Loss: 0.0397\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0397_513a3f7b.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0425\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0409\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0408\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0421, Val Loss: 0.0404\n",
      "Epoch 144/2048 - Train Loss: 0.0419, Val Loss: 0.0402\n",
      "Epoch 160/2048 - Train Loss: 0.0416, Val Loss: 0.0400\n",
      "Epoch 176/2048 - Train Loss: 0.0413, Val Loss: 0.0400\n",
      "Epoch 192/2048 - Train Loss: 0.0410, Val Loss: 0.0400\n",
      "Early stopping at epoch 197 - Train Loss: 0.0411, Val Loss: 0.0400\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0400_513a3f7b.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0444\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0422\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0415\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0427, Val Loss: 0.0403\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0400\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0404\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0399\n",
      "Early stopping at epoch 159 - Train Loss: 0.0414, Val Loss: 0.0402\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0402_513a3f7b.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0496, Val Loss: 0.0447\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0451, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0412\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0429, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0422, Val Loss: 0.0408\n",
      "Epoch 144/2048 - Train Loss: 0.0419, Val Loss: 0.0403\n",
      "Epoch 160/2048 - Train Loss: 0.0417, Val Loss: 0.0401\n",
      "Early stopping at epoch 167 - Train Loss: 0.0416, Val Loss: 0.0402\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0402_513a3f7b.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 3}\n",
      "Epoch 16/2048 - Train Loss: 0.0495, Val Loss: 0.0446\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0409\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0427, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0421, Val Loss: 0.0401\n",
      "Epoch 128/2048 - Train Loss: 0.0419, Val Loss: 0.0403\n",
      "Early stopping at epoch 137 - Train Loss: 0.0418, Val Loss: 0.0402\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0402_7d8fb9c7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0497, Val Loss: 0.0450\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0450, Val Loss: 0.0415\n",
      "Epoch 64/2048 - Train Loss: 0.0440, Val Loss: 0.0410\n",
      "Epoch 80/2048 - Train Loss: 0.0434, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0404\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0402\n",
      "Early stopping at epoch 128 - Train Loss: 0.0421, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0404_7d8fb9c7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0448\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0422\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0407\n",
      "Epoch 80/2048 - Train Loss: 0.0433, Val Loss: 0.0406\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0403\n",
      "Epoch 112/2048 - Train Loss: 0.0422, Val Loss: 0.0401\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0401\n",
      "Early stopping at epoch 134 - Train Loss: 0.0420, Val Loss: 0.0400\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0400_7d8fb9c7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0445\n",
      "Epoch 32/2048 - Train Loss: 0.0463, Val Loss: 0.0421\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0406\n",
      "Epoch 96/2048 - Train Loss: 0.0427, Val Loss: 0.0403\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0402\n",
      "Epoch 128/2048 - Train Loss: 0.0419, Val Loss: 0.0400\n",
      "Early stopping at epoch 142 - Train Loss: 0.0417, Val Loss: 0.0401\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0401_7d8fb9c7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0497, Val Loss: 0.0449\n",
      "Epoch 32/2048 - Train Loss: 0.0463, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0410\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0409\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0406\n",
      "Epoch 96/2048 - Train Loss: 0.0427, Val Loss: 0.0401\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0404\n",
      "Early stopping at epoch 122 - Train Loss: 0.0421, Val Loss: 0.0403\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0403_7d8fb9c7.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 3.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0446\n",
      "Epoch 32/2048 - Train Loss: 0.0465, Val Loss: 0.0426\n",
      "Epoch 48/2048 - Train Loss: 0.0451, Val Loss: 0.0415\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0413\n",
      "Epoch 80/2048 - Train Loss: 0.0435, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0431, Val Loss: 0.0409\n",
      "Epoch 112/2048 - Train Loss: 0.0427, Val Loss: 0.0403\n",
      "Epoch 128/2048 - Train Loss: 0.0423, Val Loss: 0.0404\n",
      "Early stopping at epoch 142 - Train Loss: 0.0421, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0404_5fceabde.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0499, Val Loss: 0.0453\n",
      "Epoch 32/2048 - Train Loss: 0.0467, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0416\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0412\n",
      "Epoch 80/2048 - Train Loss: 0.0433, Val Loss: 0.0410\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0411\n",
      "Epoch 112/2048 - Train Loss: 0.0425, Val Loss: 0.0407\n",
      "Epoch 128/2048 - Train Loss: 0.0422, Val Loss: 0.0403\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0402\n",
      "Early stopping at epoch 158 - Train Loss: 0.0416, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0404_5fceabde.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0492, Val Loss: 0.0442\n",
      "Epoch 32/2048 - Train Loss: 0.0460, Val Loss: 0.0419\n",
      "Epoch 48/2048 - Train Loss: 0.0447, Val Loss: 0.0411\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0407\n",
      "Epoch 80/2048 - Train Loss: 0.0431, Val Loss: 0.0404\n",
      "Epoch 96/2048 - Train Loss: 0.0426, Val Loss: 0.0402\n",
      "Epoch 112/2048 - Train Loss: 0.0421, Val Loss: 0.0400\n",
      "Early stopping at epoch 124 - Train Loss: 0.0420, Val Loss: 0.0402\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0402_5fceabde.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0445\n",
      "Epoch 32/2048 - Train Loss: 0.0463, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0441, Val Loss: 0.0409\n",
      "Epoch 80/2048 - Train Loss: 0.0433, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0406\n",
      "Epoch 128/2048 - Train Loss: 0.0421, Val Loss: 0.0401\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0403\n",
      "Early stopping at epoch 150 - Train Loss: 0.0417, Val Loss: 0.0400\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0400_5fceabde.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0444\n",
      "Epoch 32/2048 - Train Loss: 0.0463, Val Loss: 0.0421\n",
      "Epoch 48/2048 - Train Loss: 0.0447, Val Loss: 0.0413\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0431, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0426, Val Loss: 0.0402\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0400\n",
      "Epoch 128/2048 - Train Loss: 0.0418, Val Loss: 0.0398\n",
      "Epoch 144/2048 - Train Loss: 0.0416, Val Loss: 0.0397\n",
      "Early stopping at epoch 148 - Train Loss: 0.0414, Val Loss: 0.0399\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0399_5fceabde.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.0009765625, 'norm_type': 3.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0492, Val Loss: 0.0444\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0422\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0412\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0431, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0425, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0423, Val Loss: 0.0400\n",
      "Epoch 128/2048 - Train Loss: 0.0418, Val Loss: 0.0399\n",
      "Epoch 144/2048 - Train Loss: 0.0416, Val Loss: 0.0402\n",
      "Early stopping at epoch 159 - Train Loss: 0.0414, Val Loss: 0.0397\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0397_22674021.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0445\n",
      "Epoch 32/2048 - Train Loss: 0.0462, Val Loss: 0.0423\n",
      "Epoch 48/2048 - Train Loss: 0.0447, Val Loss: 0.0412\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0407\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0407\n",
      "Epoch 96/2048 - Train Loss: 0.0427, Val Loss: 0.0402\n",
      "Epoch 112/2048 - Train Loss: 0.0422, Val Loss: 0.0404\n",
      "Epoch 128/2048 - Train Loss: 0.0418, Val Loss: 0.0402\n",
      "Early stopping at epoch 131 - Train Loss: 0.0419, Val Loss: 0.0404\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0404_22674021.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0494, Val Loss: 0.0444\n",
      "Epoch 32/2048 - Train Loss: 0.0464, Val Loss: 0.0421\n",
      "Epoch 48/2048 - Train Loss: 0.0449, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0439, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0431, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0428, Val Loss: 0.0405\n",
      "Epoch 112/2048 - Train Loss: 0.0424, Val Loss: 0.0403\n",
      "Epoch 128/2048 - Train Loss: 0.0420, Val Loss: 0.0402\n",
      "Epoch 144/2048 - Train Loss: 0.0418, Val Loss: 0.0404\n",
      "Early stopping at epoch 145 - Train Loss: 0.0418, Val Loss: 0.0401\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0401_22674021.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0493, Val Loss: 0.0446\n",
      "Epoch 32/2048 - Train Loss: 0.0462, Val Loss: 0.0424\n",
      "Epoch 48/2048 - Train Loss: 0.0448, Val Loss: 0.0414\n",
      "Epoch 64/2048 - Train Loss: 0.0438, Val Loss: 0.0408\n",
      "Epoch 80/2048 - Train Loss: 0.0432, Val Loss: 0.0405\n",
      "Epoch 96/2048 - Train Loss: 0.0427, Val Loss: 0.0400\n",
      "Early stopping at epoch 112 - Train Loss: 0.0423, Val Loss: 0.0401\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0401_22674021.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0491, Val Loss: 0.0442\n",
      "Epoch 32/2048 - Train Loss: 0.0461, Val Loss: 0.0417\n",
      "Epoch 48/2048 - Train Loss: 0.0446, Val Loss: 0.0410\n",
      "Epoch 64/2048 - Train Loss: 0.0436, Val Loss: 0.0405\n",
      "Epoch 80/2048 - Train Loss: 0.0430, Val Loss: 0.0404\n",
      "Early stopping at epoch 95 - Train Loss: 0.0425, Val Loss: 0.0402\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0402_22674021.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 1}\n",
      "Epoch 16/2048 - Train Loss: 0.0514, Val Loss: 0.0481\n",
      "Epoch 32/2048 - Train Loss: 0.0483, Val Loss: 0.0455\n",
      "Epoch 48/2048 - Train Loss: 0.0467, Val Loss: 0.0455\n",
      "Epoch 64/2048 - Train Loss: 0.0458, Val Loss: 0.0442\n",
      "Epoch 80/2048 - Train Loss: 0.0452, Val Loss: 0.0443\n",
      "Epoch 96/2048 - Train Loss: 0.0446, Val Loss: 0.0443\n",
      "Epoch 112/2048 - Train Loss: 0.0442, Val Loss: 0.0463\n",
      "Early stopping at epoch 117 - Train Loss: 0.0441, Val Loss: 0.0440\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0440_0bf5c5e3.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0517, Val Loss: 0.0481\n",
      "Epoch 32/2048 - Train Loss: 0.0486, Val Loss: 0.0448\n",
      "Epoch 48/2048 - Train Loss: 0.0470, Val Loss: 0.0444\n",
      "Epoch 64/2048 - Train Loss: 0.0462, Val Loss: 0.0440\n",
      "Epoch 80/2048 - Train Loss: 0.0454, Val Loss: 0.0439\n",
      "Epoch 96/2048 - Train Loss: 0.0448, Val Loss: 0.0452\n",
      "Early stopping at epoch 100 - Train Loss: 0.0448, Val Loss: 0.0431\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0431_0bf5c5e3.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0514, Val Loss: 0.0471\n",
      "Epoch 32/2048 - Train Loss: 0.0483, Val Loss: 0.0457\n",
      "Epoch 48/2048 - Train Loss: 0.0468, Val Loss: 0.0445\n",
      "Epoch 64/2048 - Train Loss: 0.0458, Val Loss: 0.0440\n",
      "Epoch 80/2048 - Train Loss: 0.0451, Val Loss: 0.0448\n",
      "Epoch 96/2048 - Train Loss: 0.0447, Val Loss: 0.0441\n",
      "Early stopping at epoch 102 - Train Loss: 0.0445, Val Loss: 0.0433\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0433_0bf5c5e3.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0532, Val Loss: 0.0497\n",
      "Epoch 32/2048 - Train Loss: 0.0502, Val Loss: 0.0463\n",
      "Epoch 48/2048 - Train Loss: 0.0485, Val Loss: 0.0478\n",
      "Early stopping at epoch 56 - Train Loss: 0.0481, Val Loss: 0.0464\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0464_0bf5c5e3.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0531, Val Loss: 0.0502\n",
      "Epoch 32/2048 - Train Loss: 0.0500, Val Loss: 0.0472\n",
      "Epoch 48/2048 - Train Loss: 0.0485, Val Loss: 0.0459\n",
      "Epoch 64/2048 - Train Loss: 0.0475, Val Loss: 0.0454\n",
      "Epoch 80/2048 - Train Loss: 0.0469, Val Loss: 0.0451\n",
      "Early stopping at epoch 88 - Train Loss: 0.0466, Val Loss: 0.0481\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0481_0bf5c5e3.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 1.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0513, Val Loss: 0.0466\n",
      "Epoch 32/2048 - Train Loss: 0.0480, Val Loss: 0.0453\n",
      "Epoch 48/2048 - Train Loss: 0.0464, Val Loss: 0.0428\n",
      "Epoch 64/2048 - Train Loss: 0.0455, Val Loss: 0.0432\n",
      "Epoch 80/2048 - Train Loss: 0.0448, Val Loss: 0.0425\n",
      "Epoch 96/2048 - Train Loss: 0.0442, Val Loss: 0.0426\n",
      "Early stopping at epoch 106 - Train Loss: 0.0440, Val Loss: 0.0445\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0445_9aa63612.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0509, Val Loss: 0.0477\n",
      "Epoch 32/2048 - Train Loss: 0.0478, Val Loss: 0.0442\n",
      "Epoch 48/2048 - Train Loss: 0.0463, Val Loss: 0.0431\n",
      "Epoch 64/2048 - Train Loss: 0.0454, Val Loss: 0.0429\n",
      "Epoch 80/2048 - Train Loss: 0.0447, Val Loss: 0.0429\n",
      "Epoch 96/2048 - Train Loss: 0.0442, Val Loss: 0.0430\n",
      "Early stopping at epoch 109 - Train Loss: 0.0438, Val Loss: 0.0425\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0425_9aa63612.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0510, Val Loss: 0.0468\n",
      "Epoch 32/2048 - Train Loss: 0.0479, Val Loss: 0.0445\n",
      "Epoch 48/2048 - Train Loss: 0.0464, Val Loss: 0.0433\n",
      "Epoch 64/2048 - Train Loss: 0.0456, Val Loss: 0.0428\n",
      "Epoch 80/2048 - Train Loss: 0.0450, Val Loss: 0.0429\n",
      "Early stopping at epoch 95 - Train Loss: 0.0443, Val Loss: 0.0432\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0432_9aa63612.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0509, Val Loss: 0.0463\n",
      "Epoch 32/2048 - Train Loss: 0.0479, Val Loss: 0.0440\n",
      "Epoch 48/2048 - Train Loss: 0.0464, Val Loss: 0.0433\n",
      "Epoch 64/2048 - Train Loss: 0.0455, Val Loss: 0.0437\n",
      "Epoch 80/2048 - Train Loss: 0.0448, Val Loss: 0.0428\n",
      "Early stopping at epoch 88 - Train Loss: 0.0446, Val Loss: 0.0424\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0424_9aa63612.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0529, Val Loss: 0.0486\n",
      "Epoch 32/2048 - Train Loss: 0.0486, Val Loss: 0.0450\n",
      "Epoch 48/2048 - Train Loss: 0.0467, Val Loss: 0.0440\n",
      "Epoch 64/2048 - Train Loss: 0.0456, Val Loss: 0.0431\n",
      "Epoch 80/2048 - Train Loss: 0.0449, Val Loss: 0.0426\n",
      "Epoch 96/2048 - Train Loss: 0.0443, Val Loss: 0.0435\n",
      "Early stopping at epoch 108 - Train Loss: 0.0441, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0421_9aa63612.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 1.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0469\n",
      "Epoch 32/2048 - Train Loss: 0.0479, Val Loss: 0.0439\n",
      "Epoch 48/2048 - Train Loss: 0.0463, Val Loss: 0.0431\n",
      "Epoch 64/2048 - Train Loss: 0.0453, Val Loss: 0.0422\n",
      "Epoch 80/2048 - Train Loss: 0.0446, Val Loss: 0.0417\n",
      "Epoch 96/2048 - Train Loss: 0.0441, Val Loss: 0.0420\n",
      "Early stopping at epoch 98 - Train Loss: 0.0441, Val Loss: 0.0416\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0416_26f6258a.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0507, Val Loss: 0.0459\n",
      "Epoch 32/2048 - Train Loss: 0.0478, Val Loss: 0.0439\n",
      "Epoch 48/2048 - Train Loss: 0.0462, Val Loss: 0.0428\n",
      "Epoch 64/2048 - Train Loss: 0.0453, Val Loss: 0.0424\n",
      "Epoch 80/2048 - Train Loss: 0.0448, Val Loss: 0.0438\n",
      "Epoch 96/2048 - Train Loss: 0.0442, Val Loss: 0.0419\n",
      "Epoch 112/2048 - Train Loss: 0.0436, Val Loss: 0.0421\n",
      "Early stopping at epoch 127 - Train Loss: 0.0433, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0421_26f6258a.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0506, Val Loss: 0.0464\n",
      "Epoch 32/2048 - Train Loss: 0.0477, Val Loss: 0.0438\n",
      "Epoch 48/2048 - Train Loss: 0.0462, Val Loss: 0.0434\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0425\n",
      "Epoch 80/2048 - Train Loss: 0.0446, Val Loss: 0.0418\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0424\n",
      "Epoch 112/2048 - Train Loss: 0.0436, Val Loss: 0.0421\n",
      "Early stopping at epoch 113 - Train Loss: 0.0436, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0421_26f6258a.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0508, Val Loss: 0.0462\n",
      "Epoch 32/2048 - Train Loss: 0.0478, Val Loss: 0.0442\n",
      "Epoch 48/2048 - Train Loss: 0.0463, Val Loss: 0.0433\n",
      "Epoch 64/2048 - Train Loss: 0.0453, Val Loss: 0.0430\n",
      "Epoch 80/2048 - Train Loss: 0.0446, Val Loss: 0.0421\n",
      "Epoch 96/2048 - Train Loss: 0.0441, Val Loss: 0.0421\n",
      "Epoch 112/2048 - Train Loss: 0.0438, Val Loss: 0.0424\n",
      "Epoch 128/2048 - Train Loss: 0.0434, Val Loss: 0.0423\n",
      "Early stopping at epoch 134 - Train Loss: 0.0433, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0421_26f6258a.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0510, Val Loss: 0.0463\n",
      "Epoch 32/2048 - Train Loss: 0.0479, Val Loss: 0.0440\n",
      "Epoch 48/2048 - Train Loss: 0.0463, Val Loss: 0.0429\n",
      "Epoch 64/2048 - Train Loss: 0.0455, Val Loss: 0.0431\n",
      "Epoch 80/2048 - Train Loss: 0.0448, Val Loss: 0.0420\n",
      "Epoch 96/2048 - Train Loss: 0.0443, Val Loss: 0.0419\n",
      "Early stopping at epoch 110 - Train Loss: 0.0439, Val Loss: 0.0422\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0422_26f6258a.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 1.75}\n",
      "Epoch 16/2048 - Train Loss: 0.0506, Val Loss: 0.0459\n",
      "Epoch 32/2048 - Train Loss: 0.0476, Val Loss: 0.0437\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0428\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0420\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0418\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0422\n",
      "Early stopping at epoch 109 - Train Loss: 0.0437, Val Loss: 0.0419\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0419_ed9bd865.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0459\n",
      "Epoch 32/2048 - Train Loss: 0.0475, Val Loss: 0.0435\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0423\n",
      "Epoch 80/2048 - Train Loss: 0.0445, Val Loss: 0.0420\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0418\n",
      "Epoch 112/2048 - Train Loss: 0.0436, Val Loss: 0.0420\n",
      "Early stopping at epoch 124 - Train Loss: 0.0433, Val Loss: 0.0418\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0418_ed9bd865.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0458\n",
      "Epoch 32/2048 - Train Loss: 0.0474, Val Loss: 0.0434\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0419\n",
      "Epoch 80/2048 - Train Loss: 0.0444, Val Loss: 0.0420\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0417\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0419\n",
      "Epoch 128/2048 - Train Loss: 0.0431, Val Loss: 0.0416\n",
      "Early stopping at epoch 133 - Train Loss: 0.0429, Val Loss: 0.0415\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0415_ed9bd865.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0507, Val Loss: 0.0462\n",
      "Epoch 32/2048 - Train Loss: 0.0476, Val Loss: 0.0435\n",
      "Epoch 48/2048 - Train Loss: 0.0461, Val Loss: 0.0426\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0420\n",
      "Epoch 80/2048 - Train Loss: 0.0445, Val Loss: 0.0418\n",
      "Epoch 96/2048 - Train Loss: 0.0441, Val Loss: 0.0417\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0415\n",
      "Epoch 128/2048 - Train Loss: 0.0433, Val Loss: 0.0418\n",
      "Early stopping at epoch 134 - Train Loss: 0.0431, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0413_ed9bd865.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0526, Val Loss: 0.0481\n",
      "Epoch 32/2048 - Train Loss: 0.0484, Val Loss: 0.0445\n",
      "Epoch 48/2048 - Train Loss: 0.0466, Val Loss: 0.0432\n",
      "Epoch 64/2048 - Train Loss: 0.0455, Val Loss: 0.0426\n",
      "Epoch 80/2048 - Train Loss: 0.0448, Val Loss: 0.0420\n",
      "Epoch 96/2048 - Train Loss: 0.0442, Val Loss: 0.0421\n",
      "Epoch 112/2048 - Train Loss: 0.0438, Val Loss: 0.0418\n",
      "Epoch 128/2048 - Train Loss: 0.0435, Val Loss: 0.0417\n",
      "Epoch 144/2048 - Train Loss: 0.0432, Val Loss: 0.0421\n",
      "Epoch 160/2048 - Train Loss: 0.0430, Val Loss: 0.0418\n",
      "Epoch 176/2048 - Train Loss: 0.0427, Val Loss: 0.0414\n",
      "Early stopping at epoch 191 - Train Loss: 0.0426, Val Loss: 0.0416\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0416_ed9bd865.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 2}\n",
      "Epoch 16/2048 - Train Loss: 0.0504, Val Loss: 0.0458\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0435\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0426\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0419\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0417\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0420\n",
      "Epoch 112/2048 - Train Loss: 0.0434, Val Loss: 0.0413\n",
      "Epoch 128/2048 - Train Loss: 0.0430, Val Loss: 0.0413\n",
      "Early stopping at epoch 135 - Train Loss: 0.0428, Val Loss: 0.0415\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0415_dfad76a6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0506, Val Loss: 0.0458\n",
      "Epoch 32/2048 - Train Loss: 0.0476, Val Loss: 0.0436\n",
      "Epoch 48/2048 - Train Loss: 0.0461, Val Loss: 0.0427\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0425\n",
      "Epoch 80/2048 - Train Loss: 0.0444, Val Loss: 0.0425\n",
      "Epoch 96/2048 - Train Loss: 0.0440, Val Loss: 0.0420\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0413\n",
      "Epoch 128/2048 - Train Loss: 0.0432, Val Loss: 0.0412\n",
      "Early stopping at epoch 141 - Train Loss: 0.0431, Val Loss: 0.0414\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0414_dfad76a6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0508, Val Loss: 0.0458\n",
      "Epoch 32/2048 - Train Loss: 0.0475, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0450, Val Loss: 0.0421\n",
      "Epoch 80/2048 - Train Loss: 0.0445, Val Loss: 0.0416\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0416\n",
      "Epoch 112/2048 - Train Loss: 0.0434, Val Loss: 0.0410\n",
      "Early stopping at epoch 128 - Train Loss: 0.0433, Val Loss: 0.0414\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0414_dfad76a6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0507, Val Loss: 0.0458\n",
      "Epoch 32/2048 - Train Loss: 0.0476, Val Loss: 0.0437\n",
      "Epoch 48/2048 - Train Loss: 0.0461, Val Loss: 0.0427\n",
      "Epoch 64/2048 - Train Loss: 0.0451, Val Loss: 0.0421\n",
      "Epoch 80/2048 - Train Loss: 0.0444, Val Loss: 0.0416\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0415\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0412\n",
      "Epoch 128/2048 - Train Loss: 0.0431, Val Loss: 0.0413\n",
      "Epoch 144/2048 - Train Loss: 0.0428, Val Loss: 0.0412\n",
      "Early stopping at epoch 147 - Train Loss: 0.0427, Val Loss: 0.0414\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0414_dfad76a6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0504, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0474, Val Loss: 0.0435\n",
      "Epoch 48/2048 - Train Loss: 0.0459, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0450, Val Loss: 0.0420\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0419\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0415\n",
      "Epoch 112/2048 - Train Loss: 0.0436, Val Loss: 0.0418\n",
      "Epoch 128/2048 - Train Loss: 0.0430, Val Loss: 0.0411\n",
      "Epoch 144/2048 - Train Loss: 0.0429, Val Loss: 0.0413\n",
      "Early stopping at epoch 159 - Train Loss: 0.0428, Val Loss: 0.0410\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0410_dfad76a6.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 2.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0512, Val Loss: 0.0464\n",
      "Epoch 32/2048 - Train Loss: 0.0479, Val Loss: 0.0438\n",
      "Epoch 48/2048 - Train Loss: 0.0462, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0452, Val Loss: 0.0423\n",
      "Epoch 80/2048 - Train Loss: 0.0444, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0415\n",
      "Epoch 112/2048 - Train Loss: 0.0436, Val Loss: 0.0417\n",
      "Epoch 128/2048 - Train Loss: 0.0431, Val Loss: 0.0411\n",
      "Epoch 144/2048 - Train Loss: 0.0430, Val Loss: 0.0410\n",
      "Early stopping at epoch 151 - Train Loss: 0.0427, Val Loss: 0.0412\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0412_b8a94b36.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0458\n",
      "Epoch 32/2048 - Train Loss: 0.0475, Val Loss: 0.0435\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0426\n",
      "Epoch 64/2048 - Train Loss: 0.0450, Val Loss: 0.0422\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0417\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0415\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0415\n",
      "Epoch 128/2048 - Train Loss: 0.0431, Val Loss: 0.0415\n",
      "Epoch 144/2048 - Train Loss: 0.0429, Val Loss: 0.0413\n",
      "Early stopping at epoch 145 - Train Loss: 0.0428, Val Loss: 0.0416\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0416_b8a94b36.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0506, Val Loss: 0.0457\n",
      "Epoch 32/2048 - Train Loss: 0.0477, Val Loss: 0.0436\n",
      "Epoch 48/2048 - Train Loss: 0.0461, Val Loss: 0.0429\n",
      "Epoch 64/2048 - Train Loss: 0.0453, Val Loss: 0.0423\n",
      "Epoch 80/2048 - Train Loss: 0.0445, Val Loss: 0.0423\n",
      "Epoch 96/2048 - Train Loss: 0.0440, Val Loss: 0.0417\n",
      "Epoch 112/2048 - Train Loss: 0.0438, Val Loss: 0.0414\n",
      "Epoch 128/2048 - Train Loss: 0.0433, Val Loss: 0.0415\n",
      "Early stopping at epoch 143 - Train Loss: 0.0430, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0413_b8a94b36.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0472, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0427\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0415\n",
      "Epoch 128/2048 - Train Loss: 0.0432, Val Loss: 0.0414\n",
      "Epoch 144/2048 - Train Loss: 0.0428, Val Loss: 0.0410\n",
      "Epoch 160/2048 - Train Loss: 0.0426, Val Loss: 0.0410\n",
      "Epoch 176/2048 - Train Loss: 0.0423, Val Loss: 0.0410\n",
      "Epoch 192/2048 - Train Loss: 0.0421, Val Loss: 0.0411\n",
      "Epoch 208/2048 - Train Loss: 0.0420, Val Loss: 0.0409\n",
      "Early stopping at epoch 215 - Train Loss: 0.0419, Val Loss: 0.0417\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0417_b8a94b36.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0504, Val Loss: 0.0457\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0435\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0421\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0416\n",
      "Epoch 96/2048 - Train Loss: 0.0437, Val Loss: 0.0414\n",
      "Epoch 112/2048 - Train Loss: 0.0432, Val Loss: 0.0417\n",
      "Early stopping at epoch 121 - Train Loss: 0.0432, Val Loss: 0.0412\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0412_b8a94b36.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 2.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0457\n",
      "Epoch 32/2048 - Train Loss: 0.0476, Val Loss: 0.0434\n",
      "Epoch 48/2048 - Train Loss: 0.0461, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0452, Val Loss: 0.0422\n",
      "Epoch 80/2048 - Train Loss: 0.0444, Val Loss: 0.0416\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0435, Val Loss: 0.0415\n",
      "Epoch 128/2048 - Train Loss: 0.0432, Val Loss: 0.0412\n",
      "Epoch 144/2048 - Train Loss: 0.0429, Val Loss: 0.0413\n",
      "Early stopping at epoch 153 - Train Loss: 0.0426, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0413_ce5af6b9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0457\n",
      "Epoch 32/2048 - Train Loss: 0.0474, Val Loss: 0.0434\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0447, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0418\n",
      "Epoch 96/2048 - Train Loss: 0.0437, Val Loss: 0.0410\n",
      "Early stopping at epoch 112 - Train Loss: 0.0432, Val Loss: 0.0412\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0412_ce5af6b9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0454\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0432\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0437, Val Loss: 0.0411\n",
      "Epoch 112/2048 - Train Loss: 0.0433, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0430, Val Loss: 0.0411\n",
      "Epoch 144/2048 - Train Loss: 0.0426, Val Loss: 0.0412\n",
      "Epoch 160/2048 - Train Loss: 0.0425, Val Loss: 0.0411\n",
      "Early stopping at epoch 174 - Train Loss: 0.0423, Val Loss: 0.0408\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0408_ce5af6b9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0453\n",
      "Epoch 32/2048 - Train Loss: 0.0474, Val Loss: 0.0430\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0450, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0437, Val Loss: 0.0412\n",
      "Epoch 112/2048 - Train Loss: 0.0434, Val Loss: 0.0412\n",
      "Epoch 128/2048 - Train Loss: 0.0430, Val Loss: 0.0413\n",
      "Early stopping at epoch 138 - Train Loss: 0.0428, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0413_ce5af6b9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0454\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0414\n",
      "Early stopping at epoch 84 - Train Loss: 0.0440, Val Loss: 0.0416\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0416_ce5af6b9.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 2.75}\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0472, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0425\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0410\n",
      "Epoch 112/2048 - Train Loss: 0.0433, Val Loss: 0.0411\n",
      "Epoch 128/2048 - Train Loss: 0.0428, Val Loss: 0.0409\n",
      "Early stopping at epoch 136 - Train Loss: 0.0428, Val Loss: 0.0412\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0412_714af954.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0475, Val Loss: 0.0430\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0410\n",
      "Epoch 112/2048 - Train Loss: 0.0433, Val Loss: 0.0412\n",
      "Early stopping at epoch 123 - Train Loss: 0.0432, Val Loss: 0.0411\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0411_714af954.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0474, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0419\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0412\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0433, Val Loss: 0.0412\n",
      "Epoch 128/2048 - Train Loss: 0.0431, Val Loss: 0.0411\n",
      "Epoch 144/2048 - Train Loss: 0.0428, Val Loss: 0.0409\n",
      "Epoch 160/2048 - Train Loss: 0.0426, Val Loss: 0.0408\n",
      "Early stopping at epoch 163 - Train Loss: 0.0425, Val Loss: 0.0409\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0409_714af954.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0424\n",
      "Epoch 64/2048 - Train Loss: 0.0449, Val Loss: 0.0418\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0417\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0414\n",
      "Epoch 112/2048 - Train Loss: 0.0432, Val Loss: 0.0411\n",
      "Epoch 128/2048 - Train Loss: 0.0429, Val Loss: 0.0411\n",
      "Early stopping at epoch 137 - Train Loss: 0.0430, Val Loss: 0.0412\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0412_714af954.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0472, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0415\n",
      "Epoch 112/2048 - Train Loss: 0.0433, Val Loss: 0.0411\n",
      "Epoch 128/2048 - Train Loss: 0.0429, Val Loss: 0.0412\n",
      "Early stopping at epoch 133 - Train Loss: 0.0427, Val Loss: 0.0410\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0410_714af954.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 3}\n",
      "Epoch 16/2048 - Train Loss: 0.0501, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0470, Val Loss: 0.0429\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0420\n",
      "Epoch 64/2048 - Train Loss: 0.0446, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0440, Val Loss: 0.0412\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0412\n",
      "Epoch 112/2048 - Train Loss: 0.0431, Val Loss: 0.0407\n",
      "Epoch 128/2048 - Train Loss: 0.0428, Val Loss: 0.0410\n",
      "Epoch 144/2048 - Train Loss: 0.0425, Val Loss: 0.0407\n",
      "Early stopping at epoch 147 - Train Loss: 0.0425, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0406_673670af.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0501, Val Loss: 0.0453\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0429\n",
      "Epoch 48/2048 - Train Loss: 0.0455, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0445, Val Loss: 0.0415\n",
      "Epoch 80/2048 - Train Loss: 0.0439, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0434, Val Loss: 0.0410\n",
      "Epoch 112/2048 - Train Loss: 0.0431, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0428, Val Loss: 0.0410\n",
      "Epoch 144/2048 - Train Loss: 0.0424, Val Loss: 0.0408\n",
      "Early stopping at epoch 149 - Train Loss: 0.0423, Val Loss: 0.0410\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0410_673670af.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0504, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0434\n",
      "Epoch 48/2048 - Train Loss: 0.0459, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0450, Val Loss: 0.0420\n",
      "Epoch 80/2048 - Train Loss: 0.0444, Val Loss: 0.0417\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0419\n",
      "Epoch 112/2048 - Train Loss: 0.0434, Val Loss: 0.0418\n",
      "Early stopping at epoch 115 - Train Loss: 0.0435, Val Loss: 0.0413\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0413_673670af.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0475, Val Loss: 0.0434\n",
      "Epoch 48/2048 - Train Loss: 0.0460, Val Loss: 0.0428\n",
      "Epoch 64/2048 - Train Loss: 0.0450, Val Loss: 0.0418\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0439, Val Loss: 0.0414\n",
      "Epoch 112/2048 - Train Loss: 0.0434, Val Loss: 0.0416\n",
      "Early stopping at epoch 123 - Train Loss: 0.0432, Val Loss: 0.0411\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0411_673670af.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0457\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0418\n",
      "Epoch 80/2048 - Train Loss: 0.0440, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0432, Val Loss: 0.0410\n",
      "Early stopping at epoch 120 - Train Loss: 0.0430, Val Loss: 0.0411\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0411_673670af.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 3.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0447, Val Loss: 0.0414\n",
      "Epoch 80/2048 - Train Loss: 0.0440, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0411\n",
      "Epoch 112/2048 - Train Loss: 0.0431, Val Loss: 0.0410\n",
      "Early stopping at epoch 127 - Train Loss: 0.0428, Val Loss: 0.0409\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0409_d7589c47.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0505, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0472, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0420\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0420\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0416\n",
      "Epoch 112/2048 - Train Loss: 0.0432, Val Loss: 0.0408\n",
      "Epoch 128/2048 - Train Loss: 0.0429, Val Loss: 0.0408\n",
      "Epoch 144/2048 - Train Loss: 0.0426, Val Loss: 0.0411\n",
      "Epoch 160/2048 - Train Loss: 0.0424, Val Loss: 0.0407\n",
      "Epoch 176/2048 - Train Loss: 0.0422, Val Loss: 0.0408\n",
      "Epoch 192/2048 - Train Loss: 0.0419, Val Loss: 0.0409\n",
      "Early stopping at epoch 193 - Train Loss: 0.0419, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0406_d7589c47.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0452\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0421\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0416\n",
      "Epoch 96/2048 - Train Loss: 0.0437, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0432, Val Loss: 0.0413\n",
      "Early stopping at epoch 126 - Train Loss: 0.0430, Val Loss: 0.0411\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0411_d7589c47.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0503, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0418\n",
      "Epoch 64/2048 - Train Loss: 0.0445, Val Loss: 0.0415\n",
      "Epoch 80/2048 - Train Loss: 0.0438, Val Loss: 0.0412\n",
      "Epoch 96/2048 - Train Loss: 0.0434, Val Loss: 0.0411\n",
      "Epoch 112/2048 - Train Loss: 0.0430, Val Loss: 0.0408\n",
      "Epoch 128/2048 - Train Loss: 0.0425, Val Loss: 0.0408\n",
      "Early stopping at epoch 139 - Train Loss: 0.0425, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0406_d7589c47.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0504, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0433\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0443, Val Loss: 0.0419\n",
      "Early stopping at epoch 92 - Train Loss: 0.0440, Val Loss: 0.0415\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0415_d7589c47.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.001953125, 'norm_type': 3.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0455\n",
      "Epoch 32/2048 - Train Loss: 0.0473, Val Loss: 0.0432\n",
      "Epoch 48/2048 - Train Loss: 0.0457, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0418\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0416\n",
      "Epoch 96/2048 - Train Loss: 0.0438, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0433, Val Loss: 0.0411\n",
      "Epoch 128/2048 - Train Loss: 0.0430, Val Loss: 0.0409\n",
      "Epoch 144/2048 - Train Loss: 0.0427, Val Loss: 0.0407\n",
      "Early stopping at epoch 160 - Train Loss: 0.0424, Val Loss: 0.0409\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0409_ed41f632.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0502, Val Loss: 0.0454\n",
      "Epoch 32/2048 - Train Loss: 0.0471, Val Loss: 0.0431\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0422\n",
      "Epoch 64/2048 - Train Loss: 0.0446, Val Loss: 0.0418\n",
      "Epoch 80/2048 - Train Loss: 0.0440, Val Loss: 0.0411\n",
      "Epoch 96/2048 - Train Loss: 0.0435, Val Loss: 0.0409\n",
      "Epoch 112/2048 - Train Loss: 0.0431, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0427, Val Loss: 0.0412\n",
      "Epoch 144/2048 - Train Loss: 0.0424, Val Loss: 0.0407\n",
      "Epoch 160/2048 - Train Loss: 0.0423, Val Loss: 0.0406\n",
      "Early stopping at epoch 171 - Train Loss: 0.0421, Val Loss: 0.0408\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0408_ed41f632.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0504, Val Loss: 0.0457\n",
      "Epoch 32/2048 - Train Loss: 0.0472, Val Loss: 0.0430\n",
      "Epoch 48/2048 - Train Loss: 0.0458, Val Loss: 0.0420\n",
      "Epoch 64/2048 - Train Loss: 0.0448, Val Loss: 0.0417\n",
      "Epoch 80/2048 - Train Loss: 0.0442, Val Loss: 0.0414\n",
      "Epoch 96/2048 - Train Loss: 0.0436, Val Loss: 0.0413\n",
      "Epoch 112/2048 - Train Loss: 0.0431, Val Loss: 0.0410\n",
      "Epoch 128/2048 - Train Loss: 0.0427, Val Loss: 0.0409\n",
      "Epoch 144/2048 - Train Loss: 0.0427, Val Loss: 0.0407\n",
      "Epoch 160/2048 - Train Loss: 0.0424, Val Loss: 0.0407\n",
      "Epoch 176/2048 - Train Loss: 0.0420, Val Loss: 0.0407\n",
      "Early stopping at epoch 180 - Train Loss: 0.0420, Val Loss: 0.0406\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0406_ed41f632.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0500, Val Loss: 0.0456\n",
      "Epoch 32/2048 - Train Loss: 0.0470, Val Loss: 0.0428\n",
      "Epoch 48/2048 - Train Loss: 0.0456, Val Loss: 0.0423\n",
      "Epoch 64/2048 - Train Loss: 0.0447, Val Loss: 0.0416\n",
      "Epoch 80/2048 - Train Loss: 0.0441, Val Loss: 0.0415\n",
      "Epoch 96/2048 - Train Loss: 0.0435, Val Loss: 0.0410\n",
      "Epoch 112/2048 - Train Loss: 0.0431, Val Loss: 0.0411\n",
      "Early stopping at epoch 122 - Train Loss: 0.0428, Val Loss: 0.0410\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0410_ed41f632.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0499, Val Loss: 0.0453\n",
      "Epoch 32/2048 - Train Loss: 0.0469, Val Loss: 0.0427\n",
      "Epoch 48/2048 - Train Loss: 0.0455, Val Loss: 0.0419\n",
      "Epoch 64/2048 - Train Loss: 0.0446, Val Loss: 0.0414\n",
      "Epoch 80/2048 - Train Loss: 0.0438, Val Loss: 0.0413\n",
      "Epoch 96/2048 - Train Loss: 0.0434, Val Loss: 0.0412\n",
      "Epoch 112/2048 - Train Loss: 0.0429, Val Loss: 0.0411\n",
      "Early stopping at epoch 113 - Train Loss: 0.0430, Val Loss: 0.0407\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0407_ed41f632.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 1}\n",
      "Epoch 16/2048 - Train Loss: 0.0544, Val Loss: 0.0522\n",
      "Epoch 32/2048 - Train Loss: 0.0511, Val Loss: 0.0499\n",
      "Epoch 48/2048 - Train Loss: 0.0497, Val Loss: 0.0525\n",
      "Early stopping at epoch 52 - Train Loss: 0.0494, Val Loss: 0.0496\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0496_12339adc.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0543, Val Loss: 0.0532\n",
      "Epoch 32/2048 - Train Loss: 0.0511, Val Loss: 0.0497\n",
      "Epoch 48/2048 - Train Loss: 0.0494, Val Loss: 0.0510\n",
      "Epoch 64/2048 - Train Loss: 0.0485, Val Loss: 0.0490\n",
      "Epoch 80/2048 - Train Loss: 0.0480, Val Loss: 0.0484\n",
      "Early stopping at epoch 89 - Train Loss: 0.0477, Val Loss: 0.0481\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0481_12339adc.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0557, Val Loss: 0.0534\n",
      "Epoch 32/2048 - Train Loss: 0.0525, Val Loss: 0.0532\n",
      "Epoch 48/2048 - Train Loss: 0.0509, Val Loss: 0.0515\n",
      "Epoch 64/2048 - Train Loss: 0.0500, Val Loss: 0.0506\n",
      "Early stopping at epoch 67 - Train Loss: 0.0499, Val Loss: 0.0505\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0505_12339adc.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0540, Val Loss: 0.0512\n",
      "Epoch 32/2048 - Train Loss: 0.0507, Val Loss: 0.0487\n",
      "Epoch 48/2048 - Train Loss: 0.0492, Val Loss: 0.0487\n",
      "Early stopping at epoch 59 - Train Loss: 0.0484, Val Loss: 0.0499\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0499_12339adc.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0541, Val Loss: 0.0513\n",
      "Epoch 32/2048 - Train Loss: 0.0510, Val Loss: 0.0516\n",
      "Epoch 48/2048 - Train Loss: 0.0495, Val Loss: 0.0493\n",
      "Epoch 64/2048 - Train Loss: 0.0486, Val Loss: 0.0492\n",
      "Early stopping at epoch 75 - Train Loss: 0.0479, Val Loss: 0.0500\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0500_12339adc.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 1.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0533, Val Loss: 0.0489\n",
      "Epoch 32/2048 - Train Loss: 0.0501, Val Loss: 0.0468\n",
      "Epoch 48/2048 - Train Loss: 0.0486, Val Loss: 0.0457\n",
      "Early stopping at epoch 62 - Train Loss: 0.0477, Val Loss: 0.0455\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0455_93eba380.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0536, Val Loss: 0.0492\n",
      "Epoch 32/2048 - Train Loss: 0.0506, Val Loss: 0.0472\n",
      "Epoch 48/2048 - Train Loss: 0.0490, Val Loss: 0.0454\n",
      "Epoch 64/2048 - Train Loss: 0.0480, Val Loss: 0.0457\n",
      "Epoch 80/2048 - Train Loss: 0.0474, Val Loss: 0.0456\n",
      "Epoch 96/2048 - Train Loss: 0.0469, Val Loss: 0.0448\n",
      "Epoch 112/2048 - Train Loss: 0.0465, Val Loss: 0.0457\n",
      "Early stopping at epoch 117 - Train Loss: 0.0463, Val Loss: 0.0453\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0453_93eba380.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0532, Val Loss: 0.0499\n",
      "Epoch 32/2048 - Train Loss: 0.0500, Val Loss: 0.0471\n",
      "Epoch 48/2048 - Train Loss: 0.0485, Val Loss: 0.0478\n",
      "Epoch 64/2048 - Train Loss: 0.0476, Val Loss: 0.0459\n",
      "Epoch 80/2048 - Train Loss: 0.0468, Val Loss: 0.0445\n",
      "Epoch 96/2048 - Train Loss: 0.0463, Val Loss: 0.0461\n",
      "Early stopping at epoch 107 - Train Loss: 0.0461, Val Loss: 0.0446\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0446_93eba380.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0545, Val Loss: 0.0510\n",
      "Epoch 32/2048 - Train Loss: 0.0504, Val Loss: 0.0469\n",
      "Epoch 48/2048 - Train Loss: 0.0487, Val Loss: 0.0453\n",
      "Epoch 64/2048 - Train Loss: 0.0477, Val Loss: 0.0456\n",
      "Epoch 80/2048 - Train Loss: 0.0469, Val Loss: 0.0453\n",
      "Epoch 96/2048 - Train Loss: 0.0464, Val Loss: 0.0446\n",
      "Epoch 112/2048 - Train Loss: 0.0461, Val Loss: 0.0446\n",
      "Epoch 128/2048 - Train Loss: 0.0458, Val Loss: 0.0463\n",
      "Early stopping at epoch 133 - Train Loss: 0.0456, Val Loss: 0.0466\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0466_93eba380.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0534, Val Loss: 0.0494\n",
      "Epoch 32/2048 - Train Loss: 0.0503, Val Loss: 0.0479\n",
      "Epoch 48/2048 - Train Loss: 0.0487, Val Loss: 0.0471\n",
      "Epoch 64/2048 - Train Loss: 0.0478, Val Loss: 0.0457\n",
      "Epoch 80/2048 - Train Loss: 0.0470, Val Loss: 0.0468\n",
      "Early stopping at epoch 86 - Train Loss: 0.0469, Val Loss: 0.0451\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0451_93eba380.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 1.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0534, Val Loss: 0.0487\n",
      "Epoch 32/2048 - Train Loss: 0.0503, Val Loss: 0.0470\n",
      "Epoch 48/2048 - Train Loss: 0.0487, Val Loss: 0.0453\n",
      "Epoch 64/2048 - Train Loss: 0.0479, Val Loss: 0.0452\n",
      "Epoch 80/2048 - Train Loss: 0.0472, Val Loss: 0.0452\n",
      "Epoch 96/2048 - Train Loss: 0.0466, Val Loss: 0.0445\n",
      "Early stopping at epoch 104 - Train Loss: 0.0464, Val Loss: 0.0452\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0452_771d7b50.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0528, Val Loss: 0.0482\n",
      "Epoch 32/2048 - Train Loss: 0.0497, Val Loss: 0.0459\n",
      "Epoch 48/2048 - Train Loss: 0.0482, Val Loss: 0.0454\n",
      "Epoch 64/2048 - Train Loss: 0.0473, Val Loss: 0.0442\n",
      "Epoch 80/2048 - Train Loss: 0.0466, Val Loss: 0.0444\n",
      "Epoch 96/2048 - Train Loss: 0.0461, Val Loss: 0.0444\n",
      "Early stopping at epoch 102 - Train Loss: 0.0460, Val Loss: 0.0442\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0442_771d7b50.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0534, Val Loss: 0.0489\n",
      "Epoch 32/2048 - Train Loss: 0.0501, Val Loss: 0.0463\n",
      "Epoch 48/2048 - Train Loss: 0.0487, Val Loss: 0.0454\n",
      "Epoch 64/2048 - Train Loss: 0.0478, Val Loss: 0.0453\n",
      "Epoch 80/2048 - Train Loss: 0.0472, Val Loss: 0.0449\n",
      "Epoch 96/2048 - Train Loss: 0.0467, Val Loss: 0.0455\n",
      "Early stopping at epoch 99 - Train Loss: 0.0466, Val Loss: 0.0447\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0447_771d7b50.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0528, Val Loss: 0.0480\n",
      "Epoch 32/2048 - Train Loss: 0.0497, Val Loss: 0.0458\n",
      "Epoch 48/2048 - Train Loss: 0.0484, Val Loss: 0.0451\n",
      "Early stopping at epoch 60 - Train Loss: 0.0476, Val Loss: 0.0452\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0452_771d7b50.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0533, Val Loss: 0.0486\n",
      "Epoch 32/2048 - Train Loss: 0.0501, Val Loss: 0.0459\n",
      "Epoch 48/2048 - Train Loss: 0.0486, Val Loss: 0.0452\n",
      "Epoch 64/2048 - Train Loss: 0.0476, Val Loss: 0.0445\n",
      "Epoch 80/2048 - Train Loss: 0.0469, Val Loss: 0.0441\n",
      "Early stopping at epoch 92 - Train Loss: 0.0466, Val Loss: 0.0444\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0444_771d7b50.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 1.75}\n",
      "Epoch 16/2048 - Train Loss: 0.0530, Val Loss: 0.0484\n",
      "Epoch 32/2048 - Train Loss: 0.0497, Val Loss: 0.0454\n",
      "Epoch 48/2048 - Train Loss: 0.0481, Val Loss: 0.0447\n",
      "Epoch 64/2048 - Train Loss: 0.0472, Val Loss: 0.0440\n",
      "Epoch 80/2048 - Train Loss: 0.0465, Val Loss: 0.0437\n",
      "Epoch 96/2048 - Train Loss: 0.0460, Val Loss: 0.0434\n",
      "Epoch 112/2048 - Train Loss: 0.0457, Val Loss: 0.0435\n",
      "Early stopping at epoch 115 - Train Loss: 0.0455, Val Loss: 0.0436\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0436_7b131ca7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0528, Val Loss: 0.0479\n",
      "Epoch 32/2048 - Train Loss: 0.0497, Val Loss: 0.0456\n",
      "Epoch 48/2048 - Train Loss: 0.0482, Val Loss: 0.0451\n",
      "Epoch 64/2048 - Train Loss: 0.0473, Val Loss: 0.0440\n",
      "Epoch 80/2048 - Train Loss: 0.0466, Val Loss: 0.0442\n",
      "Epoch 96/2048 - Train Loss: 0.0461, Val Loss: 0.0440\n",
      "Early stopping at epoch 110 - Train Loss: 0.0458, Val Loss: 0.0439\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0439_7b131ca7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0537, Val Loss: 0.0488\n",
      "Epoch 32/2048 - Train Loss: 0.0500, Val Loss: 0.0457\n",
      "Epoch 48/2048 - Train Loss: 0.0483, Val Loss: 0.0446\n",
      "Epoch 64/2048 - Train Loss: 0.0474, Val Loss: 0.0441\n",
      "Epoch 80/2048 - Train Loss: 0.0466, Val Loss: 0.0447\n",
      "Epoch 96/2048 - Train Loss: 0.0460, Val Loss: 0.0437\n",
      "Epoch 112/2048 - Train Loss: 0.0455, Val Loss: 0.0436\n",
      "Early stopping at epoch 118 - Train Loss: 0.0455, Val Loss: 0.0436\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0436_7b131ca7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0529, Val Loss: 0.0484\n",
      "Epoch 32/2048 - Train Loss: 0.0499, Val Loss: 0.0461\n",
      "Epoch 48/2048 - Train Loss: 0.0483, Val Loss: 0.0452\n",
      "Epoch 64/2048 - Train Loss: 0.0474, Val Loss: 0.0451\n",
      "Epoch 80/2048 - Train Loss: 0.0466, Val Loss: 0.0443\n",
      "Epoch 96/2048 - Train Loss: 0.0461, Val Loss: 0.0454\n",
      "Epoch 112/2048 - Train Loss: 0.0458, Val Loss: 0.0436\n",
      "Epoch 128/2048 - Train Loss: 0.0453, Val Loss: 0.0440\n",
      "Early stopping at epoch 131 - Train Loss: 0.0452, Val Loss: 0.0437\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0437_7b131ca7.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0529, Val Loss: 0.0482\n",
      "Epoch 32/2048 - Train Loss: 0.0497, Val Loss: 0.0455\n",
      "Epoch 48/2048 - Train Loss: 0.0482, Val Loss: 0.0448\n",
      "Epoch 64/2048 - Train Loss: 0.0471, Val Loss: 0.0443\n",
      "Epoch 80/2048 - Train Loss: 0.0465, Val Loss: 0.0438\n",
      "Epoch 96/2048 - Train Loss: 0.0458, Val Loss: 0.0435\n",
      "Epoch 112/2048 - Train Loss: 0.0455, Val Loss: 0.0438\n",
      "Epoch 128/2048 - Train Loss: 0.0451, Val Loss: 0.0436\n",
      "Early stopping at epoch 137 - Train Loss: 0.0450, Val Loss: 0.0436\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0436_7b131ca7.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 2}\n",
      "Epoch 16/2048 - Train Loss: 0.0526, Val Loss: 0.0477\n",
      "Epoch 32/2048 - Train Loss: 0.0494, Val Loss: 0.0451\n",
      "Epoch 48/2048 - Train Loss: 0.0479, Val Loss: 0.0444\n",
      "Epoch 64/2048 - Train Loss: 0.0469, Val Loss: 0.0438\n",
      "Epoch 80/2048 - Train Loss: 0.0462, Val Loss: 0.0434\n",
      "Epoch 96/2048 - Train Loss: 0.0458, Val Loss: 0.0436\n",
      "Epoch 112/2048 - Train Loss: 0.0454, Val Loss: 0.0434\n",
      "Epoch 128/2048 - Train Loss: 0.0450, Val Loss: 0.0432\n",
      "Epoch 144/2048 - Train Loss: 0.0449, Val Loss: 0.0429\n",
      "Epoch 160/2048 - Train Loss: 0.0445, Val Loss: 0.0429\n",
      "Early stopping at epoch 163 - Train Loss: 0.0444, Val Loss: 0.0428\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0428_77f688f6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0523, Val Loss: 0.0473\n",
      "Epoch 32/2048 - Train Loss: 0.0493, Val Loss: 0.0453\n",
      "Epoch 48/2048 - Train Loss: 0.0478, Val Loss: 0.0444\n",
      "Epoch 64/2048 - Train Loss: 0.0469, Val Loss: 0.0438\n",
      "Epoch 80/2048 - Train Loss: 0.0463, Val Loss: 0.0438\n",
      "Epoch 96/2048 - Train Loss: 0.0458, Val Loss: 0.0435\n",
      "Epoch 112/2048 - Train Loss: 0.0452, Val Loss: 0.0433\n",
      "Epoch 128/2048 - Train Loss: 0.0450, Val Loss: 0.0438\n",
      "Epoch 144/2048 - Train Loss: 0.0446, Val Loss: 0.0430\n",
      "Early stopping at epoch 157 - Train Loss: 0.0444, Val Loss: 0.0429\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0429_77f688f6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0521, Val Loss: 0.0481\n",
      "Epoch 32/2048 - Train Loss: 0.0492, Val Loss: 0.0452\n",
      "Epoch 48/2048 - Train Loss: 0.0476, Val Loss: 0.0439\n",
      "Epoch 64/2048 - Train Loss: 0.0468, Val Loss: 0.0436\n",
      "Epoch 80/2048 - Train Loss: 0.0459, Val Loss: 0.0436\n",
      "Epoch 96/2048 - Train Loss: 0.0456, Val Loss: 0.0440\n",
      "Early stopping at epoch 109 - Train Loss: 0.0453, Val Loss: 0.0433\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0433_77f688f6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0523, Val Loss: 0.0477\n",
      "Epoch 32/2048 - Train Loss: 0.0493, Val Loss: 0.0455\n",
      "Epoch 48/2048 - Train Loss: 0.0478, Val Loss: 0.0444\n",
      "Epoch 64/2048 - Train Loss: 0.0467, Val Loss: 0.0441\n",
      "Epoch 80/2048 - Train Loss: 0.0461, Val Loss: 0.0436\n",
      "Epoch 96/2048 - Train Loss: 0.0457, Val Loss: 0.0431\n",
      "Epoch 112/2048 - Train Loss: 0.0453, Val Loss: 0.0431\n",
      "Epoch 128/2048 - Train Loss: 0.0449, Val Loss: 0.0430\n",
      "Epoch 144/2048 - Train Loss: 0.0447, Val Loss: 0.0427\n",
      "Early stopping at epoch 160 - Train Loss: 0.0445, Val Loss: 0.0433\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0433_77f688f6.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0526, Val Loss: 0.0482\n",
      "Epoch 32/2048 - Train Loss: 0.0495, Val Loss: 0.0452\n",
      "Epoch 48/2048 - Train Loss: 0.0479, Val Loss: 0.0441\n",
      "Epoch 64/2048 - Train Loss: 0.0470, Val Loss: 0.0438\n",
      "Epoch 80/2048 - Train Loss: 0.0463, Val Loss: 0.0437\n",
      "Epoch 96/2048 - Train Loss: 0.0458, Val Loss: 0.0436\n",
      "Epoch 112/2048 - Train Loss: 0.0453, Val Loss: 0.0436\n",
      "Early stopping at epoch 117 - Train Loss: 0.0452, Val Loss: 0.0439\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0439_77f688f6.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 2.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0523, Val Loss: 0.0476\n",
      "Epoch 32/2048 - Train Loss: 0.0494, Val Loss: 0.0452\n",
      "Epoch 48/2048 - Train Loss: 0.0479, Val Loss: 0.0444\n",
      "Epoch 64/2048 - Train Loss: 0.0469, Val Loss: 0.0436\n",
      "Epoch 80/2048 - Train Loss: 0.0463, Val Loss: 0.0435\n",
      "Epoch 96/2048 - Train Loss: 0.0457, Val Loss: 0.0434\n",
      "Epoch 112/2048 - Train Loss: 0.0453, Val Loss: 0.0435\n",
      "Epoch 128/2048 - Train Loss: 0.0450, Val Loss: 0.0431\n",
      "Epoch 144/2048 - Train Loss: 0.0447, Val Loss: 0.0430\n",
      "Early stopping at epoch 157 - Train Loss: 0.0444, Val Loss: 0.0430\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0430_86ac738f.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0526, Val Loss: 0.0475\n",
      "Epoch 32/2048 - Train Loss: 0.0492, Val Loss: 0.0451\n",
      "Epoch 48/2048 - Train Loss: 0.0477, Val Loss: 0.0439\n",
      "Epoch 64/2048 - Train Loss: 0.0467, Val Loss: 0.0437\n",
      "Epoch 80/2048 - Train Loss: 0.0460, Val Loss: 0.0431\n",
      "Epoch 96/2048 - Train Loss: 0.0455, Val Loss: 0.0431\n",
      "Epoch 112/2048 - Train Loss: 0.0452, Val Loss: 0.0428\n",
      "Epoch 128/2048 - Train Loss: 0.0448, Val Loss: 0.0428\n",
      "Epoch 144/2048 - Train Loss: 0.0446, Val Loss: 0.0428\n",
      "Epoch 160/2048 - Train Loss: 0.0442, Val Loss: 0.0428\n",
      "Early stopping at epoch 175 - Train Loss: 0.0442, Val Loss: 0.0426\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0426_86ac738f.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0472\n",
      "Epoch 32/2048 - Train Loss: 0.0488, Val Loss: 0.0449\n",
      "Epoch 48/2048 - Train Loss: 0.0476, Val Loss: 0.0442\n",
      "Epoch 64/2048 - Train Loss: 0.0466, Val Loss: 0.0437\n",
      "Epoch 80/2048 - Train Loss: 0.0458, Val Loss: 0.0433\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0434\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0431\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0428\n",
      "Epoch 144/2048 - Train Loss: 0.0444, Val Loss: 0.0427\n",
      "Early stopping at epoch 160 - Train Loss: 0.0442, Val Loss: 0.0428\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0428_86ac738f.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0524, Val Loss: 0.0473\n",
      "Epoch 32/2048 - Train Loss: 0.0492, Val Loss: 0.0453\n",
      "Epoch 48/2048 - Train Loss: 0.0477, Val Loss: 0.0439\n",
      "Epoch 64/2048 - Train Loss: 0.0468, Val Loss: 0.0435\n",
      "Epoch 80/2048 - Train Loss: 0.0462, Val Loss: 0.0435\n",
      "Epoch 96/2048 - Train Loss: 0.0457, Val Loss: 0.0430\n",
      "Epoch 112/2048 - Train Loss: 0.0453, Val Loss: 0.0429\n",
      "Epoch 128/2048 - Train Loss: 0.0449, Val Loss: 0.0429\n",
      "Early stopping at epoch 138 - Train Loss: 0.0448, Val Loss: 0.0428\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0428_86ac738f.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0517, Val Loss: 0.0469\n",
      "Epoch 32/2048 - Train Loss: 0.0487, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0472, Val Loss: 0.0437\n",
      "Epoch 64/2048 - Train Loss: 0.0463, Val Loss: 0.0431\n",
      "Epoch 80/2048 - Train Loss: 0.0456, Val Loss: 0.0428\n",
      "Epoch 96/2048 - Train Loss: 0.0451, Val Loss: 0.0428\n",
      "Epoch 112/2048 - Train Loss: 0.0447, Val Loss: 0.0428\n",
      "Early stopping at epoch 116 - Train Loss: 0.0448, Val Loss: 0.0427\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0427_86ac738f.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 2.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0521, Val Loss: 0.0475\n",
      "Epoch 32/2048 - Train Loss: 0.0491, Val Loss: 0.0449\n",
      "Epoch 48/2048 - Train Loss: 0.0475, Val Loss: 0.0440\n",
      "Epoch 64/2048 - Train Loss: 0.0467, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0460, Val Loss: 0.0428\n",
      "Early stopping at epoch 96 - Train Loss: 0.0455, Val Loss: 0.0433\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0433_00dba9fd.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0521, Val Loss: 0.0476\n",
      "Epoch 32/2048 - Train Loss: 0.0491, Val Loss: 0.0448\n",
      "Epoch 48/2048 - Train Loss: 0.0476, Val Loss: 0.0439\n",
      "Epoch 64/2048 - Train Loss: 0.0466, Val Loss: 0.0434\n",
      "Epoch 80/2048 - Train Loss: 0.0461, Val Loss: 0.0434\n",
      "Epoch 96/2048 - Train Loss: 0.0456, Val Loss: 0.0430\n",
      "Epoch 112/2048 - Train Loss: 0.0451, Val Loss: 0.0431\n",
      "Epoch 128/2048 - Train Loss: 0.0447, Val Loss: 0.0429\n",
      "Epoch 144/2048 - Train Loss: 0.0445, Val Loss: 0.0427\n",
      "Early stopping at epoch 155 - Train Loss: 0.0443, Val Loss: 0.0428\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0428_00dba9fd.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0520, Val Loss: 0.0472\n",
      "Epoch 32/2048 - Train Loss: 0.0490, Val Loss: 0.0449\n",
      "Epoch 48/2048 - Train Loss: 0.0474, Val Loss: 0.0437\n",
      "Epoch 64/2048 - Train Loss: 0.0465, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0458, Val Loss: 0.0431\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0432\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0428\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0429\n",
      "Epoch 144/2048 - Train Loss: 0.0443, Val Loss: 0.0425\n",
      "Epoch 160/2048 - Train Loss: 0.0440, Val Loss: 0.0425\n",
      "Epoch 176/2048 - Train Loss: 0.0438, Val Loss: 0.0425\n",
      "Epoch 192/2048 - Train Loss: 0.0436, Val Loss: 0.0425\n",
      "Early stopping at epoch 206 - Train Loss: 0.0435, Val Loss: 0.0424\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0424_00dba9fd.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0521, Val Loss: 0.0471\n",
      "Epoch 32/2048 - Train Loss: 0.0491, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0476, Val Loss: 0.0440\n",
      "Epoch 64/2048 - Train Loss: 0.0466, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0461, Val Loss: 0.0432\n",
      "Epoch 96/2048 - Train Loss: 0.0456, Val Loss: 0.0428\n",
      "Epoch 112/2048 - Train Loss: 0.0451, Val Loss: 0.0428\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0427\n",
      "Epoch 144/2048 - Train Loss: 0.0445, Val Loss: 0.0432\n",
      "Epoch 160/2048 - Train Loss: 0.0442, Val Loss: 0.0425\n",
      "Early stopping at epoch 172 - Train Loss: 0.0440, Val Loss: 0.0425\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0425_00dba9fd.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0473\n",
      "Epoch 32/2048 - Train Loss: 0.0489, Val Loss: 0.0448\n",
      "Epoch 48/2048 - Train Loss: 0.0475, Val Loss: 0.0438\n",
      "Epoch 64/2048 - Train Loss: 0.0464, Val Loss: 0.0438\n",
      "Epoch 80/2048 - Train Loss: 0.0459, Val Loss: 0.0430\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0433\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0428\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0430\n",
      "Epoch 144/2048 - Train Loss: 0.0443, Val Loss: 0.0426\n",
      "Epoch 160/2048 - Train Loss: 0.0442, Val Loss: 0.0429\n",
      "Early stopping at epoch 170 - Train Loss: 0.0440, Val Loss: 0.0428\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0428_00dba9fd.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 2.75}\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0471\n",
      "Epoch 32/2048 - Train Loss: 0.0490, Val Loss: 0.0446\n",
      "Epoch 48/2048 - Train Loss: 0.0474, Val Loss: 0.0435\n",
      "Epoch 64/2048 - Train Loss: 0.0464, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0457, Val Loss: 0.0428\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0432\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0424\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0423\n",
      "Early stopping at epoch 129 - Train Loss: 0.0446, Val Loss: 0.0427\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0427_acb586f9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0518, Val Loss: 0.0474\n",
      "Epoch 32/2048 - Train Loss: 0.0488, Val Loss: 0.0445\n",
      "Epoch 48/2048 - Train Loss: 0.0474, Val Loss: 0.0437\n",
      "Epoch 64/2048 - Train Loss: 0.0464, Val Loss: 0.0434\n",
      "Epoch 80/2048 - Train Loss: 0.0457, Val Loss: 0.0432\n",
      "Epoch 96/2048 - Train Loss: 0.0452, Val Loss: 0.0431\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0427\n",
      "Early stopping at epoch 125 - Train Loss: 0.0446, Val Loss: 0.0427\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0427_acb586f9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0474\n",
      "Epoch 32/2048 - Train Loss: 0.0489, Val Loss: 0.0448\n",
      "Epoch 48/2048 - Train Loss: 0.0474, Val Loss: 0.0440\n",
      "Epoch 64/2048 - Train Loss: 0.0464, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0458, Val Loss: 0.0430\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0430\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0429\n",
      "Early stopping at epoch 121 - Train Loss: 0.0447, Val Loss: 0.0426\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0426_acb586f9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0470\n",
      "Epoch 32/2048 - Train Loss: 0.0488, Val Loss: 0.0445\n",
      "Epoch 48/2048 - Train Loss: 0.0472, Val Loss: 0.0440\n",
      "Epoch 64/2048 - Train Loss: 0.0463, Val Loss: 0.0432\n",
      "Epoch 80/2048 - Train Loss: 0.0456, Val Loss: 0.0429\n",
      "Epoch 96/2048 - Train Loss: 0.0452, Val Loss: 0.0426\n",
      "Epoch 112/2048 - Train Loss: 0.0447, Val Loss: 0.0427\n",
      "Early stopping at epoch 124 - Train Loss: 0.0445, Val Loss: 0.0426\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0426_acb586f9.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0522, Val Loss: 0.0476\n",
      "Epoch 32/2048 - Train Loss: 0.0490, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0475, Val Loss: 0.0439\n",
      "Epoch 64/2048 - Train Loss: 0.0465, Val Loss: 0.0434\n",
      "Epoch 80/2048 - Train Loss: 0.0459, Val Loss: 0.0428\n",
      "Early stopping at epoch 96 - Train Loss: 0.0453, Val Loss: 0.0430\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0430_acb586f9.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 3}\n",
      "Epoch 16/2048 - Train Loss: 0.0520, Val Loss: 0.0471\n",
      "Epoch 32/2048 - Train Loss: 0.0487, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0473, Val Loss: 0.0439\n",
      "Epoch 64/2048 - Train Loss: 0.0464, Val Loss: 0.0430\n",
      "Epoch 80/2048 - Train Loss: 0.0456, Val Loss: 0.0431\n",
      "Epoch 96/2048 - Train Loss: 0.0452, Val Loss: 0.0431\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0425\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0426\n",
      "Early stopping at epoch 129 - Train Loss: 0.0445, Val Loss: 0.0426\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0426_94624073.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0472\n",
      "Epoch 32/2048 - Train Loss: 0.0488, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0474, Val Loss: 0.0440\n",
      "Epoch 64/2048 - Train Loss: 0.0464, Val Loss: 0.0432\n",
      "Epoch 80/2048 - Train Loss: 0.0458, Val Loss: 0.0432\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0427\n",
      "Epoch 112/2048 - Train Loss: 0.0448, Val Loss: 0.0426\n",
      "Epoch 128/2048 - Train Loss: 0.0446, Val Loss: 0.0426\n",
      "Early stopping at epoch 132 - Train Loss: 0.0443, Val Loss: 0.0425\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0425_94624073.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0471\n",
      "Epoch 32/2048 - Train Loss: 0.0490, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0474, Val Loss: 0.0438\n",
      "Epoch 64/2048 - Train Loss: 0.0465, Val Loss: 0.0432\n",
      "Epoch 80/2048 - Train Loss: 0.0458, Val Loss: 0.0429\n",
      "Early stopping at epoch 93 - Train Loss: 0.0455, Val Loss: 0.0432\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0432_94624073.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0520, Val Loss: 0.0470\n",
      "Epoch 32/2048 - Train Loss: 0.0490, Val Loss: 0.0446\n",
      "Epoch 48/2048 - Train Loss: 0.0476, Val Loss: 0.0436\n",
      "Epoch 64/2048 - Train Loss: 0.0465, Val Loss: 0.0433\n",
      "Epoch 80/2048 - Train Loss: 0.0457, Val Loss: 0.0429\n",
      "Epoch 96/2048 - Train Loss: 0.0453, Val Loss: 0.0428\n",
      "Epoch 112/2048 - Train Loss: 0.0450, Val Loss: 0.0430\n",
      "Epoch 128/2048 - Train Loss: 0.0447, Val Loss: 0.0423\n",
      "Early stopping at epoch 144 - Train Loss: 0.0445, Val Loss: 0.0426\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0426_94624073.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0469\n",
      "Epoch 32/2048 - Train Loss: 0.0487, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0473, Val Loss: 0.0434\n",
      "Epoch 64/2048 - Train Loss: 0.0463, Val Loss: 0.0431\n",
      "Epoch 80/2048 - Train Loss: 0.0456, Val Loss: 0.0429\n",
      "Epoch 96/2048 - Train Loss: 0.0452, Val Loss: 0.0427\n",
      "Early stopping at epoch 107 - Train Loss: 0.0448, Val Loss: 0.0428\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0428_94624073.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 3.25}\n",
      "Epoch 16/2048 - Train Loss: 0.0515, Val Loss: 0.0468\n",
      "Epoch 32/2048 - Train Loss: 0.0486, Val Loss: 0.0443\n",
      "Epoch 48/2048 - Train Loss: 0.0470, Val Loss: 0.0434\n",
      "Epoch 64/2048 - Train Loss: 0.0461, Val Loss: 0.0428\n",
      "Epoch 80/2048 - Train Loss: 0.0454, Val Loss: 0.0425\n",
      "Epoch 96/2048 - Train Loss: 0.0449, Val Loss: 0.0424\n",
      "Epoch 112/2048 - Train Loss: 0.0445, Val Loss: 0.0423\n",
      "Epoch 128/2048 - Train Loss: 0.0442, Val Loss: 0.0422\n",
      "Early stopping at epoch 137 - Train Loss: 0.0440, Val Loss: 0.0421\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0421_14d5dcb2.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0523, Val Loss: 0.0475\n",
      "Epoch 32/2048 - Train Loss: 0.0493, Val Loss: 0.0453\n",
      "Epoch 48/2048 - Train Loss: 0.0478, Val Loss: 0.0442\n",
      "Epoch 64/2048 - Train Loss: 0.0469, Val Loss: 0.0437\n",
      "Epoch 80/2048 - Train Loss: 0.0461, Val Loss: 0.0435\n",
      "Epoch 96/2048 - Train Loss: 0.0456, Val Loss: 0.0433\n",
      "Epoch 112/2048 - Train Loss: 0.0452, Val Loss: 0.0430\n",
      "Early stopping at epoch 127 - Train Loss: 0.0450, Val Loss: 0.0433\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0433_14d5dcb2.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0519, Val Loss: 0.0473\n",
      "Epoch 32/2048 - Train Loss: 0.0488, Val Loss: 0.0448\n",
      "Epoch 48/2048 - Train Loss: 0.0472, Val Loss: 0.0437\n",
      "Epoch 64/2048 - Train Loss: 0.0462, Val Loss: 0.0434\n",
      "Epoch 80/2048 - Train Loss: 0.0457, Val Loss: 0.0430\n",
      "Epoch 96/2048 - Train Loss: 0.0450, Val Loss: 0.0429\n",
      "Early stopping at epoch 108 - Train Loss: 0.0447, Val Loss: 0.0429\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_2_0.0429_14d5dcb2.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0517, Val Loss: 0.0469\n",
      "Epoch 32/2048 - Train Loss: 0.0486, Val Loss: 0.0447\n",
      "Epoch 48/2048 - Train Loss: 0.0472, Val Loss: 0.0437\n",
      "Epoch 64/2048 - Train Loss: 0.0463, Val Loss: 0.0434\n",
      "Epoch 80/2048 - Train Loss: 0.0455, Val Loss: 0.0427\n",
      "Epoch 96/2048 - Train Loss: 0.0451, Val Loss: 0.0426\n",
      "Epoch 112/2048 - Train Loss: 0.0446, Val Loss: 0.0426\n",
      "Epoch 128/2048 - Train Loss: 0.0443, Val Loss: 0.0423\n",
      "Epoch 144/2048 - Train Loss: 0.0440, Val Loss: 0.0424\n",
      "Epoch 160/2048 - Train Loss: 0.0438, Val Loss: 0.0422\n",
      "Epoch 176/2048 - Train Loss: 0.0437, Val Loss: 0.0421\n",
      "Early stopping at epoch 179 - Train Loss: 0.0436, Val Loss: 0.0423\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_3_0.0423_14d5dcb2.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0520, Val Loss: 0.0473\n",
      "Epoch 32/2048 - Train Loss: 0.0488, Val Loss: 0.0446\n",
      "Epoch 48/2048 - Train Loss: 0.0473, Val Loss: 0.0436\n",
      "Epoch 64/2048 - Train Loss: 0.0465, Val Loss: 0.0431\n",
      "Epoch 80/2048 - Train Loss: 0.0457, Val Loss: 0.0430\n",
      "Epoch 96/2048 - Train Loss: 0.0452, Val Loss: 0.0427\n",
      "Epoch 112/2048 - Train Loss: 0.0449, Val Loss: 0.0429\n",
      "Epoch 128/2048 - Train Loss: 0.0444, Val Loss: 0.0425\n",
      "Epoch 144/2048 - Train Loss: 0.0442, Val Loss: 0.0425\n",
      "Epoch 160/2048 - Train Loss: 0.0439, Val Loss: 0.0426\n",
      "Epoch 176/2048 - Train Loss: 0.0437, Val Loss: 0.0424\n",
      "Epoch 192/2048 - Train Loss: 0.0435, Val Loss: 0.0424\n",
      "Early stopping at epoch 193 - Train Loss: 0.0436, Val Loss: 0.0423\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_4_0.0423_14d5dcb2.pth\n",
      "Testing parameters: {'learning_rate': 0.0009765625, 'batch_size': 32, 'epochs': 2048, 'dropout_rate': 0.0, 'input_size': 784, 'encoder_PE_nodes': [800, 200, 10], 'encoder_PE_activations': ['relu', 'sigmoid', 'relu'], 'decoder_PE_nodes': [200, 800, 784], 'decoder_PE_activations': ['relu', 'sigmoid', 'sigmoid'], 'loss': 'custom', '_lambda': 0.00390625, 'norm_type': 3.5}\n",
      "Epoch 16/2048 - Train Loss: 0.0518, Val Loss: 0.0470\n",
      "Epoch 32/2048 - Train Loss: 0.0487, Val Loss: 0.0448\n",
      "Epoch 48/2048 - Train Loss: 0.0471, Val Loss: 0.0436\n",
      "Epoch 64/2048 - Train Loss: 0.0463, Val Loss: 0.0432\n",
      "Epoch 80/2048 - Train Loss: 0.0456, Val Loss: 0.0428\n",
      "Epoch 96/2048 - Train Loss: 0.0450, Val Loss: 0.0428\n",
      "Epoch 112/2048 - Train Loss: 0.0447, Val Loss: 0.0424\n",
      "Epoch 128/2048 - Train Loss: 0.0443, Val Loss: 0.0424\n",
      "Epoch 144/2048 - Train Loss: 0.0439, Val Loss: 0.0422\n",
      "Early stopping at epoch 151 - Train Loss: 0.0440, Val Loss: 0.0422\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_0_0.0422_7c67919c.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0522, Val Loss: 0.0474\n",
      "Epoch 32/2048 - Train Loss: 0.0491, Val Loss: 0.0451\n",
      "Epoch 48/2048 - Train Loss: 0.0478, Val Loss: 0.0441\n",
      "Epoch 64/2048 - Train Loss: 0.0467, Val Loss: 0.0437\n",
      "Epoch 80/2048 - Train Loss: 0.0460, Val Loss: 0.0433\n",
      "Epoch 96/2048 - Train Loss: 0.0455, Val Loss: 0.0430\n",
      "Epoch 112/2048 - Train Loss: 0.0451, Val Loss: 0.0429\n",
      "Epoch 128/2048 - Train Loss: 0.0447, Val Loss: 0.0426\n",
      "Epoch 144/2048 - Train Loss: 0.0444, Val Loss: 0.0428\n",
      "Early stopping at epoch 150 - Train Loss: 0.0443, Val Loss: 0.0427\n",
      "Model saved to ./3d_grid/ConfigurableSAE_3d_grid_1_0.0427_7c67919c.pth\n",
      "Epoch 16/2048 - Train Loss: 0.0517, Val Loss: 0.0468\n",
      "Epoch 32/2048 - Train Loss: 0.0486, Val Loss: 0.0444\n",
      "Epoch 48/2048 - Train Loss: 0.0470, Val Loss: 0.0435\n"
     ]
    }
   ],
   "source": [
    "#unit_test()\n",
    "testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Generating Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
