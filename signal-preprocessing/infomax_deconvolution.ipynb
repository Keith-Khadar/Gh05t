{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information-Maximization Approach to Blind Separation and Blind Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports / Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to True to use GPU (CuPy) if available, or False to use CPU (NumPy/Scipy)\n",
    "USE_GPU = False\n",
    "\n",
    "# -------------------------------\n",
    "# Import libraries and set backend alias\n",
    "# -------------------------------\n",
    "import numpy as np      # for CPU-based I/O and plotting helper conversions\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import time as tick\n",
    "\n",
    "# Try to import CuPy\n",
    "try:\n",
    "    import cupy as cp\n",
    "    gpu_available = True\n",
    "except ImportError:\n",
    "    gpu_available = False\n",
    "\n",
    "# Decide which backend to use for array operations:\n",
    "if USE_GPU and gpu_available:\n",
    "    xp = cp\n",
    "else:\n",
    "    import numpy as xp  # if GPU not used or not available, use NumPy\n",
    "    gpu_available = False  # force CPU mode\n",
    "\n",
    "# For signal processing, try to use CuPy’s versions if available.\n",
    "# If not, fall back to SciPy’s functions.\n",
    "if USE_GPU and gpu_available:\n",
    "    try:\n",
    "        from cupyx.scipy.signal import firwin, freqz\n",
    "        try:\n",
    "            from cupyx.scipy.signal import lfilter\n",
    "            has_cupyx = True\n",
    "        except ImportError:\n",
    "            # Fall back to SciPy's lfilter if CuPy's is not available.\n",
    "            from scipy.signal import lfilter\n",
    "            has_cupyx = False\n",
    "    except ImportError:\n",
    "        from scipy.signal import lfilter, firwin, freqz\n",
    "        has_cupyx = False\n",
    "else:\n",
    "    from scipy.signal import lfilter, firwin, freqz\n",
    "    has_cupyx = False\n",
    "\n",
    "if USE_GPU and gpu_available:\n",
    "    try:\n",
    "        sliding_window_view = xp.lib.stride_tricks.sliding_window_view\n",
    "    except AttributeError:\n",
    "        # Fallback implementation for 1D arrays.\n",
    "        def sliding_window_view(x, window_shape):\n",
    "            n = x.shape[0] - window_shape + 1\n",
    "            return xp.stack([x[i:i+window_shape] for i in range(n)])\n",
    "else:\n",
    "    from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# Helper to convert arrays to CPU for plotting and I/O.\n",
    "if USE_GPU and gpu_available:\n",
    "    to_cpu = cp.asnumpy\n",
    "else:\n",
    "    to_cpu = lambda x: x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "x_speech_cpu, fs_speech = sf.read(\"speech.WAV\")\n",
    "x_speech = xp.asarray(x_speech_cpu.astype(np.float64))\n",
    "\n",
    "# Example parameters\n",
    "noise_variances = [0.1, 0.3, 1.0]\n",
    "M_candidates = [64, 128, 256, 512]\n",
    "L_candidates = [4, 8, 16, 32, 64]\n",
    "eta_candidates = [3**(-i) for i in range(2,8)]\n",
    "est_cdf_candidates = ['sigmoid', 'tanh']\n",
    "\n",
    "print(\"Speech sampling rate:\", fs_speech)\n",
    "plt.figure()\n",
    "plt.plot(to_cpu(x_speech))\n",
    "plt.title(\"Speech Input\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Low-Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = 1000   # Cutoff frequency in Hz\n",
    "numtaps = 501  # Filter order (should be odd)\n",
    "\n",
    "# Design FIR filter (firwin always returns a NumPy array; we then convert to xp array)\n",
    "fir_coeff_cpu = firwin(numtaps, fc, fs=fs_speech, pass_zero=True)\n",
    "fir_coeff = xp.asarray(fir_coeff_cpu)\n",
    "\n",
    "# Compute frequency response (using the chosen signal processing functions)\n",
    "w, h = freqz(fir_coeff_cpu, worN=8000)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(to_cpu(w * fs_speech / (2 * np.pi)),\n",
    "         20 * np.log10((np.abs(h))), 'b')\n",
    "plt.title('FIR Lowpass Filter Frequency Response')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain (dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Memory-less Monotonic Mapping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + xp.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return xp.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - xp.tanh(x)**2\n",
    "\n",
    "def gaussian(x):\n",
    "    return xp.exp(-x**2)\n",
    "\n",
    "def gaussian_derivative(x):\n",
    "    return -2 * x * xp.exp(-x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_plant(x, fir_coeff=None):\n",
    "    \"\"\"\n",
    "    Applies an unknown plant operation:\n",
    "      - If fir_coeff is provided, filters x using the FIR filter.\n",
    "      - Otherwise, applies a recursive difference equation.\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    if fir_coeff is not None:\n",
    "        # If using GPU with cupyx support, call lfilter directly on xp arrays.\n",
    "        if USE_GPU and gpu_available and has_cupyx:\n",
    "            y = lfilter(fir_coeff, 1, x)\n",
    "        else:\n",
    "            # Otherwise, convert inputs to NumPy arrays for SciPy's lfilter\n",
    "            x_cpu = to_cpu(x)\n",
    "            fir_cpu = to_cpu(fir_coeff)\n",
    "            y_cpu = lfilter(fir_cpu, 1, x_cpu)\n",
    "            y = xp.asarray(y_cpu)  # Convert the result back to the chosen backend\n",
    "    else:\n",
    "        y = xp.zeros(N, dtype=x.dtype)\n",
    "        for n in range(N):\n",
    "            if n == 0:\n",
    "                y[n] = x[n]\n",
    "            elif n < 10:\n",
    "                y[n] = y[n-1] + x[n]\n",
    "            else:\n",
    "                y[n] = y[n-1] + x[n] - x[n-10]\n",
    "    return y\n",
    "\n",
    "def add_noise(y, noise_var=0.1, seed=0):\n",
    "    xp.random.seed(seed)\n",
    "    noise = xp.sqrt(noise_var) * xp.random.randn(y.shape[0])\n",
    "    return y + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_true(M, FIR_coeffs=None):\n",
    "    if FIR_coeffs is None:\n",
    "        w_true = xp.ones(10)\n",
    "    else:\n",
    "        w_true = FIR_coeffs\n",
    "    if M <= 10:\n",
    "        return w_true\n",
    "    else:\n",
    "        return xp.concatenate((w_true, xp.zeros(M-10)))\n",
    "\n",
    "def compute_weighted_snr(w_est, FIR_coeffs=None):\n",
    "    M = w_est.shape[0]\n",
    "    if FIR_coeffs is not None:\n",
    "        w_true = get_w_true(M, FIR_coeffs)\n",
    "    else:\n",
    "        w_true = get_w_true(M)\n",
    "    if w_true.shape[0] > w_est.shape[0]:\n",
    "        w_est = xp.concatenate((w_est, xp.zeros(w_true.shape[0]-w_est.shape[0])))\n",
    "    num = xp.dot(w_true, w_true)\n",
    "    diff = w_true - w_est\n",
    "    den = xp.dot(diff, diff)\n",
    "    if den < 1e-15:\n",
    "        return 999.0\n",
    "    return 10.0 * xp.log10(num / den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILENAME = \"all_results.csv\"\n",
    "PLOT_DIR = \"plots\"\n",
    "if not os.path.exists(PLOT_DIR):\n",
    "    os.makedirs(PLOT_DIR)\n",
    "def plot_and_save(sig_true, sig_pred, figname, title=\"Comparison\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(to_cpu(sig_true), label=\"Actual Output\", alpha=0.7)\n",
    "    plt.plot(to_cpu(sig_pred), label=\"Predicted Output\", alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Sample index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR, figname), dpi=150)\n",
    "def plot_comparison(d, x, y, title=\"\", dir='/comparison'):\n",
    "    length = min(d.shape[0], x.shape[0], y.shape[0])\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(to_cpu(d[:length]), label=\"True Signal\", alpha=0.7)\n",
    "    plt.plot(to_cpu(x[:length]), label=\"Noisy Observed Input\", alpha=0.7)\n",
    "    plt.plot(to_cpu(y[:length]), label=\"Predicted Input\", alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Sample index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(PLOT_DIR+dir, title + \".png\"), dpi=150)\n",
    "def plot_comparison_fft(d, x, y, title=\"\", dir='/comparison_fft'):\n",
    "    length = min(d.shape[0], x.shape[0], y.shape[0])\n",
    "    plt.figure(figsize=(8,4))\n",
    "    xticks = np.fft.fftfreq(length, 1/fs_speech)\n",
    "    plt.xticks(xticks)\n",
    "    plt.plot(np.abs(np.fft.fft(to_cpu(d), length)), label=\"True Signal\", alpha=0.7)\n",
    "    plt.plot(np.abs(np.fft.fft(to_cpu(x), length)), label=\"Noisy Observed Input\", alpha=0.7)\n",
    "    plt.plot(np.abs(np.fft.fft(to_cpu(y), length)), label=\"Predicted Input\", alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Sample index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(PLOT_DIR+dir, title + \".png\"), dpi=150)\n",
    "def plot_weight_tracks(avg_w_track, std_w_track, time_steps, M, title, xlabel=\"Sample index\", ylabel=\"Weight\", max_pts=500, dir='/weight_tracks'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for m in range(M):\n",
    "        plt.plot(to_cpu(time_steps), to_cpu(avg_w_track[:, m]), label=f\"w[{m}]\")\n",
    "    plt.title(f\"Weight Tracks: {title}\")\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Weight Value\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOT_DIR+'/weight_tracks', title + \".png\"), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind Deconvolution Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blind Deconvolution Algorithms CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_max_deconvolution_gaussian_pdf(x, w, filter_length=50, learning_rate=0.01, non_linearity='sigmoid'):\n",
    "    if w.shape[0] != filter_length:\n",
    "        raise ValueError(\"Filter length must match the length of the initial filter w.\")\n",
    "    if x.shape[0] != filter_length:\n",
    "        raise ValueError(\"Signal x must match the length of the initial filter w\")\n",
    "    if w is None or xp.allclose(w, xp.zeros(filter_length)):\n",
    "        w = xp.random.randn(filter_length)\n",
    "        w = w / xp.linalg.norm(w)\n",
    "    v = xp.dot(x, w)\n",
    "    if non_linearity == 'sigmoid':\n",
    "        y = sigmoid(v)\n",
    "        grad = 1/w + x * (1.0 - 2.0 * y)\n",
    "        w_update = w + learning_rate * grad\n",
    "    elif non_linearity == 'tanh':\n",
    "        y = tanh(v)\n",
    "        grad = 1/w - 2 * x * y\n",
    "        w_update = w + learning_rate * grad\n",
    "    else:\n",
    "        raise ValueError(\"Non-linearity not implemented. Try 'sigmoid' or 'tanh'.\")\n",
    "    return w_update, y\n",
    "def info_max_deconvolution_gaussian_pdf_simulation(x, filter_length=50, num_iterations=1000, learning_rate=0.01):\n",
    "    T = x.shape[0] - filter_length + 1\n",
    "    if T <= 0:\n",
    "        raise ValueError(\"Signal x must be longer than the filter length.\")\n",
    "    if sliding_window_view is not None:\n",
    "        X = sliding_window_view(x, window_shape=filter_length)\n",
    "    else:\n",
    "        X = xp.array([x[i:i+filter_length] for i in range(T)])\n",
    "    w = xp.random.randn(filter_length)\n",
    "    w = w / xp.linalg.norm(w)\n",
    "    for it in range(num_iterations):\n",
    "        y = xp.dot(X, w)\n",
    "        g_y = sigmoid(y)\n",
    "        error = 1.0 - 2.0 * g_y\n",
    "        grad = xp.dot(X.T, error)\n",
    "        w += learning_rate * grad\n",
    "        w = w / xp.linalg.norm(w)\n",
    "        if (it % (num_iterations // 10) == 0) or (it == num_iterations - 1):\n",
    "            entropy_est = -xp.mean(xp.log(g_y * (1 - g_y) + 1e-8))\n",
    "            print(f\"Iteration {it}/{num_iterations}, entropy estimate: {to_cpu(entropy_est):.4f}\")\n",
    "    y_final = xp.dot(X, w)\n",
    "    return w, y_final\n",
    "def info_max_deconvolution_parzen_window_sampler(x, w, M=50, L=10, eta=0.01, est_cdf='sigmoid', kernel='gaussian'):\n",
    "    if w.shape[0] != M:\n",
    "        raise ValueError(\"M must match the length of the initial filter w.\")\n",
    "    if x.shape[0] != M + L:\n",
    "        raise ValueError(\"Signal x must match the length of the initial filter (M + L) windows\")\n",
    "    if w is None or xp.allclose(w, xp.zeros(M)):\n",
    "        w = xp.random.randn(M)\n",
    "        w = w / xp.linalg.norm(w)\n",
    "    if est_cdf == 'sigmoid':\n",
    "        activation = sigmoid\n",
    "        activation_derivative = sigmoid_derivative\n",
    "    elif est_cdf == 'tanh':\n",
    "        activation = tanh\n",
    "        activation_derivative = tanh_derivative\n",
    "    else:\n",
    "        raise ValueError(\"Invalid est_cdf. Try 'sigmoid' or 'tanh'.\")\n",
    "    if kernel == 'gaussian':\n",
    "        kernel_func = gaussian\n",
    "        kernel_derivative_func = gaussian_derivative\n",
    "    else:\n",
    "        raise ValueError(\"Invalid kernel. Only 'gaussian' is supported.\")\n",
    "    \n",
    "    x_fin = x[L:L+M]\n",
    "    X_windows = (sliding_window_view(x, M)[:L]\n",
    "                 if sliding_window_view is not None\n",
    "                 else xp.array([x[i:i+M] for i in range(L)]))\n",
    "    y_fin = xp.dot(x_fin, w)\n",
    "    Y_fin = xp.full((L, 1), y_fin)\n",
    "    Y_windows = xp.reshape(xp.dot(X_windows, w), (L, 1))\n",
    "    Z_fin = activation(Y_fin)\n",
    "    Z_windows = activation(Y_windows)\n",
    "    xt_fin = x_fin * activation_derivative(y_fin)\n",
    "    Xt_fin = xp.repeat(xt_fin[xp.newaxis, :], L, axis=0)\n",
    "    Xt_windows = X_windows * activation_derivative(Y_windows)\n",
    "    kernel_weight = kernel_derivative_func(Z_fin - Z_windows)\n",
    "    chain_rule_kernel_weight = Xt_fin - Xt_windows\n",
    "    entropy_grad = xp.mean(kernel_weight * chain_rule_kernel_weight, axis=0)\n",
    "    w_new = w - eta * entropy_grad\n",
    "    return w_new\n",
    "def info_max_deconvolution_parzen_window_sampler_simulation(x, d, M=50, L=10, eta=0.01,\n",
    "                                                            est_cdf='sigmoid', kernel='gaussian', trial=None):\n",
    "    x = xp.asarray(x)\n",
    "    N = x.shape[0]\n",
    "    if trial is not None:\n",
    "        xp.random.seed(trial)\n",
    "    x = xp.pad(x, (M+L-1, 0), mode='constant')\n",
    "    w = xp.random.randn(M)\n",
    "    w = w / xp.linalg.norm(w)\n",
    "    weight_tracks = xp.zeros((N, M))\n",
    "    predictions = xp.zeros(N)\n",
    "    for i in range(N):\n",
    "        segment = x[i: i + M + L]\n",
    "        x_fin = segment[L:L+M]\n",
    "        current_prediction = xp.dot(x_fin, w)\n",
    "        new_w = info_max_deconvolution_parzen_window_sampler(segment, w, M, L, eta, est_cdf, kernel)\n",
    "        y = xp.dot(x_fin, new_w)\n",
    "        if xp.isnan(y):\n",
    "            print(\"y is NaN\")\n",
    "        predictions[i] = current_prediction\n",
    "        weight_tracks[i] = new_w\n",
    "        w = new_w\n",
    "    return weight_tracks, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blind Deconvolution GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_max_deconvolution_parzen_window_sampler_gpu(x, w, M=50, L=10, eta=0.01, est_cdf='sigmoid', kernel='gaussian'):\n",
    "    if w.shape[0] != M:\n",
    "        raise ValueError(\"M must match the length of the initial filter w.\")\n",
    "    if x.shape[0] != M + L:\n",
    "        raise ValueError(\"Signal x must match the length of the initial filter M + L previous windows\")\n",
    "    if w is None or cp.allclose(w, cp.zeros(M)):\n",
    "        w = cp.random.randn(M)\n",
    "        w = w / cp.linalg.norm(w)\n",
    "    if est_cdf == 'sigmoid':\n",
    "        activation = sigmoid\n",
    "        activation_derivative = sigmoid_derivative\n",
    "    elif est_cdf == 'tanh':\n",
    "        activation = tanh\n",
    "        activation_derivative = tanh_derivative\n",
    "    else:\n",
    "        raise ValueError(\"Non-linearity is either not implemented, or invalid. Try 'sigmoid' or 'tanh'.\")\n",
    "    if kernel == 'gaussian':\n",
    "        kernel_func = gaussian\n",
    "        kernel_derivative_func = gaussian_derivative\n",
    "    else:\n",
    "        raise ValueError(\"Window is either not implemented, or invalid. Try 'gaussian'.\")\n",
    "    \n",
    "    x_fin = x[L:L+M]\n",
    "    X_windows = cp.lib.stride_tricks.sliding_window_view(x, M)[:L]\n",
    "    y_fin = cp.dot(x_fin, w)\n",
    "    Y_fin = cp.full((L, 1), y_fin)\n",
    "    Y_windows = cp.reshape(cp.dot(X_windows, w), (L, 1))\n",
    "    Z_fin = activation(Y_fin)\n",
    "    Z_windows = activation(Y_windows)\n",
    "    xt_fin = x_fin * activation_derivative(y_fin)\n",
    "    Xt_fin = cp.repeat(xt_fin[cp.newaxis, :], L, axis=0)\n",
    "    Xt_windows = X_windows * activation_derivative(Y_windows)\n",
    "    kernel_weight = kernel_derivative_func(Z_fin - Z_windows)\n",
    "    chain_rule_kernel_weight = Xt_fin - Xt_windows\n",
    "    entropy_grad = cp.mean(kernel_weight * chain_rule_kernel_weight, axis=0)\n",
    "    w_new = w - eta * entropy_grad\n",
    "    return w_new\n",
    "\n",
    "def info_max_deconvolution_parzen_window_sampler_simulation_gpu(x, d, M=50, L=10, eta=0.01,\n",
    "                                                            est_cdf='sigmoid', kernel='gaussian', trial=None):\n",
    "    x = cp.asarray(x)\n",
    "    N = x.shape[0]\n",
    "    if trial is not None:\n",
    "        cp.random.seed(trial)\n",
    "    x = cp.pad(x, (M+L-1, 0), mode='constant')\n",
    "    w = cp.random.randn(M)\n",
    "    w = w / cp.linalg.norm(w)\n",
    "    weight_tracks = cp.zeros((N, M))\n",
    "    predictions = cp.zeros(N)\n",
    "    for i in range(N):\n",
    "        segment = x[i: i + M + L]\n",
    "        x_fin = segment[L:L+M]\n",
    "        current_prediction = cp.dot(x_fin, w)\n",
    "        new_w = info_max_deconvolution_parzen_window_sampler(segment, w, M, L, eta, est_cdf, kernel)\n",
    "        y = cp.dot(x_fin, new_w)\n",
    "        if cp.isnan(y):\n",
    "            print(\"y is NaN\")\n",
    "        predictions[i] = current_prediction\n",
    "        weight_tracks[i] = new_w\n",
    "        w = new_w\n",
    "    return weight_tracks, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Grid Search for Blind Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_deconvolution(x, d, M=50, L=10, candidate_etas=None, candidate_est_cdfs=None, num_trials=10):\n",
    "    if candidate_etas is None:\n",
    "        candidate_etas = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    if candidate_est_cdfs is None:\n",
    "        candidate_est_cdfs = ['sigmoid', 'tanh']\n",
    "    performance_dict = {}\n",
    "    best_avg_nmse = xp.inf\n",
    "    best_params = None\n",
    "    best_trial_outputs = None\n",
    "\n",
    "    for eta_candidate in candidate_etas:\n",
    "        for est_candidate in candidate_est_cdfs:\n",
    "            trial_namses = xp.zeros(num_trials)\n",
    "            trial_predictions = xp.zeros((num_trials, x.shape[0]))\n",
    "            trial_weights = xp.zeros((num_trials, x.shape[0], M))\n",
    "            for trial in range(num_trials):\n",
    "                tw, tp = info_max_deconvolution_parzen_window_sampler_simulation(\n",
    "                    x, d, M=M, L=L, eta=eta_candidate, est_cdf=est_candidate, kernel='gaussian', trial=trial)\n",
    "                trial_weights[trial] = tw\n",
    "                trial_predictions[trial] = tp\n",
    "                valid_mask = ~xp.isnan(tp)\n",
    "                y_pred = tp[valid_mask]\n",
    "                d_valid = d[valid_mask]\n",
    "                y_pred_norm = xp.linalg.norm(y_pred)\n",
    "                d_valid_norm = xp.linalg.norm(d_valid)\n",
    "                if y_pred.size > 0:\n",
    "                    amse = xp.mean((d_valid - y_pred*(d_valid_norm/y_pred_norm)) ** 2)\n",
    "                    namse = amse / d_valid_norm\n",
    "                else:\n",
    "                    namse = xp.nan\n",
    "                trial_namses[trial] = namse\n",
    "            avg_weights = xp.nanmean(trial_weights, axis=0)\n",
    "            std_weights = xp.nanstd(trial_weights, axis=0)\n",
    "            avg_predictions = xp.nanmean(trial_predictions, axis=0)\n",
    "            std_predictions = xp.nanstd(trial_predictions, axis=0)\n",
    "            avg_namse = xp.nanmean(trial_namses)\n",
    "            std_namse = xp.nanstd(trial_namses)\n",
    "            performance_dict[(eta_candidate, est_candidate)] = (avg_namse, std_namse)\n",
    "            print(f\"Candidate eta={eta_candidate}, est_cdf={est_candidate} --> Avg NMSE: {to_cpu(avg_namse):.6f} +/- {to_cpu(std_namse):.6f}\")\n",
    "            if avg_namse < best_avg_nmse:\n",
    "                best_avg_nmse = avg_namse\n",
    "                best_params = (eta_candidate, est_candidate)\n",
    "                best_trial_outputs = {\n",
    "                    'avg_weights': avg_weights,\n",
    "                    'avg_predictions': avg_predictions,\n",
    "                    'std_weights': std_weights,\n",
    "                    'std_predictions': std_predictions\n",
    "                }\n",
    "    print(f\"\\nBest parameters: eta={best_params[0]}, est_cdf={best_params[1]} with average NMSE: {to_cpu(best_avg_nmse):.6f}\")\n",
    "    return best_avg_nmse, best_params, best_trial_outputs, performance_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for different M and L values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was using this block to test stuff out, ignore this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_list = []  # to store best (eta, est_cdf) tuples for each candidate run\n",
    "p1_df_deconv = pd.DataFrame(columns=['Input', 'Noise Variance', 'Model Order',\n",
    "                                       'Best Eta', 'Best est_cdf', 'W-SNR', 'NMSE'])\n",
    "\n",
    "for input_name, d in zip([\"speech\"], [x_speech]):\n",
    "    print(f\"\\n=== {input_name.upper()} Input ===\")\n",
    "    N = d.shape[0]\n",
    "    best_y_pred = None\n",
    "    best_namse = xp.inf\n",
    "\n",
    "    for nv in noise_variances:\n",
    "        d_noisy = add_noise(d, noise_var=nv)\n",
    "        x_noisy = unknown_plant(d_noisy, fir_coeff=fir_coeff)\n",
    "        print(f\"  Noise variance={nv}\")\n",
    "        for M in M_candidates:\n",
    "            for L in L_candidates:\n",
    "                time_steps = xp.arange(N)\n",
    "                x_w = x_noisy[:N]\n",
    "                d_w = d_noisy[:N]\n",
    "                t_start = tick.perf_counter()\n",
    "                best_avg_namse, best_params, best_stat_outputs, performance = grid_search_deconvolution(\n",
    "                    x=x_w, d=d_w, M=M, L=L,\n",
    "                    candidate_etas=eta_candidates,\n",
    "                    candidate_est_cdfs=est_cdf_candidates,\n",
    "                    num_trials=num_trials\n",
    "                )\n",
    "                t_stop = tick.perf_counter()\n",
    "                best_eta, best_est_cdf = best_params\n",
    "                best_params_list.append(best_params)\n",
    "                y_avg = best_stat_outputs['avg_predictions']\n",
    "                avg_weights = best_stat_outputs['avg_weights']\n",
    "                if avg_weights[-1] is not None:\n",
    "                    final_w_est = avg_weights[-1]\n",
    "                    w_snr = compute_weighted_snr(final_w_est, fir_coeff)\n",
    "                else:\n",
    "                    w_snr = xp.nan\n",
    "                print(f\"M={M}, best_eta={best_eta}, best_est_cdf={best_est_cdf}, W-SNR={to_cpu(w_snr):.2f} dB, \"\n",
    "                      f\"NMSE={to_cpu(best_avg_namse):.6f}, Time to find best params={t_stop-t_start:.2f} s\")\n",
    "                title_str_val = (f\"{input_name.upper()}, noise={nv}, M={M}, eta={best_eta}, est_cdf={best_est_cdf}\\n\"\n",
    "                                 f\"W-SNR_val={to_cpu(w_snr):.2f} dB, NMSE={to_cpu(best_avg_namse):.6f}\")\n",
    "                x_w_normalized = x_w / xp.linalg.norm(x_w)\n",
    "                d_w_normalized = d_w / xp.linalg.norm(d_w)\n",
    "                y_avg_normalized = y_avg / xp.linalg.norm(y_avg)\n",
    "                mask = ~xp.isnan(y_avg_normalized)\n",
    "                plot_comparison(d_w_normalized[mask], x_w_normalized[mask], y_avg_normalized[mask], title=title_str_val)\n",
    "                plot_comparison_fft(d_w_normalized[mask], x_w_normalized[mask], y_avg_normalized[mask], title=title_str_val)\n",
    "                plot_weight_tracks(avg_weights, best_stat_outputs['std_weights'], time_steps, M, title_str_val)\n",
    "                if best_avg_namse < best_namse:\n",
    "                    print(f\"  ** New best NMSE found: {to_cpu(best_avg_namse):.6f} **\")\n",
    "                    best_namse = best_avg_namse\n",
    "                    best_y_pred = y_avg\n",
    "                new_row = pd.DataFrame([[input_name, nv, M, best_eta, best_est_cdf,\n",
    "                                          to_cpu(w_snr) if USE_GPU and gpu_available else w_snr,\n",
    "                                          to_cpu(best_avg_namse) if USE_GPU and gpu_available else best_avg_namse]],\n",
    "                                       columns=p1_df_deconv.columns)\n",
    "                p1_df_deconv = pd.concat([p1_df_deconv, new_row], ignore_index=True)\n",
    "    \n",
    "    out_fname = f\"speech_imax_pred.wav\"\n",
    "    nonnan_best_y_pred = best_y_pred[~xp.isnan(best_y_pred)]\n",
    "    sf.write(out_fname, to_cpu(nonnan_best_y_pred).reshape(-1, 1), fs_speech)\n",
    "\n",
    "avg_best_eta = np.mean([params[0] for params in best_params_list])\n",
    "print(f\"\\nAverage best eta: {avg_best_eta:.6f}\")\n",
    "p1_df_deconv.to_csv(os.path.join(PLOT_DIR, \"deconv_grid_search_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_df_deconv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
